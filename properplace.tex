\RequirePackage[l2tabu, orthodox]{nag}%less problems with LaTeX code
\RequirePackage{silence}\WarningFilter{newunicodechar}{Redefining Unicode character}
\pdfgentounicode=1 %permits (with package glyphtounicode) to copy eg x ⪰ y iff v(x) ≥ v(y) from pdf to unicode data. 
\input{glyphtounicode}%nice copy from PDF
\documentclass[preprint, french, english, 11pt, authoryear]{elsarticle}%english main language
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{newunicodechar}%able to use e.g. → or ≤ in source
\usepackage{babel}
\frenchbsetup{AutoSpacePunctuation=false, SuppressWarning=true}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{color}
\usepackage{natbib}
\usepackage{doi}
\usepackage{hyperref}
\hypersetup{breaklinks, colorlinks, linkcolor=black, citecolor=black, urlcolor={blue!80!black}, bookmarksopen}
\usepackage{bookmark}% hyperref doc says: Package bookmark replaces hyperref’s bookmark organization by a new algorithm (...) Therefore I recommend using this package.
\usepackage{cleveref}
\newcommand{\protectforpdf}[1]{\texorpdfstring{\ensuremath{#1}}{#1}}
\bibliographystyle{abbrvnat}
\usepackage{etoolbox}
\apptocmd{\thebibliography}{\hfuzz=20cm\raggedright}{}{}
\usepackage[nolist,smaller,printonlyused]{acronym}
\begin{acronym}
\acro{DM}{Decision Maker}
\acro{WTP}{Willingness to Pay}
\end{acronym}
%which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200
\tolerance=2000
%accept overfull hbox up to...
\hfuzz=2cm
%reduces verbosity about the bad line breaks
\hbadness 5000
%reduces verbosity about the underful vboxes
\vbadness=1300

\onehalfspacing
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newcommand{\commentYM}[1]{\textcolor{blue}{YM: #1}}
\newcommand{\commentOC}[1]{\textcolor{red}{OC: #1}}
\newcommand{\commentOCf}[1]{\textcolor{red}{\selectlanguage{french}{OC : #1}}}
\newcommand{\commentE}[1]{\textcolor{green}{RelecteurExterne: #1}}
\newunicodechar{ℝ}{\mathbb{R}}
\newunicodechar{≠}{\ensuremath{\neq}}
\newunicodechar{≤}{\ensuremath{\leq}}
\newunicodechar{≥}{\ensuremath{\geq}}
\newunicodechar{→}{\ifmmode\rightarrow\else\textrightarrow\fi}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{∪}{\cup}
\newunicodechar{∩}{\cap}
\newunicodechar{¬}{\ifmmode\lnot\else\textlnot\fi}
\newunicodechar{…}{\ifmmode\ldots\else\textellipsis\fi}

\newcommand{\adv}{\mathscr{N}}
\newcommand{\fadv}{\mathscr{N}_J}%fuzzy adv

\begin{document}
\title{Justification and decision sciences}

\author[ld]{Y. Meinard\corref{cor1}}
\author[ld]{O. Cailloux}
\cortext[cor1]{Corresponding author}
\address[ld]{Universit\'e Paris-Dauphine, PSL Research University, CNRS, UMR [7243], LAMSADE, 75016 PARIS, FRANCE}

\begin{abstract}
Decisions are a core subject matter for many economic theories and sub-disciplines, which can be collectively called ``decision sciences''. This article aims at clarifying the normative status of practices that consist in using insights from decision sciences to support decision-making, by formulating recommendations. When applied to a concrete problem, decision sciences obtain conclusions of the form $N ⇒_c R$. Such conclusions contain recommendations $R$ conditionned by the norms or normative conceptions $N$, through  an implication $N ⇒_c R$, which holds true given a series of information about the context $c$. This article explores strategies deployed in the economic and philosophical literature to jump from $N ⇒_c R$ to $R$, while eschewing to take a stance on $N$. We argue that these strategies fail. As an alternative, we argue that, as decision scientists, we should openly endorse, as part of our scientific practice, the norm $\adv$, according to which we should embark in a ``quest for justification'': the attitude of people who endlessly keep on arguing about the justification of their stances about what ought to be done. We display reasons to accept $\adv$. We then argue that endorsing $\adv$ in our scientific practice implies deploying an attitude that consist in:
\begin{enumerate}[label=\roman*.]
	\item Systematically justifying our recommendations;
	\item Actively eliciting criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understanding our own justifiability in a comparative sense.
\end{enumerate}
\end{abstract}

\begin{keyword}
Decision Aiding, Normative Economics, Legitimacy, Justification, Ethics of Operational Research
\end{keyword}

\maketitle
Here link to the Five Commandments.

\section{Introduction}
\commentYM{Trucs à mentionner quelque part : Bradom articulating reasons, D and L reason based theory of choice, G. Gauss justificatory liberalism}

Decisions are a core subject matter for many economic theories and sub-disciplines. In this article, we will use the loose phrase ``decision sciences'' to refer to all these economic approaches, which take decision-making as their main topic, ranging from operational research to social choice theory, through public choice theory, the microeconomic theory of choice, rational choice theory, multi-criteria decision aiding methodology, and so on.

Some of the studies gathered under this umbrella present themselves as purely academic contributions, concerned only with establishing scientific results. However, most decision sciences have practical applications, both in the private sector and in policy-making \citep{tsoukias_policy_2013,marchi_evidence-based_2016}. Such applications entail a call for knowledge to become advice, and purportedly scientific propositions to endorse the normative status of prescriptions. 
In this article, we want to clarify the normative status of such practices, which consist in using insights from decision sciences to support decision-making.

By talking about ``normative status'', we mean that we want to clarify the extent to which these practices are indeed normative, and to articulate a normative account of them. 
The term ``normative'', used to qualify a “practice”, will be taken here in a broad sense, to refer to practices that aim at recommending some actions. This understanding is admittedly broad, since it encompasses practices concerned with notions such as ethics, justice, the good and the just, and so on. 
Though broad, this understanding is not all-encompassing. In particular, it excludes purely positive or purely empirical attempts to capture the above mentioned notions. For example, empirical studies aimed at capturing what people in a given group mean when using the term ``justice'', as examplified by \citet{gaertner_empirical_2012}, does not fall within our definition of a ``normative'' inquiry. Besides, we will be concerned here only with recommendations, and will leave aside more binding or constraining normative notions such as obligation.

Based on this understanding of ``normative'', the issue articulated above in terms of ``normative status'' refers to the following difficulty. When analysts use decision sciences to tackle a given concrete problem, they are commonly expected by their clients, concerned stakeholders and the general public to formulate recommandations $R$. However, in fact the analysts' conclusion in such a situation is typically not a self-standing $R$, but rather an implication $N ⇒_c R$, which holds true given a series of information about the context $c$. Such conclusions contain recommendations $R$ conditionned by norms or normative conceptions $N$: accepting  $N$ leads to accepting the recommendations, whereas rejecting $N$ does not lead to any recommandation. In this formal representation, the ``$⇒_c $'' symbol represents what one might call the ``technical'' aspects of the decision-aid, consisting, among others, in data elicitation and analysis, model selection procedures, mathematical formulations and calculi, simulations, sensitivity analyzes, and so on.

\begin{example}[Cost-Benefit Analysis (CBA)]
Let us introduce a simple example which will be used in the entire article to illustrate various importants steps of our reasoning. Imagine that a decision analyst is asked by a \ac{DM} to help him decide whether or not he should implement a given project $P$. The analyst uses cost-benefit analysis \citep{layard_cost-benefit_1994} and ends-up formulating a recommandation $R$ = ``P should be implemented''. This recommandation is not unconditional. Thanks to her precise analysis of the context $c$ and her computations, the analyst derives $R$, through $⇒_c $, from a norm $N$, which entrenches the relevance of using cost-benefit analysis to decide whether $P$ should be implemented or not. This norm is ``preference utilitarianism'', a norm stipulating that aggregate welfare, as measured by individual preferences, should be maximized  \citep{meinard_ethical_2016}.
\end{example}
\commentOCf{J’aime beaucoup cette idée d’un exemple suivi.}

In real-life decision-aiding practice, identifying the $R$, $N$ and $⇒_c$ parts in the conclusions of decision analyses, and thereby articulating these conclusions in the form $N ⇒_c R$, might prove extremelly difficult, and possibly sometimes impossible. This is mainly because some of the concepts used to articulate decision scientific reasonings and results (which are encapsulated in the symbol $⇒_c$ in our formalism) are, at least according to some authors such as \citet{mongin_value_2006} and \citet{baujard_value_2013}, intermingled with norms (or ``value-judgments'' to use the same vocabulary as the above-cited authors). In the present article, we will leave these issues aside and admit that the retranscription in $N ⇒_c R$ form is possible, at least  in theory. Our reasoning will be mostly focused on tightly formalized cases where $N$ can take the form of an axiom or a set of axioms. With due caution we will, however, strive to draw more general conclusions, applicable to other sorts of $N$.
\commentOC{Can’t we say that we are interested in giving support to both $N$ and $⇒_c$?}

The retranscription in $N ⇒_c R$ form is useful because it allows to define the normative status of a given application of decision sciences as the attitude of the decision analyst towards $N$ in this application. In the present article, we will explore various \commentOC{?} of these attitudes, exemplified in the economic and philosophical literature. We will see that these various attitudes share a critical blindspot: they evacuate or trivialize the task to help the \ac{DM} to make up her mind about $N$.

By contrast, we claim that this task is pivotal. In order to accomplish it, we argue that decision scientists should endorse an ``higher level'' norm $\adv$, according to which we should embark in a ``quest for justification'': the attitude of people who endlessly keep on arguing about the justification of their stances about what ought to be done. We call $\adv$ a ``higher level'' norm because $\adv$ can be used to establish if this or that $N$ can be used in a given application of decision sciences, but in itself $\adv$ is too abstract for any $R$ to be derived from it in the absence of any additional $N$. Notice that we use here a comparative term (``high\emph{er}''), because our point is simply that $\adv$ does not play the same role as $N$, and places itself ``upstream'' $N$. Elaborating a precise and complete typology of norms falls beyond the scope of this article. In particular, we do not claim that there are only two kinds of norms: higher level ones, and lower level ones. The difference might be one of degrees.

We then argue that $\adv$ can be fleshed out to articulate a series of four simple rules that applications of decisions sciences should follow if they set themselves the requirement to duly integrate the need to help the \ac{DM} to make up her mind about $N$. 

The immense literature on the normative underpinnings of economic science \citep{buchanan_positive_1959,sen_nature_1967,dwyer_scientific_1985, heath_value_1994,mongin_value_2006,baujard_value_2013} tackles issue which are, to some undeniable extent, linked with the ones that we explore here. However, despite these numerous historical debates, the applied literature still expresses diametrically opposed stances on these matters (\citet{spash_bulldozing_2015} vs. \citet{scharks_dont_2016} for example) \commentOCf{C’est plus beau si on écrit : …diametrically opposed stances on these matters \citep{spash_bulldozing_2015, scharks_dont_2016}}. This suggests that clarifications are still needed, especially when it comes to the practice of producing recommendations, as opposed to the theoretical aspects on which the above literature is mainly focussed.

This article is an attempt in that direction. It is divided into seven parts. Following the present introduction, section 2 explores three attitudes with respect to $N$ and $N ⇒ R$ which one can find in the economic literature. We argue that these attitudes have fatal flaws. Section 3 explores the strategy deployed in the literature in political philosophy. In section 4 we argue for endorsing $\adv$. Section 5 clarifies the notion of justification that we need to make sense of $\adv$. Section 6 fleshes out the implications of this notion materialized in a set of four concrete rules, and section 7 concludes.

\section{Elusive economic attitudes with respect to \protectforpdf{N}}
\subsection{\protectforpdf{A1}: agnosticism about \protectforpdf{N}}
A widespread vision among economists is that economics is a value-neutral, purely scientific endeavor. This approach admits that value-judgments are essentially non-scientific, and that economics as a science should therefore eliminate them. This vision suggests a first attitude, $A1$, which consists, for the economist, in sticking to conclusions of the form $N ⇒_c R$, and letting \acp{DM}, or even “society” in general, decide of their attitude towards $N$ on their own. Deriving $R$ thus lies, in this attitude, outside the scientific part of the endeavor. 

Being completely agnostic about $N$, $A1$ could be applied to any norm, however absurd or blatantly immoral, still leading to conclusions of the form $N ⇒_c R$. Such an attitude would certainly produce hoards of results that would not be of interest to anyone. $A1$ accordingly does not capture what most researchers in economics, decision sciences, or related fields do.\commentOC{I believe we have to say that it’s also not what they should do. Or is it sufficiently clear that it is implicit here?}

\subsection{\protectforpdf{A2}: the quest for ``self-evident'' \protectforpdf{N}}
\commentYM{peut-être faudrait-il ici distinguer deux attitude : d'un côté, la recherche de $N$ self-evident, c'est-à-dire dont on attend que tout le monde les accepte ou les rejette, mais en tout cas que tout le monde ait la même attitude vis-à-vis d'eux (eg. Pareto, dictature...), d'un autre côté, les $N$ dont on attend juste qu'elles soient ``transparentes'', c'est-à-dire dont on se dit que les gens doivent tous pouvoir se faire leur avis dessus, même si on s'attend à ce que différentes personnes aient des avis différents}
\commentOCf{C’est vrai que c’est conceptuellement intéressant, mais à ce stade je pense qu’on ne ferait rien de cette distinction, et on peut donc se contenter de notre description actuelle ce concernant à mon avis.}
In order to overcome this problem, a natural amendment of $A1$ is to confine the inquiry to norms which are clear and largely accepted enough for \acp{DM}, or society, to decide, without the help of science, that they endorse them. Let us call such norms ``self-evident''.
This approach defines a second attitude, $A2$: science obtains conclusions of the form $N ⇒_c R$, and $N$ is self-evident, therefore, $R$ holds.

Identifying such self-evident $N$ however proves more difficult than one might expect, for two reasons.

First, typical candidates for such norms in the literature are axioms that, under their technical, decontextualized expression, may appear convincing. But once they are applied to concrete contexts, one soon realizes that, in their concrete formulation, they remain convincing only if very restrictive conditions are fulfilled. To illustrate this idea, let us take the strong Pareto principle, stating that state of affairs $y$ is better than $x$ if no one is worse-off in $y$ as compared to $x$, and at least one person is better-off in $y$ as compared to $x$. This is undeniably a normative axiom, but most authors present this normativity as ``minimal'', in the sense that it seems innocuous to admit that most people, if not everyone, accepts this normative principle. According to this argument, the strong Pareto principle would hence be a ``self-evident'' $N$. However, this claim is more debatable than most authors seem to admit, as emphasized by \cite{sen_rationality_2004}, among others. Take for example a slightly unequal situation $x$ where individual $i$ is quite well-off whereas individual $j$ is poor. Compare with situation $y$ where $i$ receives a bonanza and $j$'s situation is unchanged. $y$ Pareto dominates $x$, but is considerably more unequal. The idea that everyone would claim that $y$ is better than $x$ is far from self-evident. It relies on questionable assumptions about a total absence of aversion to inequality and envy. The Pareto principal hence no longer appears self-evident when applied to wealth, and only retrieves its self-evidence if it is applied to some aggregated welfare index integrating aversion to inequality and envy. One thereby sees how difficult it might be to set the situation so as to render it evident that everyone will agree on the Pareto principle when applied to a concrete context (\citet{mongin_axiomatisation_2003} and \citet{baujard_bien-etre_2015} articulate a similar point by arguing that axiomatic approaches are ``purely syntactic'' approaches, ``without a semantic'' liable to guarantee that their seeming convincing in the abstract implies that they will appear convincing in concrete settings). One can therefore not claim without further ado that the strong Pareto principle is self-evident, and a similar reasoning holds for similar axioms, seemingly ``self-evident'' in the abstract.

Second, accepting some norms logically entails accepting their implications, but it is not evident for an individual to know whether all the implications of some norms are acceptable for her. To illustrate this idea, consider \citeauthor{arrow_social_2012}’s \citeyearpar{arrow_social_2012} caracterization of the dictator rule (we thank Ulle Endriss for this example). Arrow's argument is based on axioms that the author presents as liable to be endorsed by most of his readers. \commentOC{I don’t like “that the author presents as liable to be”, seems convoluted and seems to attack Arrow.} The argument shows that the Dictator rule is caracterized (in some formal context) by the axioms of Universal Domain, Pareto Dominance, and Independence of Irrelevant Alternatives. It is easily imaginable that non-expert individuals would willingly accept each of these axioms as capturing value-judgments they endorse about what they demand from a voting rule, if the axioms were explained to them by focusing only on what each axiom demands separately. The point of Arrow's theorem, and the reason why this result is so powerful, is that a series of axioms which all appear acceptable yields dictatorship, which our imaginary individuals would certainly reject. A natural way out of the conundrum is to question the spontaneous adherence to the axioms, which prove, on due reflection, to be less commendable. The example of the Dictator rule therefore shows that one cannot rest content with the bare fact that a norm $N$ seems self-evident in the abstract, since one can be led to reject a seemingly self-evident $N$ on due reflexion, once one has come to realize some of $N$'s implications.

\subsection{\protectforpdf{A3}: choosing \protectforpdf{N} that decision-makers ``would endorse if he could understand''}
$A1$ and $A2$ are two attitudes whereby economists claim to use decisions sciences while leaving $N$ outside the purview of their scientific inquiry. We have argued that both attitudes fail because they are predicated on a implausible premisse: that \acp{DM} do not need the help of decision sciences to make up their mind about $N$.

By contrast, a third attitude, $A3$, consists in claiming that, when articulated in the form of axioms, $N$ are too difficult for \acp{DM} to understand. Decision scientists holding this attitude admit that they have the collective skills to understand axioms and discuss among peers whether this or that axiom should be accepted or not. But they do not consider that \acp{DM} should take part in such discussions, for the simple reason that these are technical, difficult decisions, and most \acp{DM} are therefore incapable to participate. When they arrive at conclusions $N ⇒_c R$, where $N$ encapsulates axioms that decision scientists collectively deem commendable, they consider themselves entitled to jump to $R$ without bothering to help \acp{DM} to make up their mind about $N$. Indeed, \acp{DM} being ill-equiped to understand $N$, this would be a waste of time and energy. At most the decision scientist will invest some time to explain to the \ac{DM} why it was a good idea to endorse $N$, or will content himself to think that, if the \ac{DM} were able to understand the axioms, he would endorse them.

Attitude $A3$ consists, for the decision scientist, in endorsing a higher-level norm $\mathscr{N}_{A3}$ that consists in claiming that expert discussions about norms among decision scientists entitle them to make decisions about norms on behalf of \acp{DM}. Such a norm $\mathscr{N}_{A3}$, which embodies what \citet{estlund_democratic_2009} calls ``the expert/boss fallacy'', is quite questionable, and it is likely that few decision scientists really wholeheartedly endorse it. 

An additional problem with $A3$ is how to decide whether to endorse $\mathscr{N}_{A3}$. \commentOC{I’d remove the rest of this §, which does not seem very illuminating to me. The mere fact of letting the reader think about this problem should be enough to convince that there’s a problem, I think.}
One can admit that the decision whether or not to endorse $\mathscr{N}_{A3}$ should be taken by decision scientists, in which case one endorses $\mathscr{N}_{A3}$ to decide whether to endorse $\mathscr{N}_{A3}$, and there does not seem to be any reason in this case to end-up rejecting $\mathscr{N}_{A3}$, because it does not seem self-contradictory. But this first approach sounds unacceptably circular. A second possibility would be to apply $A2$ to $\mathscr{N}_{A3}$, but in such a case our arguments against $A2$ hold. A last possibility would be to refer to \acp{DM} to ask them if they are willing to surrender the choice of their stance towards $N$ to the decision scientist. To our best knowledge, such an approach has never been empirically tested.

\commentOC{However, I’d add something. Related to the “additional problem”, it is to the best of our knowledge left unspecified in the literature what is precisely required (when adopting  $\mathscr{N}_{A3}$) for an expert to decide that “enough” discussion has taken place in the expert community and that a consensus has been reached about the acceptability of some norm. 
(In fact, this remark resembles the remark about $\mathscr{N}_{A4}$: it is puzzling that it is left completely implicit and unarticulated.) 
}

\subsection{\protectforpdf{A4}: informally testing whether decision-makers endorse \protectforpdf{N}}
The blatant weaknesses of $A3$ suggest a pragmatic variant, $A4$. This is the attitude of decision scientists who reject $A3$'s idea that decision scientists can decide about $N$ on behalf of \acp{DM}, and therefore make a point to informally discuss the meaning of $N$ with the \acp{DM} to verify that they agree that the specifics of the situation are such that $N$ appears endorsable to the \acp{DM}. The problem with $A4$ is that is strangely combines a scientific approach to arrive at $N ⇒_c R$, with an informal, loose approach to lead \acp{DM} to make up their mind about $N$, without a clear methodology.

Like $A3$, $A4$ is anchored in a higher level norm $\mathscr{N}_{A4}$. But this higher level norm is not clearly articulated. It encapsulate the idea that decision analysts cannot make decisions about $N$ on behalf of \acp{DM}, but does not specify precisely what they should do.

\begin{example}[CBA (Continued)]
Let us simply illustrate the meaning of attitudes $A1-4$ in our hypothetical scenario of an application of CBA.

$A1$ admits that the task for the analyst is to compute a CBA, but does not account for the reason for her to choose a CBA. It might be, for example, that the \ac{DM} requested decision-aid through a public procurement procedure specifying that CBA should be used. The analyst complies and remains agnostic about the $N$ underlying CBA

$A2$ would mean, for the analyst, that she admits that preference utilitarianism a self-evident, in the sense that most \acp{DM} if not all will accept it.

$A3$, by contrast, acknowledges that \acp{DM} can find it difficult to understand the meaning of this $N$, and might be be at a loss trying to decide whether or not they should endorse it. An analyst adopting $A3$ would hence fall back upon a community of researchers endorsing $N$ to take the decision to endorse $N$ on behalf of \acp{DM}.

Lastly, an analyst adopting $A4$ would find $A3$ inacceptable, and would informally strive to discuss with the \ac{DM} to help him decide whether or not he endorses $N$. But to accomplish this task, the analyst will be left without a rigorous methodology.
\end{example}


\section{Elusive strategies to clear \protectforpdf{N} from its normative content}
We have argued in the former section that the attitudes currently found in the economic literature are unsatisfactory. $A3$ and $A4$ however suggest an interesting solution, which consists in refering to a higher level norm. The philosophical literature contains some interesting, deeper explorations of this idea, in particular in debates on ``pure procedural'' vs. ``substantive'' approaches to political legitimacy.

Substantive theories claim that democracy is a matter of values. An example of such an approach is \cite{brettschneider_value_2006}, who claims that democracy is first and foremost a set of ``core values'', which can be materialized in the proceedings of constitutional courts just as well as in votes and institutional proceedings more usually called ``democratic''. As opposed to substantive theories, purely procedural theories claim to account for democracy by delineating formal properties of decision-making procedures that are supposed to be purely value-neutral, and from which democracy would emerge. (Notice that this debate should not be conflated with the debate opposing “output” vs. “input” theories of legitimacy \citep{vatn_environmental_2016, backstrand_environmental_2010}: proponent of an input theory of democracy claim that, if a decision has been taken through democratic procedures, then it is democratic, whatever its output; proponents of output theories take the opposite stance).

In our formalism, substantive theories claim that $N$, in order to be powerful enough to permit stating $N ⇒_c R$ for for $R$s talking about democratic credentials, must contain value-judgments. Whereas purely procedural theories claim that it is possible to obtain $N ⇒_c R$ without $N$ containing value-judgments. The purely procedural approach can hence be seen as another strategy, $A5$, allowing to obtain $R$ from $N ⇒_c R$, this time by claiming that $N$ does not contain value-judgments after all, and can therefore innocuously be accepted. $A5$ is the strategy deployed in a couple of historical cornerstones of contemporary political philosophy: \cite{rawls_political_2005} and \cite{habermas_moralbewustsein_1983}. Let us examine whether $A5$ proved more powerful than $A1-4$.

\cite{rawls_political_2005}'s theory epitomizes what \cite{estlund_democratic_2009} called a ``flight from substance''. He did not want his theory to make any value-judgment about the kind of state of affair that should prevail in a democratic society. He therefore argued that a policy is democratically legitimate if it is based on a constitution whose justification is acceptable by all  ``reasonable'' citizens. But he did not want to make value-judgments about democratic processes either. He therefore further argued that the very definition of reasonableness should be something for reasonable citizens to pick-up. He thereby attempted to eschew making any value-judgments in his account of legitimacy and reasonableness. This was supposed to be a complete flight from substance, in the sense that this account was supposed to eschew any value-judgment, whatsoever. If this reasoning were successful, it would allow to derive $R$ from $N ⇒_c R$ by emptying $N$ from its normative content, rendering it innocuous to endorse.
\commentOC{I think we should write that it removes the value judgments from $N$, rather that it empties it from its normative content, because we haven’t defined the latter and it conflicts with our definition of normative practice. But maybe we’d better removing this sentence altogether (or shorten it) because we said this already.}

This approach fails, however, for reasons articulated in different versions most prominently by \cite{habermas_reconciliation_1995} and \cite{estlund_democratic_2009}. \commentOC{Remove: Let us start with \cite{estlund_democratic_2009}'s argument because it is simpler to summarize.} \citet{estlund_democratic_2009} noticed that, if one admits, following Rawls, that the notion of reasonableness should be selected by reasonable people themselves, there is an ``impervious'' plurality of groups that could select themselves as being ``reasonable''. He concluded that rawlsian political philosophers have no choice but to make bold claims about the content of the concept of reasonableness. \cite{habermas_reconciliation_1995}'s argument is, to a large extent, similar. He criticizes Rawls' presentation of his notions of the ``veil of ignorance'' and the ``overlapping consensus'' as \emph{devices} whose real-life functionning can give rise to principles of justice. According to \cite{habermas_reconciliation_1995}, these notions are rather rhetorical tools thanks to which Rawls exposes principles of justice that he deduces from various philosophical notions, such as the one of a moral person, which Rawls presupposes. Rawls' flight from substance hence abruptly collapses in a retreat back to the substantial inquiry into the nature and features of a moral subject.  Rawls' attempt is therefore the paragon of the failure of the flight from substance (which is neither a logical flaw nor a failure to unveil illuminating insights, but a failure to strip the argument from its normative anchorage, or ``substance''). His theory is anchored in a higher level norm $\mathscr{N}_R$, but this higher level norm is not thematized as such in his philosophy.

By contrast, in his debate with Rawls on the theory of justice, Habermas goes a step further by analyzing the higher level norm underlying his theory (though he does not uses this vocabulary). \cite{habermas_moralbewustsein_1983}'s ``weak'' transcendental deduction of the tenets of ``discours ethics'' from communicative action is particularly interesting in this respect. \citet{habermas_theorie_1981} argues that agents communicating with one another make validity claims of three sorts: veritative claims about truth, normative claims about values and norms, and authenticity claims about expressions concerning their inner life, feelings and conciousness. The role that norms play is therefore clearly circumscribed in Habermas' framework, and it concerns one kind of validity claims among others. \cite{habermas_moralbewustsein_1983} does not locate the tenets of ``discours ethics'' at this level. He rather argues that all the acts and deeds that consist in making validity claims are oriented by a strive for intercomprehension, which lies at the core of communicative action. And he identifies the tenets of discourse ethics as conditions of possibility for this intercomprehension-oriented activity. On the face of it, Habermas' reasoning therefore seems to provide the means to eschew the task to help the \acp{DM} to make up their mind about norms. Indeed, he identifies an ``ethics'', which is presumably something that allows to identify what ought to be done, or to formulate recommendations, and the tenets of this ``ethics'' are such that it would be pointless to expect \acp{DM} to make up their mind about them, because these tenets are conditions of possibility for a very basic, all-pervasive structure of human action. Like $A3$, Habermas' approach is therefore anchored in a higher level norm, $\mathscr{N}_{H}$, capturing the tenets of discours ethics. Just like $\mathscr{N}_{A3}$, this higher level norm does not allow directly to deduce recommendations $R$. But as opposed to proponents of $A3$, Habermas provides foundations to entrench his $\mathscr{N}_{H}$. 

These foundations are, however, derived from his very specific understanding of communication and its importance in the functioning of human societies, which has been extensively criticized in the literature \citep{heath_communicative_2001,honneth_kritik_1985}. 

By anchoring itself in a higher level norm $\mathscr{N}_{A3}$, $A3$ paves the way for a satisfactory solution to our problem in this article. $A4$ overcomes $A3$'s shortcomings by pointing the need to find a better higher level norm than $\mathscr{N}_{A3}$, but fails to articulate one. Similarly, Rawls' approach is anchored in a higher level norm $\mathscr{N}_{H}$ that he fails to account for. Habermas goes a step further by entrenching his higher level norm $\mathscr{N}_{H}$ in his philosophy of society. In the sections to come, our aim is to follow this lead and identify a more relevant higher level norm $\adv$, which is more fitted to our object (viz, applications of decision sciences), and is not derived from Habermas' disputed vision of communicative action.

\section{The quest for justification}
\label{sec-quest}
In this section, we introduce another higher level norm $\adv$, according to which, as decision scientists, we should embark on a ``quest for justification'': the attitude of people who endlessly keep on arguing about the justification of their stances about what ought to be done. In this section, we will take the concept of justification in a very abstract sense. This will allow us to discuss reasons to endorse $\adv$. The next section will flesh out the content of this concept to some extent, before we delve into even more concrete considerations in the penultimate section.

\subsection{Reasons to endorse the quest for justification}

\commentYM{Olivier, sur cette section nous avons un gros désaccord. D'après ce que je comprends, selon toi $\adv$ s'impose, ou est vraiment la seule norme self-evident. Je ne le comprends pas bien cette position, ou plutôt, je trouve l'argument complètement vide. Pour moi c'est une version de $A2$, qui ne tient pas la route car $A2$ ne tient pas la route. Pour moi $R3$ est une version non-vide de et argument. Si tu as quelque chose d'autre en tête, peut-être que je comprendrai mieux si tu le rédiges}
\commentOC{See \cref{sec-whichnorms}.}

We have claimed above that any conclusion of applications of decision sciences aimed at articulating recommendations has the form $N ⇒_c R$. If the decision scientist faces a challenge of the form ``why should we endorse $N$?'', or if she feels the need to clarify why one should endorse $N$ for any other reason, she can adopt a variety of attitudes which, we argue, necessarily converge towards either of two fundamental normative attitudes: endorsing $\adv$ or endorsing what we call ``strong moral realism''.

Most, if not all, normative reasonings strive, at least at first, to provide \emph{justifications} for the $N$ they command. In so doing, they seem to endorse $\adv$. However, whereas some truly endorse $\adv$ and therefore never stop giving new justifications, by constrat, at some point, some normative reasonings fall back upon some basic normative tenets which are not seen as requiring justifications. People engaged in normative reasonings of the latter sort admit (sometimes explicitely, but sometimes also implicitly, and perhaps without being fully aware of it) that they can claim, about these basic normative tenets, without further ado, that they are ``right'' or ``good''. Let us call this latter attitude ``strong moral realism''.

\begin{example}[CBA (Continued)]
\label{ex-cba-smr}
An analyst challenged, for example, by a stakeholder, as to whether using CBA is relevant to decide on whether to implement $P$ could behave in a ``strong moral realist'' way by simply claiming that CBA is a criterion maximizing aggregate welfare, and it is simply unquestionable that aggregate welfare is what policies should maximize. \commentOC{I’d prefer: “behave in a ``strong moral realist'' way by considering that it is simply unquestionable that CBA is a criterion maximizing aggregate welfare, and that aggregate welfare is what policies should maximize.” (because otherwise we introduce a dissymmetry in the two-parts argument where we hint that one is supposedly more correct)} By contrast, an analyst embarked on a quest for justification would feel the need to articulate a justification of this normative claim, and discuss it with the stakeholder.
\end{example}
\commentOCf{On peut adhérer à $\fadv$ et être convaincu que CBA est valable dans une situation de décision donnée. De même, Galilée était peut-être convaincu que le résultat de son expérience de pensée serait en sa faveur, mais c’est compatible avec une attitude scientifique correcte. Ce qui ne le serait pas serait de refuser de faire l’expérience. L’attitude de l’analyste, pour être incompatible avec $\fadv$, doit être non pas simplement d’être lui-même convaincu, mais bien de refuser le débat. Même avec ma proposition de reformulation, ça n’apparait pas assez clairement. Et même si l’analyste refuse le débat, ça pose la question : tous les cadres de débat sont-ils bons ? L’analyste pourrait refuser un débat dans une circonstance qui lui semble non propice au débat serein, tout en adhérant à $\fadv$. Tout comme Bourdieu qui refuserait un débat télévisé.}

Notice that the word ``realism'', and to a lesser extent the phrase ``moral realism'', understood in various senses, play important roles in the philosophical literature (see for example \citet{putnam_realism_1992}'s defense of realism). We do not claim that our notion encompasses all these senses. Our argument makes sense when one uses our definition of ``strong moral realism'', and we do not make any broader claim.

A first reason, $R1$, to endorse $\adv$ is that most normative reasonings start by embarking on the quest for justification, but at some point some deviate and fall back upon ``strong moral realism''. In that sense, most versions of ``strong moral realism'' are incoherent. However, $R1$ is admittedly a rather weak reason to endorse $\adv$ , because it possibily does not concern all variants of ``strong moral realism'' (versions that never articulate justifications are excluded) and, more worryingly, it is predicated on the further norm that incohenre is a fatal flaw for a normative attitude, which is not accounted for by $R1$.

A second, stronger reason, $R2$, is that ``strong moral realism'' either converges towards $\adv$, or it collapses either in a refusal to articulate any recommendation or in an apology of violence. Indeed, imagine that, as a ``strong moral realist'', you face a challenge to your vision of what ought to be done. You can reply by justifying your stance, and in so doing you give up ``strong moral realism'' and lean towards $\adv$. Or you can flight the request and refuse to articulate any recommendation after all. Or you can ankylose on your stance and strive to impose it by force. In that case, either violence is part of your vision of what ought to be done, in which case you are stuck in the apology of violence, or your vision of what ought to be done rejects violence and your ``strong moral realism'' is repudiated. The only stable ``strong moral realism'' is therefore the apology of violence -- where ``stable'' means here that this attitude can survive without converging towards the attitude with which we contrast is, that is: $\adv$.

\commentOCf{Je trouve ton argument $R2$ très subtil et intéressant, maintenant que je le comprends. Mais je trouve qu’il ne fonctionne pas bien sur le cas de la violence, voir ci-dessous (ou il faut préciser le contexte). L’argument est je pense correct plus généralement, sous la forme suivante : SMR s’étend. Si SMR et appliquer $R$ conduit à une conséquence $c$, et $\adv$ conduit à rejeter c, alors, SMR et appliquer $R$ requiert également d’être obtus concernant $c$. Être sérieusement SMR risque donc d’entrainer beaucoup de refus de discussion. (Mais il me semble que l’argument n’est percutant que si on peut trouver au moins un exemple d’application convaincant.)}

\commentOCf{L’exemple de la violence ne fonctionne pas bien. Quid si la recommandation est fournie à un groupe de gens, dont seule une petite minorité questionne la validité ? Ou, un partisan du SMR pourrait simplement user de stratagèmes (par exemple rhétoriques) pour se construire une majorité en soutien, voire une unanimité, en assurant un débat inéquitable. Ou, il pourrait utiliser la force des institutions, sans pour autant utiliser la violence explicitement (par exemple il est possible que Mitterrand se soit opposé à la majorité de la population quand il a aboli la peine de mort). Ou, il pourrait renoncer à $R$ seulement quand il voit que ça l’oblige à la violence. De plus, que veut dire "imposer sa recommandation par la force" dans le cas où la recommandation est de \emph{ne pas} appliquer la peine de mort ? En résumé, il n’est pas clair qu’imposer une solution par l’entourloupe requière nécessairement plus de violence que débattre autant que possible (car on pourrait ne jamais arriver à l’unanimité et il y a des gens qui n’écoutent pas les arguments).}

What about the quest for justifications: is it stable? The quest for justifications can be transient: one can be ready to argue up to a certain point, and then fall back upon ``strong moral realism''. What if it is not transient -- if it does not fall back upon ``strong moral realism''? One might argue that, if you endorse the quest for justification, it means that you endorse the values underlying the idea that moral stances should be backed by justifications. And these very values are the core of your ``strong moral realism''. The quest for justification would hence unavoidably fall back on ``strong moral realism''. More precisely, based on what we said above, referring to the apology of violence, one could claim that the ``strong moral realism'' in which the quest for justification is anchored is embodied by the acceptance of the norm $N=$``violence is bad''. We claim that such a rejoinder is flawed. Indeed, one can defend $N=$``violence is bad'' through either of two attitudes: striving to identify justifications to our endorsing it, or admitting that it is a basic normative tenet that does not require justifications. If we defend $N=$``violence is bad'' in the first manner, our quest for justification is not anchored in a ``strong moral realism''. 

A third reason $R3$ is more circumstancial, and confined to applications of decision sciences to policy making. The role of scientific expertise in policy making is sometimes presented as undergoing a crisis (eg.\citet{godard_environnement_2015}). The story goes as follows. In the recent past, scientific expertise used to play a key-role in policy making, it was seen as a means to guarantee the rationality of policies, thanks to \emph{objective} scientific expertise. But things are said to have changed, more or less suddenly, in the past twenty years, due to various factors classified by \citet{godard_environnement_2015} under four main headings: the emergence of a growing concern for global threats (climate change, biodiversity erosion, large-scale technological accidents such as nuclear one, etc.); a global crisis of the credibility of nation States as effective agents in a world dominated by economic and financial forces; the resounding impact of some large scale health or food scandals, such as the ``mad cow'' scandal; the growing influence of mass-media, liable to amplify the visibility of such scandals and associated conflicts of interest.

Due to the influence of these factors, experts and their various reports, recommendations and conclusions are said to undergo a crisis of \emph{confidence}. \citet{godard_environnement_2015} recalls that, as a response, many expertise settings, proceedings and institutions have evolved (in more or less successful attempts to restore the lost confidence) to increase their \emph{transparency}, \emph{pluralism} and \emph{independence}.

These three criteria are largely accepted as requirements to impose on any expertise. However, they cannot be considered as absolute and applicable in all situations. As \citet{godard_environnement_2015} aptly points out, in some situations an excessive transparency can cripple expertise, and independence is, in many respects, unachievable: every expert has its interests, an uninterested expert is a chimera. Similarly, pluralism denies the very idea that expertise can have a point, if pluralism means that all opinions, however fanciful or extremist, should be given the same weight. Accordingly, these three criteria are better conceived as implications of a more fundamental principle: the need to justify expert opinions. \citet{godard_environnement_2015} p. 379 mentions this idea in passing, in the case of independence: ``the right question is not `tell me to whom are you tied', but `tell me which arguments justify your opinion' ''. But a similar rationale applies to the other two criteria: the point of requiring transparency is to render visible the justifications underlying the various expert opinions, or the lack thereof; the point of pluralism is to expose justifications to a large sample of counterarguments, as diverse as possible.

The largely admitted need for scientific expertise to be transparent, pluralist and independant hence appears to reflect that the normative credentials of $\adv$ are implicitely largely accepted. 

\subsection{The endorsement of the quest for justification in practice}
Despite $R3$, we do not claim that everyone endorses $\adv$ all the time. In some situations, one may prefer to turn a blind eye toward one's inability to justify one's stance, for example, because facing this inability might be psychologically too difficult. We claim, however, that, in most situations where decision sciences are made use of and are applied to real-life problems, endorsing $\adv$ is a matter of course, and that most practices that consist in applying decision sciences in this way endorse, at least implicitly, $\adv$.

That said, we emphasize that highlighting $\adv$ as a central norm for applications of decision sciences is far from being trivial. The literature forcefully illustrates how supposedly scientific expertises can prove spurious, hide conflicts of interests, and in that sense do not impose themselves to justify the recommendations they formulate (e.g. \citet{hoggan_climate_2009,oreskes_merchants_2011}). Similarly, the existence of debates in the applied literature on whether economic expertise is value neutral (e.g. the debate \citet{spash_bulldozing_2015} vs. \citet{scharks_dont_2016} refered to above) testify for the fact that some decision scientists deny that they endorse a norm like $\adv$ in their practices.

\subsection{How our strategy relates to the other ones in the literature}
Like $A3$, $A4$, Rawls' and Habermas' approaches, our strategy is anchored in a higher level norm $\adv$. This higher level norm is extremelly abstract, and does not allow deriving recommandations $R$, even when much contextual elements $c$ are taken into account. It rather delineates an attitude that decision sciences should have when they ask themselves whether a given $N$ should be adopted, for a $N$ liable, in a specific context $c$, to derive $R$ through $⇒_c $. It is useful, then, to examine how $\adv$ can relate to the higher level norms associated with the stances studies in sections 2 and 3.

We have seen that $A3$ is anchored in a higher-level norm $\mathscr{N}_{A3}$ that consists in claiming that expert discussions about norms among decision scientists entitle them to make decisions about norms on behalf of \acp{DM}. $\adv$ belongs to a higher level than $\mathscr{N}_{A3}$, in the sense that it can be applied, not only to the norms $N$ that $\mathscr{N}_{A3}$ is concerned to select, but also to $\mathscr{N}_{A3}$ itself: this is what proponents of $A4$ do, when they argue to reject $A3$. Similarly, $\adv$ can be applied to $\mathscr{N}_{A4}$, and this is what one does when pointing that $A4$ lacks a clearly articulated methodology. Likewise, $\adv$ can be applied to $\mathscr{N}_{R}$ (this is what Habermas does when he unveils the fact that Rawls does not account for the concept of a moral agent underlying his theory), and to $\mathscr{N}_{H}$ (this is what Habermas himself does when he makes a point to derive the tenets of discourse ethics from his theory of communicative action, and this is also critics such as \citet{honneth_kritik_1985} do when they question the latter theory). $\adv$ hence places itself in a higher position than all the higher level norms explored so far.

At this stage, the reader will certainly have noticed that our notion of a quest for justification is, in sereval important respect, quite close to some notions developped by Habermas, and that the above-mentioned argument of Habermas' is the closest approach to ours, among those explored so far. We indeed full-heartedly acknowledge the influence of Habermas. As far as we know, Habermas however never explicitely spelled out the precise ideas captured by our notion of a quest for justification. And the purely exegetic question whether he would endorse our formulation falls beyond our scope in the present article. 

\section{Which notion of justification?}
So far we have used the notion of justification in an unspecified, abstract sense, and one might want to criticize our reasoning by claiming that we used the term ``justification'' ambiguously. Indeed, when used in the abstract, the term ``justification'' is certainly a deeply ambiguous one, in part because it refers to a ``thick'' concept in \citet{williams_ethics_1985}'s sense. A justification can be seen in a purely positive sense, as a set of arguments that someone deploys to defend a stance, as a matter of empirical fact. But, at the same time, the term ``justification'' has unmistakable normative connotations: a purported justification that would prove unable to convince anyone would not be considered to be a justification properly speaking; similarly, an alleged justification entirely based on spurious arguments would not count as a justification, properly speaking. This raises the risk that our rationale in the former section might made sense only because we presupposed a specific normative notion of justification, specifying what should count as \emph{a good justification} or \emph{a justification properly speaking}, without our clarifying the content of this specific notion of justification. In order to proceed rigorously, at the present stage we therefore have to clarify this notion. For that purpose, we will work by elimination, starting with the crudest notion of justification and progressively focussing on one that can prove adequate for our purposes.

A first, crude notion of justification could take the form of a precise identification of the norms underlying the method(s) that a decision scientits puts to use in a given situation.

\begin{example}[Economic valuation methods]
The most prominently used economic valuation methods are based on measurements of people's \acp{WTP}, as it can be elicited by surveys addressed at individual (stated preference methods: mainly contingent valuation and choice experiment) or revealed by these individuals' behavior on markets (revealed preference methodes: mainly travel cost and hedonic pricing methods). \citet{meinard_ethical_2016} proposed a typology of these methods depending on their respective normative underpinnings. A prominent alternative to \acp{WTP}-based methods developped in recent years is deliberative valuation \citep{bartkowski_economic_2017}. This refers to methods based on choice-experiments or \acp{WTP} questionnaires embedded in protocols of exchanges of information and discussions. \citet{bartkowski_beyond_2018} explored their positive philosophical underpinnings, referring mainly to \citet{sen_idea_2009}. Each method can hence be associated with a ``justification'', understood as a clarification of the norms underlying each method: deliberative valuation is associated with Sen's philosophy, stated preference  \acp{WTP}-based methods with ``welfarism'' and revealed preference  \acp{WTP}-based methods with ``endowment conservatism''. This precise definition of these normative frameworks should not concern us here, and we will accept the validity of these associations for the purpose of the argument. The important point from our point of view here is that, thanks to these elements, one can identify a series of argumentative justifications that can be deployed to defend all those kinds of methods in their application to our example.
\end{example}

Based on the example above, one might be tempted to conclude that, seen through the lenses of the quest for justification, all the methods mentioned would allow decision scientists to justify them. We see here a first inadequate notion of justification. In order for it to be possible to use the notion of a quest for justification to say something non-vacuous about decision sciences and their applications, we need a more determinate notion of justification, one that does not trivially allow to say that anything can always be justified, in the sense that one can always articulate a discours to formulate a ``justification'', however spurious or vaccuous.

A second, more determinate notion of justification can be envisaged, using the sociological literature on ``orders of justification'' \citep{boltanski_justification_2006}. According to this literature, various groups typically refer to different and largely irreconciliable ``orders of justifications'', which can (according to some authors at least) be formalized as sets of normative axioms accepted by some groups but rejected by others. This suggests the following approach. One could relate to each other the typology of ``orders of justifications'' and a typology of justifications underlying various decision scientific methods, so that, based on a sociological survey determining in which groups the people concerned by a given application of decision sciences fall, one could pick up a decision scientific methods justified by the same axioms as those endorsed by those people.

However, such an approach would, in our view, fail to capture some aspects of the notion of justification that we need to make sense of the idea of a quest for justification. Indeed, in the kind of cases envisaged by the literature on ``orders of justifications'', it might be that some people accept a given set of axiom, as a matter of fact, but that, if they were confronted to counterarguments challenging one or serveral of these axioms, they would change their mind and switch to another normative stance. If, as decision scientists, we face such people as we are embarked on a ``quest for justification'', it would appear incoherent, it would be a failure of the ``quest for justification'' to eschew arousing such reactions. 

In order to integrate such reactions, we need a more interactive notion of justification, one that certainly cannot be mechanically applied at the level of methods in general, and should rather be applied to concrete, particular decision processes (understood in the sense spelled out in \citet{tsoukias_concept_2007}). Decision aiding processes are concrete sets of continued interactions between decision analysts, decision-makers and concerned stakeholders. The notion of justification that we need refers to the justification that can be articulated for the specific usages of the methods at this or that stage during the decision aiding process. Coming back to our example of environmental economic valuations, the various methods mentioned about can be used for very different purposes at various stages in concrete decision aiding processes. Stated and revealed preferences studies are often used to feed cost-benefit analyses \citep{layard_cost-benefit_1994}. However, as emphasized by \citet{meinard_ethical_2016}, the very same monetary valuations can just as well be used as arguments to strengthen public awareness of the importance of the object they value, or to put a provisional figure on the impact that various kinds of actions can have on various groups of stakeholders, or in many other ways. In these various cases, one can develop a justification that takes advantage of the identification of the norms $N$ underlying the method used, but also integrates many other elements pertaining the context, and the specific usage of the method within the particular decision aiding process -- including, for example, discussions between the analyst and the \acp{DM} whereby the analyst explains to the \acp{DM} that $N$ are presupposed at a given stage on a provisional basis, and the analyst helps the \acp{DM} to understand the implications of this provisional assumption of $N$.

In line with this approach, one could then admit that a justification deserves to be called so if it is acceptable by those to whom it is presented. In such an approach, the fact that argumented justifications can be carved out for the different methods simply means that the methods can be put to the test of their acceptability by various people or groups. This raises the question: how can one know if a justification is acceptable in this sense? A natural answer would consist in claiming that a justification qualifies as acceptable if and only if it turns out to be accepted in all the situations in which it can be applied. However, here again, how can one perform that kind of test? At best one can say whether applications of a given methods \emph{have so far been accepted}, but this leaves aside all possible but non actual applications.

This problem echoes Habermas' arguments against Rawls' flight from substance, mentioned above. We look here for a means to determine the notion of justification, but we want it to remain an \emph{normative} notion. By anchoring it in the positive idea of accepted justification, we would deprive it from an important normative aspects. The lesson from \cite{habermas_reconciliation_1995}'s and \cite{estlund_democratic_2009}'s criticism of Rawls' notion of ``reasonable'' applies directly: if it is to make sense, Rawls' theory is not about justifications that real people usually accept or will accept, but about justifications that citizens \emph{would} accept, if they were reasonable. \cite{habermas_faktizitat_1992} forcefully emphazises this counterfactual aspect in his theory of legitimacy. Similarly, we have to undertand the notion of acceptability of a justification in a counterfactual sense. 

But how can one know that a justification is acceptable in this sense? An option would be to define acceptable justifications as those that are endorsed by \acp{DM} and concerned stakeholders once they have taken all the relevant arguments and counterarguments into account. However, to our best knowledge, there is no operational framework to date to capture such ``deliberated judgments'' (see however Cailloux and Meinard), and even once one will be available, it is likely that operationality constraints such as time constraints will make it impossible to deploy such a technology in all applications of decision sciences. Besides, either this very definition of ``acceptability'' is anchored in a strong moral realism, or it should itself be justified, and how would we define the relevant acceptability without circularity? Our agenda at this stage is therefore to develop an account of what it means to endorse $\adv$ in our practice of decision sciences, without having to fall back upon a strong moral realist account of what is an acceptable justification.

\section{The recommended model}
\cite{meinard_what_2017} ventured a partial solution to the problem spelled out above, in a study of the concept of legitimacy. This partial solution is based on two tenets.

The first tenet is ``incrementalism''. ``Incrementalism'' holds that the idea that one can be able to capture a definitive list of criteria defining what is a good argument, what is the reasonable, what is acceptable, and so on, is illusory. According to ``incrementalism'', one had better work incrementally, to improve step by step justifications, argumentations, etc. This tenet hence consists in accepting that any attempt to specify criteria to capture what makes a justification acceptable is bound to be provisional, and that one can only laboriously improve the blunt concept of acceptability step by step.

The second tenet is ``primacy of practice'': instead of searching for acceptability criteria through theoretical reflection, one should take the stance that consists in putting justifications to the test in real-life situations. According to ``primacy of practice'', justifiability is not a property of a recommendation formulated by a decision analyst, it is a property of the recommendation \emph{together with} the manner these recommendations are  implemented and argued against and in favor.

These two tenets allow to overcome a very problematic feature of philosophical approaches such as Rawls' and Habermas', which is that such approaches seem to admit that philosophical arguments can decide if an argument is a good one, or a justification is an acceptable one, even without a single real stakeholder or decision-maker having the opportunity to make up her mind about it.\cite{meinard_what_2017} used these two tenets to delineate an understanding of the concept of legitimacy. But this approach can easily be translated into an answer to our question in the present article. Here we will translate some important elements of this approach to our context, and also address what we take to be weaknesses of \cite{meinard_what_2017}'s approach, so as to unfold a more satisfactory account.

Our proposed account will be articulated in five points.

A first point is designed to capture the idea that, as application of ``primacy of practice'', our endorsement of $\adv$ should first and foremost take the form of our actually articulating justifications.

As decision scientists, our quest for justification should consist in:
\begin{itemize}
\item[i.]	Systematically justifying our recommendations;
\end{itemize}

A second point should prevent our using justifications that happen to be accepted, as a matter of fact, at the moment when we articulate them, but whose weaknesses we sweep under the carpet. This point enbodies ``incrementalism'', by admitting that, once we have found arguments in favour of something, we should try to look for ways through which they could be discarded. Real-life examples of decision-aiding practices that flout this clause are given in \cite{meinard_what_2017}, which lead him to introduce a requirement to be ready to defend one's recommendations against criticisms, even when none are formulated. This requirement is insufficient, however. Indeed, an account associating it whith clause [i] would be impaired by a worrying weakness, which can readily be identified by referring to the literature on epistemic injustice \cite{fricker_epistemic_2007} (this problem is not addressed by \cite{meinard_what_2017}). Some people and group have access to knowledge, others have not. The former are in a position to articulate criticisms, the latter are not. By imposing that decision scientists should be ready to defend their recommendations, the above approach exposes decision science only to part of the spectrum from which criticisms can come. What if there are no criticisms addressed at us, whereas many could have been, but were not, because of epistemic injustices? Would we still feel confident in claiming that our approach materializes the idea of a quest for justifications in such a case? We do not think so. There is therefore something amiss in the above account.

Can we fix the problem by identifying a specific group of people that should be the source of criticisms, or even a procedure that should be used to encourage the formulation of such criticisms? Such an approach would not work, because it is hopeless to believe that we can once and for all identify a relevant group of people (or set of groups of people) and/or a magical procedure. We need a more astute approach.

Though incomplete, the above account contains the key to the conundrum. Indeed, this account successfully addresses a problem which is, in a sense, structurally similar to the one we are now addressing. We cannot expect to be able to articulate once and for all what a good justification is. That is why the above account does not spell out a purportedly definitive list of criteria, and rather delineates an attitude on the part of decision analysts. The same trick can do the job here again. We cannot identify once and for all a perfectly relevant group of people and/or a perfect procedure. What we can do is identify an attitude that will be conducive to the quest for justification, and this attitude is a requirement to actively elicit criticisms. This requirement is the missing element in our account to fix its first weakness.

\begin{itemize}
\item[ii.]	Actively eliciting criticisms;
\end{itemize}

We now need a fourth clause to allow clauses ii and iii to embody ``primacy of practice'', by putting justications to the test in real-life, instead of confining them to theoretical criteria (without clause iv, clauses ii and iii would be counterfacual, purely dispositional criteria).

\begin{itemize}
\item[iii.]	 Actively defend our recommendations against all criticisms;
\end{itemize}

But this account, although completed to fix the first weakness, still has another worrying weakness, which can be captured by raising the question: when can one admit that one has produced \emph{enough} justifications? (This weakness was also ignored by  \citet{meinard_what_2017}.) Imagine that you have embarked in a discussion with a stakeholder who always has new criticisms to raise. In such a situation, in our logic, should one admit that you cannot stop the discussion at some point or another? This would give to your contradictor a serious advantage, which certainly is undue: if he is ill-intentioned, he can condemn you to indefinitely argue in vain.

The key to solve this new problem can be found in Sen's contribution to political philosophy. \cite{sen_idea_2009} interestingly distinguished two visions of justice: the transcendental vision and the comparative vision. In broad outline, when applied to the notion of justice, a transcendental vision in his jargon is one that claims to answer questions such as ``what is just?'', ``what does justice consist in?'', ``which criterion can one use to decide if a given situation is just or unjust?'' and so on. By contrast, a comparative vision is one that claims that such questions are unanswerable, and that the point of theories of justice is rather to address comparative questions such as ``is situation \emph{x} more just or less just than situation \emph{y}?'' We do not claim in this article to adjudicate the credentials of an application of this account to theories of justice. We simply want to pinpoint that this structure of argument elegantly solves the remaining problem with the above account. If one admits that one cannot give a definitive answer to the question ``what is a good application of decision science in a democracy?'', but that this is not too bad, because the only truly relevant question is a comparative one such as ``is application \emph{A1} better than application \emph{A2}?'', then one can appreciate the relevance of the above account.

The comparatist approach is no panacea. It is, in a sense, a deflationary approach, and we should be prepared to live with the corresponding modesty. 
Besides, it can arouse expectations that it cannot deliver. It is therefore important to clarify what a comparatist reading of our approach cannot do. It does not provide a metric, no generally applicable mechanical means to compare any two applications without discussions. There is bound to be myriads of hard cases where one application of decision science will appear better than another on some respect, but worse on another respect. We do not claim to solve this problem.

In concrete terms, the comparist leads to add a fifth clause to our account:
\begin{itemize}
\item[iv.]	Understanding our own justifiability in a comparative sense.
\end{itemize}

To sum up, the model that we recommend is that, as decision scientists, we should advocate a quest for justification that consists in:
\begin{enumerate}[label=\roman*.]
	\item Systematically justifying our recommendations;
	\item Actively eliciting criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understanding our own justifiability in a comparative sense.
\end{enumerate}

Let us ponder on this formulation. Clearly, applying the formula [i-iv] is unlikely to ensure that we will be able to identify \emph{the} ultimate justification for our recommendation. For that, we would need to have access to all the possible arguments, all the possibly relevant information, and we would need a perfect definitive definition of what is a \emph{good} justification. This \emph{first best} is unreachable. A commandable \emph{second best} is the ``deliberated judgments'' framework developped by Cailloux and Meinard. However, it is likely that operationality constraints such as time constraints will make it impossible to deploy this approach in all applications of decision sciences. The account that we are looking for, and which is for the moment provisionally captured by the formula [i-v], should hence be seen as an operational third best account that captures the essence of $\adv$ in real-life conditions where knowledge is drastically bounded.

At this stage, we have arrived at a more concrete notion of a ``quest for justification'', one that can be used in real-life by decision scientists, whose extensive formula is [``incrementalism'', ``primacy of practice'', i-iv]. Now we have to make sure that this concrete formula is not \emph{too concrete}, in the following sense: we have to make sure that our reasoning about the abstract notion of justification, unfolded in section 4 to argue that we have reasons to endorse $\adv$, still works with the concrete notion of justification encapsulated in [``incrementalism'', ``primacy of practice'', i-iv].

For that purpose, let us leave $R1$ aside, because it is the weakest reason to endorse $\adv$, and let us start with $R3$. $R3$ states that the largely admitted requirement that expertise should be transparent, pluralist and independant reflect an implicit endorsement of $\adv$ by most people. This argument works, we claim, no less with $\adv$ fleshed out by the concrete formula [``incrementalism'', ``primacy of practice'', i-iv] than with $\adv$ formulated in the abstract. Indeed, ``incrementalism'' and ``primacy of practice'' reflect the idea that even experts have limited capacities to identify definitive solutions to the problems they are entrusted to tackle, and therefore their conclusions cannot be considered definitive solutions, and are rather the outcome of reasonings that they should be able to display and account for, in practice. Similarly, clauses [i-iv] spell out the attitude of experts who would enact a willingness to be transparent, pluralist and independant by displaying the arguments underlying their stances, and by actively being willing to face dissident stances.
Let us now turn to $R2$. Checking if our argument concerning $R2$ holds for the concrete notion of $\adv$ encapsulated in [``incrementalism'', ``primacy of practice'', i-iv] means asking whether the latter formula unavoidably encapsulate a variant of ``strong moral realism''. Of course of version of ``strong moral realism'' can take the form of a defense of [``incrementalism'', ``primacy of practice'', i-iv] simply stating that these tenets are the rights one, and that's the way it is. But the real issue is whether it is possible to endorse [``incrementalism'', ``primacy of practice'', i-iv] without endorsing ``strong moral realism''. We argue that it is possible, because the various elements in [``incrementalism'', ``primacy of practice'', i-iv] can all be argued for, on the basis of justifications, which in turn can be defended on the basis of other justifications, and so on. For example, in our presentations of tenets i-iv, we introduced them using arguments, referring to Rawls' and Habermas' philophical approaches to legitimacy, and to theories of epistemic injustices. If challenges, these arguments could be defended by other arguments, found in Rawls'; Habermas'; Frickers' and others' writtings, and so on. Similarly, ``incrementalism'' and ``primacy of practice'' are tenets anchored in philosophical reasonings which can be used to justify their relevance, and whose criticisms can be met by referring to yet other justifications, and so on (see e.g. \citet{meinard_du_2013}). We therefore claim that $R3$ and $R3$ work for the fleshed out version of $\adv$ no less than for the abstract version used in section 4.

\commentYM{one possible modif could be to move the current section 4 after the current section 6. I am not sure....}

\section{Conclusions}
In this article, we have introduced a normative account of the role of decision sciences and their applications. For that purpose, we have emphasized the failure of various strategies designed  to jump from $N ⇒_c R$ to $R$, while eschewing to take a stance on $N$.

We have strived to demonstrate that all these appoaches fail, which has led us to recommend a completely different strategy, that consists in explicitely endorsing $\adv$, referring to the norm that we should embark in a ``quest for justification''. When have then spelled out the implications of endorsing this approach, based on admitting the tenets of ``incrementalism'' and ``primacy of practice'', and conceiving of the justifiability of applications of decision sciences in a comparative approach. We thereby ended up recommending the corresponding model for the proper role of decision sciences, which can be articulated as follows:

As decision scientists, we should advocate a quest for justification that consists in:
\begin{itemize}
	\item Systematically justifying our recommendations;
	\item Actively eliciting criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understanding our own justifiability in a comparative sense.
\end{itemize}

Though this models aims to provide a general account of the normative stance that we should take as decision scientists, and therefore is undoubtedly very ambitious in its scope, we emphasize that it is also very modest in many respects. It does not provide a metric, no generally applicable mechanical means to compare any two applications of decision sciences without discussions. There is bound to be myriads of hard cases where one application of decision science will appear better than another on some respect, but worse on another respect.

To conclude, it might be useful to mention some prominent objections that one might want to raise against our approach, and see how our approach fairs.

A first objection might come from decision scientiists who would claim that what we claim they should do is precisely what they already do. It is clearly part of our hope that this account of the normative stance of decision sciences will not come as a surprise for most decision scientists, and is rather liable to gather large support among them. However, though we accordingly expect that most decision scientists will agree with us at the stage when $\adv$ is formulated in the abstract terms of ``justification'', we surmise that most of them do not have clearly articulated ideas about the concrete implications of this basic normative stance, as they are encapsulated in the concrete formula [``incrementalism'', ``primacy of practice'', i-iv]. Its actual implementation might accordingly prove more disrupting for decision sciences practices than the cheer endorsement of $\adv$ in its most abstract form. In particular, it is worth pointing out that most applications of decision sciences take place in the contexts of contracts, such as public procurements. It is highly likely, therefore, that in many concrete situations, consultants or decision scientists implementing decision aid simply comply with the contrats binding them, instead of unfolding the kind of attitude encapsulated in [``incrementalism'', ``primacy of practice'', i-iv]. Accordingly the idea that decision aid providers would already do what we claim they should do is hardly credible. Notice that we are not saying here that our approach is doomed to be inapplicable due to binding decision aiding contracts. Most contracts are incomplete, and leave room for decision scientists to take the liberty to implement approaches such as ours, to some extent, providing they are willing to do so. What we say is simply that it is not plausible to claim that decision scientists all already implement our approach.

A second objection might come from people who would claim that justification is a noble, but impossible to implement in practice. Such critics would claim that, in practice, decision scientists have no choice but to pick up some norms $N$ to derive recommendations, and any attempt to engage in a quest for the justification of these norms would be impractical. Our approach does not, however, claim that one should always endlessly justify everything -- which would indeed be impractical. We rather claim that we should understand our own justifiability in a comparative sense (clause iv above). It is unclear, therefore, that our approach will be more laborious or painful that supposedly more pragmatic alternatives. Besides, as \citet{godard_environnement_2015} recalls, expert advices are often harshly questionned. In such condition, a basic choice for decision scientists is: either work as if criticisms will never come, and then work hard when they come as they probably will, or prepare yourself by endorsing the justification requirement from the very beginning. At the very least, it is far from self-evident that the first strategy is the more ``pragmatic'' one.

A last objection might be that our rationale concerning justification only seemed to hold water thanks to the extreme abstractness of the notion of justification as we use it. In that sense, one could perhaps have said exactly the same things, while replacing $\adv$ by another abstract norm such as, for example, the the requirement that one should reason correctly, or that some should used good reasons rather than spurious ones. We admit that this is a fair criticisms. But this is why we did not contend ourselves with the defense of $\adv$ spelled out in the abstract in section 4, and rather fleshed out our notion of $\adv$ in sections 5 and 6.


%So far, the argument has been entirely abstract. This section will use a series of example to try to flesh it out to some extent.
%Let us start by a burning issue in environmental sciences, the current biodiversity crisis. The current rate of species extinctions is unprecedented. Many conservationist succumb to authoritarian temptations. Democracy looks poorly adapted to take bold decisions to save the planet. It seems like there is a choice to be made. Either we believe in democracy, participation, etc., in which case planet Earth will collapse; or an authoritarian regime will save the Planet and Humanity against its own willing. I think that such a debate is ill-conceived, and that the approach developed here solves the problem, at least to some extent. The idea that urgency trumps the need for participation and democracy in an argument like any other. If a justification based on this argument wins, then the decision to trump participation is not undemocratic, in any non-trivial sense.

%\commentOC{ Bof. Ta dissolution du débat joue
%sur l’ambiguïté du concept de démocratie. Si on prétend que
%la démocratie, c’est prendre les décisions en fonction des
%jugements délibérés du peuple, alors faire la procédure que
%tu proposes, c’est ne pas céder à l’urgence.}

%The same logic shows that this approach can be used to unlock some of the perennial apparent dilemma plaguing the functioning of democratic policies, due to the fact that the above mentioned output/input debate appears undecidable. A typical example in this respect is the case of the 1991 cancellation of the legislative elections in Algeria between the two rounds of the election, following the government’s understanding of the fact that it would certainly be overwhelmingly won by the “Front Islamic du Salut”, championing a largely undemocratic policy agenda. An output theory would call this decision legitimate, an input one would deem it undemocratic. Our approach claims that none of the alternatives (canceling the election or letting it unfold) is intrinsically legitimate, and none is intrinsically more legitimate than the other. The more legitimate one would be the one buttressed more thoroughly by a quest for justification on the part of its champions. This, clearly, is a local answer. Small scale debates here and there probably have unfolded and generated different winners in this respect. There is no general answer to this question. There are illuminating, well-structures local answers.


\section*{Acknowledgements}
We thank Jerome Lang, Philippe Grill and Juliette Rouchier for powerful comments and suggestions on this manuscript.

\section*{References}

\bibliography{decision,philo-eco,beliefs,deliber}

%https://tex.stackexchange.com/questions/26333/elsarticle-appendix-and-a-table-of-contents
\renewcommand*{\appendixname}{}
\appendix

\section{Which norms}
\label{sec-whichnorms}
\selectlanguage{french}

Il faut je crois distinguer deux normes sous ce qu’on appelle $\adv$. D’abord, $\fadv$, la norme vague qui dit qu’il faut toujours chercher des justifications, comme décrit \cref{sec-quest}. Par opposition à $\adv$, qui a le sens beaucoup plus précis qu’on lui donne plus loin sous forme des quatre commandements. En \cref{sec-quest}, on parle uniquement de $\fadv$ je pense. (Sinon il faut clarifier ceci pour le lecteur, et ce que j’écris ci-dessous est en grande partie non valide.)

Comme je le comprends, ce qu’on demande avec $\fadv$, c’est tout simplement d’adopter en matière de normes l’attitude de doute et d’ouverture d’esprit qui fait la force de la science en matière de \og{}faits\fg{} (disons).

D’après moi, oui, $\fadv$, comprise comme ça, s’impose, et est largement acceptée par quiconque déclare pratiquer une activité scientifique (telle que des sciences de la décision).

Pour nuancer cependant ma position, je dirais qu’effectivement, il faudrait être sûr que le lecteur comprenne bien que ce qu’on demande. Si le lecteur croit que ce qu’on demande, c’est de laisser tomber définitivement des normes $N$ plus précises, même en tant que normes temporaires acceptées pour des raisons pratiques, il risque de trouver qu’on va trop loin. De même, il pourrait penser que ça conduit inévitablement au relativisme (ce dont tu parles plus loin) et rejeter $\fadv$ initialement, avant de comprendre qu’elle ne souffre en fait pas de cette implication. Donc d’accord avec toi que $\fadv$ n’est pas évidente dans le sens où elle n’est pas nécessairement immédiatement compéhensible, ou dans le sens où elle n’est pas initialement évidente pour quelqu’un qui n’a jamais réfléchi à ces questions. Mais, contrairement à $A3$, je pense qu’on peut l’expliquer clairement aux non experts en épistémologie, et que une fois ceci fait, elle apparaitra acceptable simplement par introspection, et ça me semble être sa justification ultime.

Un problème lié est que c’est bizarre d’appeler $\fadv$ une norme. Nous avons défini pratique normative mais pas norme. Je soupçonne que pour certains auteurs, l’idée de norme est nécessairement liée à un jugement de valeur plus substantiel. Exemples : le vert est plus joli que l’orange ; tu ne tueras point ; il faut maximiser l’efficacité au détriment du respect de la nature. Or, $\fadv$ est tellement fondamentale qu’elle ressemble à l’exigence d’être cohérent, de bien raisonner, etc. Ça peut paraitre bizarre à l’esprit de certains d’appeler ça une norme (d’ailleurs moi aussi je trouve ça bizarre). Pour résumer ce point, je soupçonne que certains vont déclarer qu’ils ne sont pas d’accord avec nous que leur pratique de scientifique requiert d’accepter la norme $\fadv$, simplement parce qu’ils ont autre chose en tête quand ils parlent de norme, mais que, à part ce problème de vocabulaire, ils seraient d’accord avec nous. Il me semble que, si on part effectivement sur l’idée de distinguer $\fadv$ et $\adv$, il faudrait ne pas appeler $\fadv$ une norme, ou au moins discuter ce point.

Ensuite, il y a ambiguïté sur les “normes” substantielles $N$, illustrée dans ton \cref{ex-cba-smr} de CBA. Mais reprenons d’abord ce qu’on écrit plus haut à propos de la pareto-dominance. Je pense que certains auteurs, quand ils parlent de PD (dont moi, souvent), ont en tête la variante PD-tautologique, celle qu’on décrit succinctement plus haut, qui dit que une alternative doit être préférée à une autre si elle domine l’autre au sens de Pareto \emph{en supposant} qu’on a pris toutes les dimensions pertinentes en compte. Et pour savoir si on a pris toutes les dimensions pertinentes en compte, il faut regarder si on a bien qu’il suffit qu’une alternative en domine une autre au sens de Pareto pour assurer que la première soit préférée à la deuxième. Si qqn a PD-tautologique en tête quand il parle de PD, le fait qu’il affirme PD-tautologique n’implique pas une prise de position de sa part sur la question de savoir s’il a bien appliqué PD-substantiel dans le problème concret dont il s’occupe. De même, dans ton exemple sur CBA, il y a ambiguïté, car l’analyste en question pourrait affirmer que 1) CBA maximise le welfare aggrégé et 2) le welfare aggrégé est ce qu’il faut maximiser \emph{en considérant ces affirmations comme des tautologies}. Dans ce cas, l’analyste a raison d’affirmer cela, et ne contredit pas $\fadv$ (pour la raison indiquée dans mon commentaire après ton exemple). Par contre, il ne s’ensuit pas que \emph{son application} de CBA dans le contexte donné soit correcte. Mais cette nuance n’apparait pas dans l’exemple, ce qui pourrait à mon avis générer des malentendus très problématiques.

Je comprends comme suit les objections suivantes de ta part à mon affirmation que $\fadv$ s’impose : premièrement, considérer que $\fadv$ s’impose est une version de $A2$ et est donc une attitude incorrecte ; deuxièmement, c’est vide ; troisièmement, $R3$ dit la même chose en mieux. Il faudrait si tu veux bien que tu reformules ta deuxième objection, je ne comprends pas.

Concernant ta première objection, $A2$ peut être comprise dans un sens étroit ou dans un sens large (peut-être n’est-ce pas suffisament clair dans le texte actuel ?). L’attitude $A2$-étroit est la version de $A2$ qui concerne des normes $N$ précises, celles qui permettent de déduire des $R$, et cette attitude, en effet comme tu dis, ne tient pas la route. Mais on peut aussi considérer $A2$ plus largement et l’appliquer sur une norme imprécise telle que $\fadv$. Nos arguments contre $A2$-étroit ne tiennent pas nécessairement contre $A2$-large. En effet, nos deux arguments sont 1) les normes candidates sont des axiomes précis, or, on ne sait jamais si ces axiomes sont valables dans un contexte donné, il faut bien une norme de plus haut niveau pour le déterminer ; et 2) le décideur ne voit pas facilement les conséquences des normes précises qu’il accepte. Aucun de ces deux arguments n’est valable quand on applique $A2$-large à $\fadv$.

Concernant ta troisième objection, je ne suis pas sûr de te suivre dans $R3$, mais mettons-nous d’abord d’accord sur le reste, car ce point me semble subordonné au reste de la discussion.

Cependant, je ne m’oppose pas à ce qu’on donne des raisons en plus, si on en trouve, pour ceux qui ne trouveraient pas $\fadv$ évident. Mais je ne suis pas convaincu à ce stade qu’on puisse trouver des raisons qui ne supposent pas déjà que $\fadv$ est évident. (Ton $R2$ est toutefois un bon candidat.) Mais on est peut-être d’accord en pratique sur un point important (voire suffisant) : je pense qu’il est effectivement utile qu’on explique bien ce qu’on veut dire par $\fadv$ et qu’on déjoue les malentendus possibles.

J’ai l’intuition que tu veux contrer l’attitude des gens qui ne doutent pas assez, par exemple sans-doute celle qu’on rencontre facilement parmi les partisans de CBA (ou généralement parmi les partisans d’une opinion majoritaire dans un cercle donné). Mais ceux-là diraient, je pense, qu’ils adhèrent à $\fadv$ tout comme nous, simplement, qu’ils sont en désaccord sur la bonne façon de le mettre en œuvre. Le désaccord serait donc au niveau de $\adv$ version précise. Autrement dit, tout le monde se prétend ouvert d’esprit, mais les gens peuvent être en désaccord sur ce que ça veut dire précisément.

Je suis d’accord qu’il y a probablement des gens qui doutent sérieusement de la pertinence de $\fadv$ pour des questions morales de fond, des questions de valeurs spécifiques : qqn pourrait refuser par exemple de discuter du fait que la peine de mort, c’est mal, par exemple (et donc ce serait la thèse d’un SMR). (Et ici je soupçonne que $R2$ pourrait faire effet.) Mais je pense qu’il est clair pour notre lectorat que ce genre d’attitude n’est pas celle d’un scientifique de l’aide à la décision, qui n’a pas légitimité à imposer ses opinions sur la peine de mort ou d’autres sujets substantiels du genre, et donc que avec ce genre de cas on s’éloigne de notre sujet.

\selectlanguage{english}

\section{Related perspectives}
\label{sec-related}
Here are perspectives found in the literature about validation, or about the dichotomy prescriptive – descriptive, and the comparison with our approach. (This is currently only a draft. And my quotes are not exact, they are mostly rephrased.)

\subsection{Von Winterfeldt and Fischer}
In Wendt, Vlek (eds.) - Utility, Probability, and Human Decision Making.pdf, p. 58.

\begin{quote}
Axioms distinguish models. They provide an analyst with a systematic testing procedure to choose an evaluation model. BUT: axioms can’t be validated (infinite domain), are not satisfied descriptively (inconsistencies in spontaneous behavior). But measurement theoretic justification of these models is possible. The basic axioms can be tested roughly on easy choices. Second, parameters can be assessed on easy comparisons. (More structured models provide easier comparisons.) If axioms are satisfied in a subset of choice alternatives, and the subset is sufficiently rich to assess the basic model parameters, then “one can have some faith in an extrapolation of the evaluation function constructed”. Idea is to follow the prescriptions as long as one believes that failures of assumptions in actual tests are not systematic, or are due to systematic applications of obviously unsatisfactory simplifying strategies. In summary: axioms permit to discover those systematic violations which are intended and rationally justified by the DM. 

P. 80: MAUT methods are typically validated against “wholistic (or intuitive)” (spontaneous) preferences, what’s called the convergent validity approach. This is ok as long as the nb of dimensions is small, say, not greater than five: then the simplifying heuristic strategies do not apply. Then, the convergent validity approach seems quite reasonable.

Axioms are called “behavioral assumptions”.
\end{quote}

The view proposed by these two authors requires the existence and knowledge of a set of “easy” choices, on which axioms can be tested. They propose no way of determining whether, assuming the tests succeed on those easy choices, the principles extend to the non-easy choices. By contrast, we give no special status to easy choices (or to any subset of the decision situations to which the aid is to be applied), and we propose a systematic, precise validation framework that gives a chance to detect any situation in which the principles on which the aid rests do not validly apply (as judged from $i$).
\commentYM{ce que tu dis me semble tenir la route, mais je pense que tu aurais du mal à convaincre de la supériorité de ton approche les auteurs que tu cites juste avant. Je ne pense pas qu'on puisse à si bon compte sabrer toute la littérature sur les axiomes et leur justitfication. Je te ferai passer un papier que j'ai écris là-dessus, et qui est actuellement en soumission}

About the possibility of intransitive preferences.
\begin{quote}
P. 114. intransitive preferences arise because of information overload or indifference thresholds. If information overload, then intransitivities do not necessarily lead to reject the weak order assumption. DM can be faced with his inconsistencies and asked to resolve them. (Sophisticated strategies involving sequential trade-offs can be used…) OR avoid inconsistencies by sticking to “those subsets of the evaluation space which he can handle easily”. Then extrapolate those judgments by applying the model. BUT indifference thresholds may produce intransitivities which cannot be resolved, since they constitute a genuine limitation in the decision maker’s judgmental process. In such a case (example of non discrimination of “interior noise”) of a genuine and non resolvable failure of the weak order assumption, the original model has to be replaced by a semiorder model. However allowing for intransitive indifferences lead to potential money pumping, hence “most decision analysts … would argue that a semiorder approach should only be a last resort in modeling”.

Authors take example where “it would be easy to convince the dm that he should care even about the smallest differences, thus making him conform with the weak order assumption”.
\end{quote}

Our approach offers a description of how such attempt of convincing the dm [that intransitivies should not occur] might take place, be faced with contradiction (to avoid brainwashing), and defines how one can determine whether it is successful. It is an empirical question, in our approach, whether methods that allow for intransitivities will be more successful than others, rather than a question of whether the practioner feels about it (ok, never, last resort only…)

\subsection{Raiffa}
\begin{quote}
Back from Prospect theory to UT, in Plural Rationality and Interactive Decision Processes (1984). Cites Allais and Ellsberg. Some people fully understand SEU but refuse to adopt these principles in their own important decision making. Then: 1) Raiffa agrees that important psychological concerns should be addressed in the theory; 2) sometimes the theory is right however and therapy is the appropriate remedy. He confesses that therapy has not always proven to be ingenious enough, however.
\end{quote}

Again, we provide a way to distinguish therapy from brain-washing, and a way of selecting those theories that are more successful than others in providing “therapy” or switching to weaker (or different) principles when appropriate.
\commentYM{là, c'est vraiment trop elliptique}

\subsection{Machina}
Machina - Choice Under Uncertainty: Problems Solved and Unsolved (2000).

\begin{quote}
	People have the right to be non SEU maximisers. The theory must take this into account.
\end{quote}

Maxima does not indicate how to systematically distinguish those situations where you are not an SEU maximiser simply because you haven’t considered the best arguments in favor of it. Describing usual behavior does not suffice to give good prescription. Our approach permits to distinguish those cases.

\subsection{Allais VS Morgenstern and Amihud}
Allais, M., \& Hagen, O. (Eds.). (1979). Expected utility hypotheses and the Allais paradox. Dordrecht: D. Reidel.

\begin{quote}
Allais (Foreword): “It would not be rational to admit a system of axioms and not accept its implications (principle of consistency), but it is still an open question whether rationality should be defined on the basis of criteria relating only to random choice, or following criteria which are independent of all consideration of random choice.” 

Morgenstern: utility theory is to be applied to normal circumstances, where the individual knows the situation we talk about. In game theory, we start with assumption that higher payoff is better, then derive the rational behavior. But we have to not deal in ranges that we know humans can’t cope with (e.g. comparing very small probabilities).

Morgenstern: Incidentally this is a further comment on the naivete of the so-called 'revealed preference' theory (Morgenstern, 1972). If one goes outside the range of normal experience of the individuals questioned, it becomes also clear that statements about their alleged consideration of variance, skewness, first, higher moments, etc., are subject to the same doubts as their gross 'decision' noted above. This matter is treated competently by Y. Amihud in this Volume (p.149) and I fully agree with his observations.

Morgenstern: This also takes care of the matter whether those questioned would 'correct' their behavior if it were pointed out to them that they ‘act’ in violation of the expected utility hypothesis. That theory, as formulated by the von Neumann-Morgenstern axioms, is normative in the sense that the theory is 'absolutely convincing' which implies that men will act accordingly. If they deviate from the theory, an explanation of the theory and of their deviation will cause them to readjust their behavior. This is similar to the man who tries to build a perpetuum mobile and then is shown that this will never be possible. Hence, on understanding the underlying physical theory, he will give up the vain effort. Or, an individual making a mistake in, say, long division, will clearly correct himself when shown the mistake. Naturally, it is assumed that the individuals are accessible intellectually whether it be physics or arithmetics or utility that is being explained to them. In that sense there is a limitation since there are certainly persons for whom this is impossible. Whether they then should be called 'irrational' is a matter of taste.

Amihud, A reply to Allais: displays a desire for correct predictions of the theory (towards risky choices), admits that UT predicts poorly but criticises Allais whose theory is not shown to predict better.
\end{quote}

About the application of the theory to “normal” circumstances, Morgenstern’s defense could be considered somewhat similar to the view of validation by Von Winterfeldt and Fischer (above), according to which you ought to test the principles on easy choices and just assume by faith that they extend beyond those easy choices. Morgenstern seems to consider that 1) indeed utility theory will pass the tests on easy choices (called “normal circumstances”, which might extend somewhat beyond Von Winterfeldt and Fischer’s easy choices, but is also left undefined), but 2) that UT should not be applied at all beyond those. (Other interpretations are probably possible however.)

About proper validation, let us consider a situation where UT, properly applied, suggests something that the DM is not a priori convinced is a good idea. Then, Morgenstern suggests the practicioner should explain that “they ‘act’ in violation of the expected utility hypothesis”. Assume the DM is still unconvinced. Now I see two possible interpretations of the position of Morgenstern. 1) the DM ought to be called “irrational”, or any other word that means that the DM is intellectually in the same position than someone who does not understand where their fault lies in a wrong computation (or, perhaps, the practitioner should be considered not a good educationist). Or 2) this would be a falsification of UT, that Morgenstern predicts will never happen. This second interpretation might seem too charitable, but it looks plausible to me, using two points: a) Amihud cites Morgenstern when saying that he has been “taught that ‘the aim of a good theory is prediction, and in prediction lies the ultimate test of its validity’ (Morgenstern (1972), p.704).” and b) Morgenstern declares he agrees with Amihud in his text above.

This article defines precisely tests similar to those Amihud might have had in mind, and proposes to select those theories that pass those tests.

This article proposes to see (a part of) the disagreement between Allais and the utilitarists as a controversy that is to be solved empirically.

\subsection{Slovic \& Tversky}
Slovic, Tversky - Who Accepts Savage's Axiom? (1974)

\begin{quote}
The authors compares the convincing power of two arguments, one in favor of Allais, the other one in favor of Savage. The article exhibits in its conclusion a hypothetical dialog between a utilitarist and a non-utilitarist. The argument used by the utilitarist is that a UT approach will be able to convince the DM, provided sufficient explanations are given to it, so it is prescriptively correct. The opposed argument is that this might be more brain-washing than explanation. The article does not propose a way to settle this debate.
\end{quote}

In this article we tried to do precisely this: give a way of settling this kind of debate. By giving all parties the right to counter-argue, we think we can escape the allegation of brain-washing while giving subtle theories the chance to argue in favor of their principles.

\subsection{The problem of lability}
Knowing what you want: Measuring labile values In Wallsten T.,(Ed.), Cognitive processes in choice and decision behavior (pp. 117–141), Fischhoff, Slovic, \& Lichtenstein, 1980
\begin{quote}
“subtle aspects of how problems are posed, questions are phrased and responses are elicited can have substantial impact on judgments that supposedly express people’s true values. Furthermore, such lability in expressed preferences in unavoidable: questions must be posed in some manner and that manner may have a large effect on the responses elicited.”

“The moral of these results is disturbing: Invariance is normatively essential, intuitively compelling, and psychologically unfeasible. Indeed, we conceive only two ways of guaranteeing invariance. The first is to adopt a procedure that will transform equivalent versions of any problem into the same canonical representation. This is the rationale for the standard admonition to students of business, that they should consider each decision problem in terms of total assets rather than in terms of gains or losses (Schlaifer, 1959). Such a representation would avoid the violations of invariance illustrated in the previous problems, but the advice is easier to give than to follow. Except in the context of possible ruin, it is more natural to consider financial outcomes as gains and losses rather than as states of wealth. Furthermore, a canonical representation of risky prospects requires a compounding of all outcomes of concurrent decisions (e.g., Problem 4) that exceeds the capabilities of intuitive computation even in simple problems. Achieving a canonical representation is even more difficult in other contexts such as safety, health, or quality of life. Should we advise people to evaluate the consequence of a public health policy (e.g., Problems 1 and 2) in terms of overall mortality, mortality due to diseases, or the number of deaths associated with the particular disease under study?

Another approach that could guarantee invariance is the evaluation of options in terms of their actuarial rather than their psychological consequences. The actuarial criterion has some appeal in the context of human lives, but it is clearly inadequate for financial choices, as has been generally recognized at least since Bernoulli, and it is entirely inapplicable to outcomes that lack an objective metric. We conclude that frame invariance cannot be expected to hold and that a sense of confidence in a particular choice does not ensure that the same choice would be made in another frame. It is therefore good practice to test the robustness of preferences by deliberate attempts to frame a decision problem in more than one way.”
\end{quote}
We could study how our approach might be used to overcome problems highlighted here above. Using different frames as counter-arguments, one can study, using our framework, which are the suggestions which better resist re-framing. (To be developed…)

\end{document}
