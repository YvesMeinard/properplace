\RequirePackage[l2tabu, orthodox]{nag}%more warnings
\RequirePackage{silence}\WarningFilter{newunicodechar}{Redefining Unicode character}
\pdfgentounicode=1 %permits (with package glyphtounicode) to copy eg x ⪰ y iff v(x) ≥ v(y) from pdf to unicode data. 
\input{glyphtounicode}%nice copy from PDF
\documentclass[preprint, french, english, 11pt, authoryear]{elsarticle}%english main language
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{newunicodechar}%able to use e.g. → or ≤ in source
\usepackage{babel}
\usepackage{scrextend}
\frenchbsetup{AutoSpacePunctuation=false, SuppressWarning=true}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{color}
\usepackage{natbib}
\usepackage{doi}
\usepackage{hyperref}
\hypersetup{breaklinks, colorlinks, linkcolor=black, citecolor=black, urlcolor={blue!80!black}, bookmarksopen}
\usepackage{bookmark}% hyperref doc says: Package bookmark replaces hyperref’s bookmark organization by a new algorithm (...) Therefore I recommend using this package.
\usepackage{cleveref}
\newcommand{\protectforpdf}[1]{\texorpdfstring{\ensuremath{#1}}{#1}}
\bibliographystyle{abbrvnat}
\usepackage{etoolbox}
\apptocmd{\thebibliography}{\hfuzz=20cm\raggedright}{}{}
\usepackage[nolist,smaller,printonlyused]{acronym}
\begin{acronym}
\acro{DM}{Decision Maker}
\acro{WTP}{Willingness to Pay}
\end{acronym}
%which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200
\tolerance=2000
%accept overfull hbox up to...
\hfuzz=2cm
%reduces verbosity about the bad line breaks
\hbadness 5000
%reduces verbosity about the underful vboxes
\vbadness=1300

\onehalfspacing
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newcommand{\commentYM}[1]{\textcolor{green}{YM: #1}}
\newcommand{\commentOC}[1]{\textcolor{red}{OC: #1}}
\newcommand{\commentOCf}[1]{\textcolor{red}{\selectlanguage{french}{OC : #1}}}
\newcommand{\commentE}[1]{\textcolor{green}{RelecteurExterne: #1}}
\newunicodechar{ℝ}{\mathbb{R}}
\newunicodechar{≠}{\ensuremath{\neq}}
\newunicodechar{≤}{\ensuremath{\leq}}
\newunicodechar{≥}{\ensuremath{\geq}}
\newunicodechar{→}{\ifmmode\rightarrow\else\textrightarrow\fi}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{∪}{\cup}
\newunicodechar{∩}{\cap}
\newunicodechar{¬}{\ifmmode\lnot\else\textlnot\fi}
\newunicodechar{…}{\ifmmode\ldots\else\textellipsis\fi}

\newcommand{\adv}{\mathscr{N}}
\newcommand{\fadv}{\mathscr{N}_J}%fuzzy adv

\begin{document}
\title{Justification and decision sciences}

\author[ld]{Y. Meinard\corref{cor1}}
\author[ld]{O. Cailloux}
\cortext[cor1]{Corresponding author}
\address[ld]{Universit\'e Paris-Dauphine, PSL Research University, CNRS, UMR [7243], LAMSADE, 75016 PARIS, FRANCE}

\begin{abstract}
Decisions are a core subject matter for many economic theories and sub-disciplines, which can be collectively called “decision sciences”. This article aims at clarifying the normative status of practices that consist in using insights from decision sciences to support decision-making, by formulating recommendations. Although many clients requesting decision aid, many concerned stakeholders and the general public typically expect from applications of decision sciences to concrete problems that they should lead to recommendations $R$, in fact decision sciences obtain conclusions of the form $N ⇒_c R$. Such conclusions contain recommendations $R$ conditionned by the norms or normative conceptions $N$, through  an implication $⇒_c$, which holds true given a series of information about the context $c$. This article explores strategies deployed in the economic and philosophical literature to jump from $N ⇒_c R$ to $R$. We argue that these strategies fail, because they share a critical blindspot: they evacuate or trivialize the task to help the \ac{DM} to make up her mind about $N$. As an alternative to these attitudes, we introduce and recommend a higher level norm $\adv$, on the basis of which, in a given decision situation, a decision analyst can decide, together with her client, whether or not a given $N$ can be adopted. In order to identify this $\adv$, we admit that the point of this higher level norm is to allow to \emph{justify} the choice of a given $N$, and we identify a series of requirements that the notion of justification should embody. We then argue that endorsing $\adv$ in our scientific practice implies deploying an attitude that consist in:
\begin{enumerate}[label=\roman*.]
	\item Systematically display arguments in favor of the choice of the $N$ from which our recommendations derive;
	\item Actively elicit criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understand our own justifiability as unavoidably provisional.
\end{enumerate}
\end{abstract}

\begin{keyword}
Decision Aiding, Normative Economics, Legitimacy, Justification, Ethics of Operational Research
\end{keyword}

\maketitle

\section{Introduction}
Decisions are a core subject matter for many economic theories and sub-disciplines. In this article, we will use the loose phrase “decision sciences” to refer to all these economic approaches, which take decision-making as their main topic, ranging from operational research to social choice theory, through public choice theory, the microeconomic theory of choice, rational choice theory, multi-criteria decision aiding methodology, and so on.

Some of the studies gathered under this umbrella present themselves as purely academic contributions, concerned only with establishing scientific results. However, most decision sciences have practical applications, both in the private sector and in policy-making \citep{tsoukias_policy_2013,marchi_evidence-based_2016}. Such applications entail a call for knowledge to become advice, and purportedly scientific propositions to endorse the normative status of prescriptions. 
In this article, we want to clarify the normative status of such practices, which consist in using insights from decision sciences to support decision-making.

By talking about “normative status”, we mean that we want to clarify the extent to which these practices are indeed normative, and to articulate a normative account of them. 
The term “normative” will be taken here in a broad sense, to refer to practices that aim at recommending some actions. This understanding is admittedly broad, since it encompasses practices concerned with notions such as ethics, justice, the good and the just, and so on. 
Though broad, this understanding is not all-encompassing. In particular, it excludes purely positive or purely empirical attempts to capture the above mentioned notions. For example, empirical studies aimed at capturing what people in a given group mean when using the term “justice”, as examplified by \citet{gaertner_empirical_2012}, does not fall within our definition of a “normative” inquiry. Besides, we will be concerned here only with recommendations, and will leave aside more binding or constraining normative notions such as obligation.

Based on this understanding of “normative”, the issue articulated above in terms of “normative status” refers to the following difficulty. When analysts use decision sciences to tackle a given concrete problem, they are commonly expected by their clients, concerned stakeholders and the general public to formulate recommendations $R$. However, in fact the analysts' conclusion in such a situation is typically not a self-standing $R$, but rather an implication $N ⇒_c R$, which holds true given a series of information about the context $c$. Such conclusions contain recommendations $R$ conditionned by norms, normative conceptions or value judgments $N$: accepting  $N$ leads to accepting the recommendations, whereas rejecting $N$ does not lead to any recommendation. In this formal representation, the “$⇒_c $” symbol represents what one might call the “technical” aspects of the decision-aid, consisting, among others, in data elicitation and analysis, model parametrization, mathematical formulations and calculi, simulations, sensitivity analyzes, and so on.

\begin{example}[Cost-Benefit Analysis (CBA)]
Let us introduce a simple example, which will be used in the entire article to illustrate various importants steps of our reasoning. Imagine that a decision analyst is asked by a \ac{DM} to help him to decide whether or not he should implement a given project $P$. The analyst uses cost-benefit analysis \citep{layard_cost-benefit_1994} and ends-up formulating a recommendation $R$ = “P should be implemented”. This recommendation is not unconditional. Thanks to her precise analysis of the context $c$ and her computations, the analyst derives $R$, through $⇒_c $, from norms $N$, entrenching the relevance of using cost-benefit analysis to decide whether $P$ should be implemented or not. Some of these norms characterize fundamental philosophical or ethical stances, such as “preference utilitarianism”: the norm stipulating that aggregate welfare, as measured by individual preferences, should be maximized  \citep{meinard_ethical_2016}. 
But $N$ also encompasses other, more or less clearly articulated norms referring to the usual requirements for a CBA to be considered to be ``properly'' implemented, such as the claim that the preferences taken into account in the study are the relevant ones to base the recommendation on, the claim that no important aspect has been forgotten among the aspects included as costs and benefits, the claim that the preference elicitation methods used actually capture the right kind of preference for the problem, etc.
\end{example}

In real-life decision-aiding practice, identifying the $R$, $N$ and $⇒_c$ parts in the conclusions of decision analyses, and thereby articulating these conclusions in the form $N ⇒_c R$, might prove extremely difficult, and possibly sometimes impossible. This is mainly because some of the concepts used to articulate decision scientific reasonings and results (which are encapsulated in the symbol $⇒_c$ in our formalism) are, at least according to some authors such as \citet{mongin_value_2006} and \citet{baujard_value_2013}, intermingled with norms (or “value-judgments” to use the latter authors' terminology). In the present article, we will leave these issues aside and admit that the retranscription in $N ⇒_c R$ form is possible, at least  in theory. Our reasoning will be mostly focused on tightly formalized cases where $N$ can take the form of an axiom or a set of axioms. With due caution we will, however, strive to draw more general conclusions, applicable to other sorts of $N$.

The retranscription in $N ⇒_c R$ form is useful because it allows to define the normative status of a given application of decision sciences as the attitude of the decision analyst towards $N$ in this application. In the present article, we will explore some of these attitudes, exemplified in the economic and philosophical literature. We will see that these various attitudes share a critical blindspot: they evacuate or trivialize the task to help the \ac{DM} to make up her mind about $N$.

By contrast, we claim that this task is pivotal. In order to accomplish it, we argue that decision scientists should endorse an “higher level” norm $\adv$, embodying the requirement to produce \emph{justifications}. We call $\adv$ a “higher level” norm because $\adv$ can be used to establish if this or that $N$ can be used in a given application of decision sciences, but in itself $\adv$ is too abstract for any $R$ to be derived from it in the absence of any additional $N$. Notice that we use here a comparative term (“high\emph{er}”), because our point is simply that $\adv$ does not play the same role as $N$, and places itself “upstream” $N$. Elaborating a precise and complete typology of norms falls beyond the scope of this article.

We flesh out $\adv$ as a series of four simple rules that applications of decisions sciences should follow if they set themselves the requirement to duly integrate the need to help the \ac{DM} to make up her mind about $N$. 

The immense literature on the normative underpinnings of economic science \citep{buchanan_positive_1959,sen_nature_1967,dwyer_scientific_1985, heath_value_1994,mongin_value_2006,sen_idea_2009,baujard_value_2013} tackles issue which are, to some undeniable extent, linked with the ones that we explore here. However, the applied literature still expresses diverging stances on these matters \citep{spash_bulldozing_2015, scharks_dont_2016}, which suggests that clarifications are still needed, especially when it comes to the practice of producing recommendations, as opposed to the theoretical aspects on which the above literature is mainly focussed (\citet{baujard_value_2013} being a noticeable exception).

This article is an attempt in that direction. It is divided into four parts. Following the present introduction, section 2 explores three attitudes with respect to $N$ and $N ⇒_c R$ which one can find in the economic and philosophical literature. In section 3, we introduce and argue for endorsing $\adv$. Section 4 concludes.

\section{Varieties of attitudes with respect to \protectforpdf{N}}
\label{sec:existing}
\subsection{Elusive economic attitudes with respect to \protectforpdf{N}}
\subsubsection{\protectforpdf{A1}: agnosticism about \protectforpdf{N}}
A widespread vision among economists is that economics is a value-neutral, purely scientific endeavor. This approach admits that value-judgments are essentially non-scientific, and that economics as a science should therefore eliminate them. This vision suggests a first attitude, $A1$, which consists, for the economist, in sticking to conclusions of the form $N ⇒_c R$, and letting \acp{DM}, or even “society” in general, decide of their attitude towards $N$ on their own. Deriving $R$ thus lies, in this attitude, outside the scientific part of the endeavor. 

Being completely agnostic about $N$, $A1$ could be applied to any norm, however absurd or blatantly immoral, still leading to conclusions of the form $N ⇒_c R$. Such an attitude would certainly produce hoards of results that would not be of interest to anyone. $A1$ accordingly does not capture what most researchers in economics, decision sciences, or related fields do.

\subsubsection{\protectforpdf{A2}: the quest for “self-evident” \protectforpdf{N}}
In order to overcome this problem, a natural amendment of $A1$ is to confine the inquiry to norms which are clear and largely accepted enough for \acp{DM}, or society, to decide, without the help of science, that they endorse them. Let us call such norms “self-evident”.
This approach defines a second attitude, $A2$: science obtains conclusions of the form $N ⇒_c R$, and $N$ is self-evident, therefore, $R$ holds.

Identifying such self-evident $N$ however proves more difficult than one might expect, for two reasons.

First, typical candidates for such norms in the literature are axioms that, under their technical, decontextualized expression, may appear convincing. But once they are applied to concrete contexts, one soon realizes that, in their concrete formulation, they remain convincing only if very restrictive conditions are fulfilled. To illustrate this idea, let us take the strong Pareto principle, stating that state of affairs $y$ is better than $x$ if no one is worse-off in $y$ as compared to $x$, and at least one person is better-off in $y$ as compared to $x$. This is undeniably a normative axiom, but most authors present this normativity as “minimal”, in the sense that it seems innocuous to admit that most people, if not everyone, accepts this normative principle. According to this argument, the strong Pareto principle would hence be a “self-evident” $N$. However, this claim is more debatable than most authors seem to admit, as emphasized by \cite{sen_rationality_2004}, among others. \commentYM{je check} Take for example a slightly unequal situation $x$ where individual $i$ is quite well-off whereas individual $j$ is poor. Compare with situation $y$ where $i$ receives a bonanza and $j$'s situation is unchanged. $y$ Pareto dominates $x$, but is considerably more unequal. The idea that everyone would claim that $y$ is better than $x$ is far from self-evident. It relies on questionable assumptions about a total absence of aversion to inequality and envy. The Pareto principle hence no longer appears self-evident when applied to wealth, and only retrieves its self-evidence if it is applied to some aggregated welfare index integrating aversion to inequality and envy. This dispute could be reproduced \emph{ad infinitum}: one might identify some concrete situations where the Pareto principal no longer appears self-evident when applied to the chosen aggregated welfare index, but retrieves its self evidence if yet another dimenson is integrated, and so on. Accordingly, the only version of the Pareto principle that one might safely consider self-evident is the thoroughly abstract version admitting that all the possibly relevant dimensions are taken into account. But such a thoroughly abstract version is not the kind of $N$ that allows to derive $R$s. One thereby sees how difficult it might be to set the situation so as to render it evident that everyone will agree on the Pareto principle when applied to a concrete context (\citet{mongin_axiomatisation_2003} and \citet{baujard_bien-etre_2015} articulate a similar point by arguing that axiomatic approaches are “purely syntactic” approaches, “without a semantics” liable to guarantee that their seeming convincing in the abstract implies that they will appear convincing in concrete settings). Therefore, one cannot claim without further ado that the strong Pareto principle is self-evident, and a similar reasoning holds for similar axioms, seemingly “self-evident” in the abstract \citep{sen_maximization_1997}.

Second, accepting some norms logically entails accepting their implications, but it is not evident for an individual to know whether all the implications of some norms are acceptable for her. To illustrate this idea, consider \citeauthor{arrow_social_2012}’s \citeyearpar{arrow_social_2012} caracterization of the dictator rule (we thank Ulle Endriss for this example). Arrow's argument is based on axioms that are liable to be endorsed by most readers. The argument shows that the Dictator rule is caracterized (in some formal context) by the axioms of Universal Domain, Pareto Dominance, and Independence of Irrelevant Alternatives. It is easily imaginable that non-expert individuals would willingly accept each of these axioms as capturing value-judgments they endorse about what they demand from a voting rule, if the axioms were explained to them by focusing only on what each axiom demands separately. The point of Arrow's theorem, and the reason why this result is so powerful, is that a series of axioms which all appear acceptable yields dictatorship, which our imaginary individuals would certainly reject. A natural way out of the conundrum is to question the spontaneous adherence to the axioms, which prove, on due reflection, to be less commendable. The example of the Dictator rule therefore shows that one cannot rest content with the bare fact that a norm $N$ seems self-evident in the abstract, since one can be led to reject a seemingly self-evident $N$ on due reflexion, once one has come to realize some of $N$'s implications.

\subsubsection{\protectforpdf{A3}: choosing \protectforpdf{N} that decision-makers “would endorse if he could understand”}
$A1$ and $A2$ are two attitudes whereby economists claim to use decisions sciences while leaving $N$ outside the purview of their scientific inquiry. We have argued that both attitudes fail because they are predicated on a implausible premisse: that \acp{DM} do not need the help of decision sciences to make up their mind about $N$.

By contrast, a third attitude, $A3$, consists in claiming that, when articulated in the form of axioms, the \acp{DM} cannot systematically take the time to strive to understand $N$ or are not always willing or able to do so. Decision scientists holding this attitude admit that they have the collective skills to understand axioms and discuss among peers whether this or that axiom should be accepted or not. But they do not consider that \acp{DM} should take part in such discussions, for the simple reason that these are technical, difficult discussions. When they arrive at conclusions $N ⇒_c R$, where $N$ encapsulates axioms that decision scientists collectively deem commendable, they consider themselves entitled to jump to $R$ without bothering to help \acp{DM} to make up their mind about $N$. Indeed, this would be a waste of time and energy. At most the decision scientist will invest some time to explain to the \ac{DM} why it was a good idea to endorse $N$, or will content himself to think that, if the \ac{DM} were able to understand the axioms, he would endorse them.

\citet[p. 180]{morgenstern_reflections_1979} might be considered as a supporter of $A3$, depending on the interpretation of his text. He writes that: 

\begin{addmargin}[3em]{3em}
“\emph{the expected utility theory (...) as formulated by the von Neumann-Morgenstern axioms, is normative in the sense that the theory is ‘absolutely convincing’ which implies that men will act accordingly. If they deviate from the theory, an explanation of the theory and of their deviation will cause them to readjust their behavior. This is similar to the man who tries to build a perpetuum mobile and then is shown that this will never be possible. Hence, on understanding the underlying physical theory, he will give up the vain effort. Or, an individual making a mistake in, say, long division, will clearly correct himself when shown the mistake.}” 
\end{addmargin}
If understood as referring to a usage of expected utility theory aiming at producing recommendations, this excerpt embodies attitude $A3$: it takes it for unquestionable that anyone should be convinced by expected utility theory. (Notice, however, that this writing can also be interpreted as referring to a purely mathematical version of utility theory that does not lead to any recommendations, and therefore falls outside the scope of the present article.)

Attitude $A3$ consists, for the decision scientist, in endorsing a higher-level norm $\mathscr{N}_{A3}$ that consists in claiming that expert discussions about norms among decision scientists entitle them to make decisions about norms on behalf of \acp{DM}. Such a norm $\mathscr{N}_{A3}$, which embodies what \citet{estlund_democratic_2009} calls “the expert/boss fallacy”, is quite questionable, and it is likely that few decision scientists really wholeheartedly endorse it. Besides, to our best knowledge it is left unspecified in the literature what is precisely required (when adopting  $\mathscr{N}_{A3}$) for an expert to decide that “enough” discussion has taken place in the expert community and that a consensus has been reached that a given $N$ should be accepted. 

\subsubsection{\protectforpdf{A4}: informally testing whether decision-makers endorse \protectforpdf{N}}
The blatant weaknesses of $A3$ suggest a pragmatic variant, $A4$. This is the attitude of decision scientists who reject $A3$'s idea that decision scientists can decide about $N$ on behalf of \acp{DM}, and therefore make a point to informally discuss the meaning of $N$ with \acp{DM} to verify that they agree that the specifics of the situation are such that $N$ appears endorsable to the \acp{DM}.

\citet{roy_multicriteria_1996} is a prominent supporter of A4. As another example of this attitude, one can think about \citet{raiffa_back_1985}’s claim that, in some cases, discussions with \acp{DM} rejecting subjective expected utility theory can lead them to accept it after all.

The problem with $A4$ is that is strangely combines a scientific approach to arrive at $N ⇒_c R$, with an informal, loose approach to lead \acp{DM} to make up their mind about $N$. Like $A3$, it is anchored in a higher level norm $\mathscr{N}_{A4}$. But this higher level norm is not clearly articulated. It encapsulate the idea that decision analysts cannot make decisions about $N$ on behalf of \acp{DM}, but does not specify precisely what they should do.

\begin{example}[CBA (Continued)]
Let us simply illustrate the meaning of attitudes $A1-4$ in our hypothetical scenario of an application of CBA.

$A1$ admits that the task for the analyst is to compute a CBA, but does not account for the reason for her to choose a CBA. It might be, for example, that the \ac{DM} requested decision-aid through a public procurement procedure specifying that CBA should be used. The analyst complies and remains agnostic about the $N$ underlying CBA.

$A2$ would mean, for the analyst, that she admits that preference utilitarianism a self-evident, in the sense that most \acp{DM} if not all will accept it.

$A3$, by contrast, acknowledges that \acp{DM} can find it difficult to understand the meaning of this $N$, and might be be at a loss trying to decide whether or not they should endorse it. An analyst adopting $A3$ would hence fall back upon a community of researchers endorsing $N$ to take the decision to endorse $N$ on behalf of \acp{DM}.

Lastly, an analyst adopting $A4$ would find $A3$ inacceptable, and would informally strive to discuss with the \ac{DM} to help him decide whether or not he endorses $N$. But to accomplish this task, the analyst will be left without a rigorous methodology.
\end{example}


\subsection{Elusive strategies to clear \protectforpdf{N} from value judgments}
We have argued in the former subsection that the attitudes currently found in the economic literature are unsatisfactory. $A3$ and $A4$ however suggest an interesting solution, which consists in referring to a higher level norm. The philosophical literature contains some interesting, deeper explorations of this idea, in particular in debates on “pure procedural” vs. “substantive” approaches to democracy and political legitimacy.

Substantive theories claim that democracy is a matter of value judgments. An example of such an approach is \cite{brettschneider_value_2006}, who claims that democracy is first and foremost a set of “core values”, which can be materialized in the proceedings of constitutional courts just as well as in votes and institutional proceedings more usually called “democratic”. As opposed to substantive theories, purely procedural theories claim to account for democracy by delineating formal properties of decision-making procedures that are supposed to be purely value-neutral, and from which democracy would emerge. (Notice that this debate should not be conflated with the debate opposing “output” vs. “input” theories of legitimacy \citep{vatn_environmental_2016, backstrand_environmental_2010}: proponent of an input theory of democracy claim that, if a decision has been taken through democratic procedures, then it is democratic, whatever its output; proponents of output theories take the opposite stance).

In our formalism, substantive theories claim that $N$, in order to be powerful enough to permit stating $N ⇒_c R$ for $R$s talking about democratic credentials, must contain value-judgments. Whereas purely procedural theories claim that it is possible to obtain $N ⇒_c R$ without $N$ containing value-judgments. The purely procedural approach can hence be seen as another strategy, $A5$, allowing to obtain $R$ from $N ⇒_c R$, this time by claiming that $N$ does not contain value-judgments after all, and can therefore innocuously be accepted. $A5$ is the strategy deployed in a couple of historical cornerstones of contemporary political philosophy: \cite{rawls_political_2005} and \cite{habermas_moralbewustsein_1983}. Let us examine whether $A5$ proved more powerful than $A1-4$.

\cite{rawls_political_2005} did not want his theory to make any value-judgment about the kind of state of affair that should prevail in a democratic society. He therefore argued that a policy is democratically legitimate if it is based on a constitution whose justification is acceptable by all  “reasonable” citizens. But he did not want to make value-judgments about democratic processes either. He therefore further argued that the very definition of reasonableness should be something for reasonable citizens to pick-up. He thereby attempted to eschew making any value-judgments in his account of legitimacy and reasonableness. This was supposed to be a complete ``flight from substance'' \citep{estlund_democratic_2009}, in the sense that this account was supposed to eschew any value-judgment, whatsoever. If this reasoning were successful, it would allow to derive $R$ from $N ⇒_c R$ by removing the value judgments from $N$, rendering it innocuous to endorse.

This approach fails, however, for reasons articulated most prominently by \cite{habermas_reconciliation_1995} and \cite{estlund_democratic_2009}. \citet{estlund_democratic_2009} noticed that, if one admits, following Rawls, that the notion of reasonableness should be selected by reasonable people themselves, there is an “impervious” plurality of groups that could select themselves as being “reasonable”. He concluded that rawlsian political philosophers have no choice but to make bold claims about the content of the concept of reasonableness. \cite{habermas_reconciliation_1995} criticizes Rawls' presentation of his notions of the “veil of ignorance” and the “overlapping consensus” as \emph{devices} whose real-life functionning can give rise to principles of justice. According to \cite{habermas_reconciliation_1995}, these notions are rather rhetorical tools thanks to which Rawls exposes principles of justice that he deduces from various philosophical notions, such as the one of a moral person, which Rawls presupposes. Rawls' flight from substance hence abruptly collapses in a retreat back to the substantial inquiry into the nature and features of a moral subject.  Rawls' attempt is therefore the paragon of the failure of the flight from substance (which is neither a logical flaw nor a failure to unveil illuminating insights, but a failure to strip the argument from its normative anchorage, or “substance”). His theory is anchored in a higher level norm $\mathscr{N}_R$, but this higher level norm is not thematized as such in his philosophy.

By contrast, in his debate with Rawls on the theory of justice, Habermas goes a step further by analyzing the higher level norm underlying his own theory (though he does not uses this vocabulary). \cite{habermas_moralbewustsein_1983}'s “weak” transcendental deduction of the tenets of “discours ethics” from communicative action is particularly interesting in this respect. \citet{habermas_theorie_1981} argues that agents communicating with one another make validity claims of three sorts: veritative claims about truth, normative claims about values and norms, and authenticity claims about expressions concerning their inner life, feelings and conciousness. The role that norms play is therefore clearly circumscribed in Habermas' framework, and it concerns one kind of validity claims among others. \cite{habermas_moralbewustsein_1983} does not locate the tenets of “discours ethics” at this level. He rather argues that all the acts and deeds that consist in making validity claims are oriented by a strive for intercomprehension, which lies at the core of communicative action. And he identifies the tenets of discourse ethics as conditions of possibility for this intercomprehension-oriented activity. On the face of it, Habermas' reasoning therefore seems to provide the means to eschew the task to help the \acp{DM} to make up their mind about norms. Indeed, he identifies an “ethics”, which is presumably something that allows to identify what ought to be done, or to formulate recommendations, and the tenets of this “ethics” are such that it would be pointless to expect \acp{DM} to make up their mind about them, because these tenets are conditions of possibility for a very basic, all-pervasive structure of human action. Like $A3$, Habermas' approach is therefore anchored in a higher level norm, $\mathscr{N}_{H}$, capturing the tenets of discours ethics. A formulation of this higher level norm is: “For a norm to be valid, the consequences and side effects that its general observance can be expected to have for the satisfaction of the particular interests of each person affected must be such that all affected can accept them freely” \citep{habermas_moralbewustsein_1983}. Just like $\mathscr{N}_{A3}$, this higher level norm does not allow directly to deduce recommendations $R$. But as opposed to proponents of $A3$, Habermas provides foundations to entrench his $\mathscr{N}_{H}$. 

These foundations are, however, derived from his very specific understanding of communication and its importance in the functioning of human societies, which has been extensively criticized in the literature \citep{heath_communicative_2001,honneth_kritik_1985}. 

By anchoring itself in a higher level norm $\mathscr{N}_{A3}$, $A3$ paves the way for a satisfactory solution to our problem in this article. $A4$ overcomes $A3$'s shortcomings by pointing the need to find a better higher level norm than $\mathscr{N}_{A3}$, but fails to articulate one. Similarly, Rawls' approach is anchored in a higher level norm $\mathscr{N}_{R}$ that he fails to account for. Habermas goes a step further by entrenching his higher level norm $\mathscr{N}_{H}$ in his philosophy of society. In the sections to come, our aim is to follow this lead and identify a more relevant higher level norm $\adv$, which is more fitted to our object (viz, applications of decision sciences), and is not derived from Habermas' disputed vision of communicative action.

\section{The recommended model}
\subsection{Justification}
In this section, our aim is to identify a higher level norm $\adv$, on the basis of which, in a given decision situation, a decision analyst can decide, together with her client, whether or not a given $N$ can be adopted. In order to identify this $\adv$, let us admit that the point of this higher level norm is to allow to \emph{justify} the choice of a given $N$.

This reference to the notion of \emph{justification} echoe contemporary debates on the role of scientific expertise in policy making, which is often enough presented as undergoing a crisis of \emph{confidence} \citep{godard_environnement_2015}. As a response, many expertise settings, proceedings and institutions have evolved (in more or less successful attempts to restore the lost confidence) to increase their \emph{transparency}, \emph{pluralism} and \emph{independence}. These three criteria are largely accepted as requirements to impose on any expertise. However, they cannot be considered as absolute and applicable in all situations. As \citet{godard_environnement_2015} points out, in some situations, an excessive transparency can cripple expertise, and independence is, in many respects, unachievable: every expert has its interests, an uninterested expert is a chimera. Similarly, pluralism denies the very idea that expertise can have a point, if it means that all opinions, however fanciful or extremist, should be given the same weight. Accordingly, these three criteria are better conceived as implications of a more fundamental principle: the need to justify expert opinions. \citet{godard_environnement_2015} p. 379 mentions this idea in passing, in the case of independence: “the right question is not `tell me to whom are you tied', but `tell me which arguments justify your opinion' ”. But a similar rationale applies to the other two criteria: the point of requiring transparency is to render visible the justifications underlying the various expert opinions, or the lack thereof; the point of pluralism is to expose justifications to a large sample of counterarguments, as diverse as possible.

These contemporary debates hence illustrate that the requirement, for decision analysts, to justify themselves, is often taken as a self-evident, unquestionable premise. One might even argue that a willingness to justify is a necessary condition for decision scientists to present themselves as \emph{scientists}. This pervasive reference to the notion of justification requirement is, however, much too vague. Indeed, the term ``justification'' is extremely polysemous. In some contexts, one might call any argument, however spurious or ill-conceived, a ``justification''. Even if one admits that a purported justification deserves to be called so only if it comes up to some ``standards of quality'' of some sort, the term ``justification'' remains underdetermined, and could mean very different things depending on the nature of the standards at issue.

Our agenda in this section is to start with the notion of justification in general, admitting that, at this level of generality, a justification requirement is innocuous, and to progressively clarify and flesh out a concrete notion of justification. Such a concrete notion should no longer be ambiguous, and should allow us to identify a satisfactory $\adv$. To that end, our approach will be similar to the one typically used in ordinary language philosophy: we will draw on everyday intuitions about the meaning of the term ``justification'', and strive to progressively sharpen a specific definition that the term should take in order to play the role that we want it to play, in the very specific context in which we want to use it. To do so, we will take advantage of the arguments developed above against the various attitudes presented in the former section. Using the terminology of ``justification'', these arguments can be summarized by saying that these attitudes are anchored in higher level norms that provide \emph{unsatisfactory justifications} for norms $N$ to adopt in various decision situations, in some yet unclarified understanding of the phrase ``unsatisfactory justification''. Drawing on these arguments will allow us to clarify the language intuitions underlying the idea that the flaws of the above attitudes testify for their being \emph{unsatisfactory justifications}. This, in turn, will allow us to sharpen our understanding of what the idea of a \emph{satisfactory justification} means for our purposes.

In the two subsections below, using this methodology, we identify a series of requirements that the notion of justification should embody (these subsections draw on provisional ideas introduced by \citet{meinard_du_2013, meinard_what_2017}). The third subsection then presents a set of practical rules that materialize these requirements and participate in fleshing them out. These practical rules specify the attitude that a decision analyst should have, if he sets himself the task to produce \emph{satisfactory justifications} for the choice of $N$ grounding his $R$.

\subsection{Three requirements}
A first, almost trivially unadapted notion of justification should be eliminated straightaway. This is the extremely large notion (already mentioned above) that would call ``justification'' any discourse or set of arguments designed to buttress the choice of a given $N$, whatever its characteristics, independently of any standard of any sort (standards of clarity, rigorousness, convincingness and so on). In this extremely large understanding of ``justification'', the phrase ``unsatisfactory justification'' is a contradiction in terms, and the idea that the attitudes explored in the former section exemplify ``unsatisfactory justifications'' is void. This first notion of justification is hence to be eliminated because, in this understanding, a justification requirement is void.

We hence need a notion of justification that integrates criteria: not everything can be a justification. But what criteria should one use? Our discussion of the higher level norms $\mathscr{N}_{A3}$, $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$ illustrates how difficult this question is. All three higher level norms specify, more or less explicitely, criteria to decide if a $N$ should be chosen. Here we introduce three requirements encapsulating the criteria that, we argue, are relevant to capture the notion of justification that we need.

\subsubsection{Incrementalism}
As we have seen, $\mathscr{N}_{A3}$ encapsulates a criterion: $N$ should be considered consensual among decision scientist experts. $\mathscr{N}_{A3}$ presupposes that this criterion is clear and determined. However, one cannot find, in the literature, any elaboration of how this criterion is supposed to be checked. This blindspot obfuscates the idea that such a consensus, if it existed, would certainly evolve as decision science knowledge improves. A more satisfactory version of $\mathscr{N}_{A3}$ would hence clarify the meaning of this criterion, and would thereby in particular highlight that the content of the criterion is liable to change as knowledge improves, incrementally. The same idea applies to $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$. We have seen that the former is anchored in an implicit philosophy of the moral subject, and the latter in a theory of society. But both theories can be questionned, and more satisfactory versions of $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$ should admit and openly display their provisional status (\cite{habermas_moralbewustsein_1983} does emphasizes this point -- discussing whether this claim is coherent with the larger habermassian framework falls beyond the scope of this article).

This first analysis of part of the shortcomings of $\mathscr{N}_{A3}$, $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$ hence suggests the need to integrate, in our notion of justification, an \emph{incrementalism} requirement, holding that it is illusory to claim to be able to capture a definitive list of criteria defining what is a satisfactory justification. According to “incrementalism”, one had better work incrementally, to improve step by step one's understanding of the relevant criteria. “Incrementalism” reflects the idea that even experts have limited capacities to identify definitive solutions to the problems they are entrusted to tackle, and therefore their conclusions cannot be considered definitive solutions.

\subsubsection{Anchorage in real-life acceptability}
Another problematic feature that our exploration of $A3$ illustrated is that it conceives the elaboration and application of $\mathscr{N}_{A3}$ as tasks for decision scientists alone to tackle. By contrast, Rawls and Habermas wanted their theories to avoid granting to the philosopher (or to the decision scientist) the right to preempt discussions about $N$. Rawls introduced this idea thanks to his notion of the ``reasonable'', which \cite{estlund_democratic_2009} rearticulated at a more general level as an acceptability requirement. We have seen that, at least according to \cite{habermas_reconciliation_1995} and \cite{estlund_democratic_2009}, Rawls' argument is flawed. But a core idea underlying it remains, in our view, pivotal to elaborate a relevant notion of justification: this idea is that how people in the flesh receive and react to purported justifications should play a core role in deciding whether the latter qualifies as a satisfactory justification.

\subsubsection{Counterfactuality}
The latter requirement might suggest the following approach, inspired by the sociological literature on “orders of justification” \citep{boltanski_justification_2006}. According to this literature, various groups in various situations typically refer to different and largely irreconciliable “orders of justifications”, which can (according to some authors at least) be formalized as sets of normative axioms accepted by some groups but rejected by others.

Drawing on this literature, one could set out to use sociological surveys determining in which groups the people concerned by a given application of decision sciences fall, and produce recommendations justified by the axioms endorsed by those people in the situation at issue. Such an approach can be seen as a refinment of $A2$. This approach refines it by allowing for the case where different people find different norms self-evident, but it falls under the same problems than $A2$ by still requiring that people judge by themselves whether they consider some norms as self-evident. In particular, it might be that people accept some norms because they look acceptable, only because they have not realized all their implications.  In other words, it might be that some people accept a given set of axiom, as a matter of fact, but that, if they were confronted to counter-arguments challenging one or several of these axioms, they would change their mind and switch to another normative stance.

In order to integrate such reactions, we need a notion of justification that does not reduce the acceptability of justifications to the bare factual acceptance of discourses. This requirement obviously echoes \cite{habermas_reconciliation_1995}'s and \cite{estlund_democratic_2009}'s criticism of Rawls' notion of “reasonable”: if it is to make sense, Rawls' theory is not about justifications that real people usually accept or will accept, but about justifications that citizens \emph{would} accept, if they were reasonable. \citet{habermas_faktizitat_1992} forcefully emphazises this counterfactual aspect in his theory of legitimacy. Similarly, we have to undertand the notion of acceptability of a justification in a counterfactual sense. 

\subsection{Conjoining the three requirements: primacy of practice}
But how can one know that a justification is acceptable in this sense? We have seen above that \cite{estlund_democratic_2009}'s solution would consist, for the philosopher, in making bold claims about the truth of the criteria used to sort out what is acceptable and what is not. But a major problem with such an approach is that it contradicts our above requirements of \emph{incrementalism} and \emph{anchorage in real-life acceptability}. In order to overcome this problem, our proposal is that the relevant notion of justification should embody the following tenet of “primacy of practice”: instead of searching for acceptability criteria through theoretical reflection, one should take the stance that consists in putting justifications to the test in real-life situations, so as to improve gradually our blunt understanding of what it means for a justification to be acceptable.

In this approach, purported justifications deserve to be called so depending on whether they satisfy some criteria. These criteria are a matter of confronting purported justifications to their real-life acceptability by people in the flesh (echoing the \emph{anchorage in real-life acceptability} requirement). This acceptability is in turn not reduced to factual acceptance (echoing the \emph{counterfactuality} requirement). It rather refers to acceptance conditioned on purported justifications being put to the test, tentatively and iteratively (echoing the \emph{incrementalism} requirement).

\subsection{Unfolding practical rules}
Obviously enough, though our analysis in the former subsections allowed us to flesh out the notion of justification to some extent, it still is indeterminate in an important respect. We still have to flesh out more precisely what it means to ``put purported justifications to the test''. This subsection is devoted to describe a practical procedure that decision analysts should follow to do that. The features of this practical procedure are derived from the understanding of the notion of justification spelled out in the former subsections.

\citet{meinard_what_2017} attempted to elaborate a practical procedure of that sort in an exploration of the concept of legitimacy. Here we will translate some elements of this approach to our context, and also address what we take to be weaknesses, so as to unfold a more satisfactory account. Our proposed practical procedure will be articulated in four points.

A first requirement is designed to capture the idea that, as application of “primacy of practice”, our endorsement of $\adv$ should first and foremost take the form of our actually articulating justifications.

\begin{itemize}
\item[i.]	Systematically display arguments in favor of the choice of the $N$ from which our recommendations derive.
\end{itemize}

A second point should prevent our using justifications that happen to be accepted, as a matter of fact, at the moment when we articulate them, but whose weaknesses we sweep under the carpet. This point embodies “incrementalism” and ``counterfactuality'', by admitting that, once we have found arguments in favor of something, we should try to look for ways through which they could be discarded. Real-life examples of decision-aiding practices that flout this clause are given in \cite{meinard_what_2017}, which lead him to introduce a requirement to be ready to defend one's recommendations against criticisms, even when none are formulated. This requirement is insufficient, however. Indeed, an account associating it with clause [i] would be impaired by a worrying weakness, which can readily be identified by referring to the literature on epistemic injustice \cite{fricker_epistemic_2007} (this problem is not addressed by \cite{meinard_what_2017}). Some people and groups have access to knowledge, others have not. The former are in a position to articulate criticisms, the latter are not. By imposing that decision scientists should be ready to defend their recommendations, the above approach exposes decision science only to part of the spectrum from which criticisms can come. What if there are no criticisms addressed at us, whereas many could have been, but were not, because of epistemic injustices? Would we still feel confident in claiming that our approach materializes satisfactory justifications in such a case? We do not think so. There is therefore something amiss in the above account.

One might suggest that the problem could be fixed by identifying a specific group of people that should be the source of criticisms, or even a procedure that should be used to encourage the formulation of such criticisms. Such an approach would not work, because it is hopeless to believe that we can once and for all identify a relevant group of people (or set of groups of people) and/or a magical procedure.

``Primacy of practice” offers a solution to this problem. We cannot identify once and for all a perfectly relevant group of people and/or a perfect procedure. What we can do is identify an attitude that will be conducive to more satisfactory justifications, and this attitude is a requirement to actively elicit criticisms. This requirement is the missing element in our account to fix its first weakness.

\begin{itemize}
\item[ii.]	Actively elicit criticisms
\end{itemize}

We now need a third clause to allow clauses i and ii to fully embody “primacy of practice”, by putting justications to the test in real-life, instead of confining them to theoretical criteria.

\begin{itemize}
\item[iii.]	 Actively defend our recommendations against all criticisms
\end{itemize}

Clauses [i-iii] spell out the attitude of experts who would enact a willingness to justify themselves by displaying the arguments underlying their stances, and by actively being willing to face dissident stances. But this account, although completed to fix the weaknesses mentioned above, still has another worrying weakness, which can be captured by raising the question: when can one admit that one has produced \emph{enough} justifications? (This weakness was also ignored by  \citet{meinard_what_2017}.) Imagine that you have embarked in a discussion with a stakeholder who always has new criticisms to raise. In such a situation, in our logic, should one admit that you cannot stop the discussion at some point or another? This would give to your contradictor a serious advantage, which certainly is undue: if he is ill-intentioned, he can condemn you to indefinitely argue in vain.

We propose to solve this problem by applying ``incrementalism'' to the justifiability of the decision aiding process. When applied to the identification of criteria to sort out acceptable justifications from unacceptable ones, incrementalism means that one can never admit that one knows what the right criterion is: proposed identifications of ``the right'' criterion are always provisional. When applied to the implementation of steps [i-iii] spelled out above, incrementalism means that, when implementing [i-iii], the decision analyst deploys a provisional account of the justifiability of the decision aid she provides. The claim that she thereby makes does not amount to claiming that the decision aid is justified, in any absolute and definitive sense. It is a provisional claim. The decision analyst can claim that her decision aid is more justifiable than it would have been if she had not done this or that, while unfolding [i-iii].

Let us see how this approach solves the problem pinpointed above, in the imaginary situation where an ill-intentioned stakeholder endlessly raises new criticisms to sabotage the decision aiding process. In such a case, a decision analyst implementing our approach would unfold [i-iii] and stop at some point, claiming that her unfolding [i-iii] provisionally entrenches the justification of her decision aid in the situation at issue. This justification is provisional in the following sense. If another decision analyst or an external observer can prove that [i-iii] can be implemented more thoroughly by providing new arguments leading to question the decision analyst's rejoinder, possibly by integrating some arguments from the ill-intentioned stakeholder, then he would thereby show that a more justified decision aiding process can be implemented.

In concrete terms, applying incrementalism to the justifiability of the decision aiding process leads to add a fourth clause to our account.
\begin{itemize}
\item[iv.]	Understand our own justifiability as unavoidably provisional.
\end{itemize}

To sum up, the model that we recommend is that, as decision scientists implementing decision science in concrete situations so as to provide recommendations, we should:
\begin{enumerate}[label=\roman*.]
	\item Systematically display arguments in favor of the choice of the $N$ from which our recommendations derive.
	\item Actively elicit criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understand our own justifiability as unavoidably provisional.
\end{enumerate}

Clearly, applying the formula [i-iv] is unlikely to ensure that we will be able to identify \emph{the} ultimate justification for our recommendations. For that, we would need to have access to all the possible arguments, all the possibly relevant information, and we would need a perfect definitive definition of what is a satisfactory justification. Our account of $\adv$ embodied by [i-iv] should be seen as a \emph{second best} (see \cite{cailloux_formal_2018} for a first instantiation in a formal framework).

\begin{example}[Cost-Benefit Analysis (CBA)]
To illustrate the concrete meaning of our reasoning, let us see how it applies to our example a decision analyst using CBA to help a \ac{DM} to decide whether or not he should implement a given project $P$.

As application of clause [i], instead of simply using the chosen method without further ado, the analyst should take upon himself to clarify the norms $N$ underlying the usage of this method, and to explain to the \ac{DM}, his partners and concerned stakeholders why he deems it relevant to admit $N$ in the case at hand. An analyst who would skip this step, for example because using CBA was part of the requirements of the public procurement procedure through which he was chosen and he admits that he has nothing to say about the relevance of this requirement, would fail to abide by [i].

As application of clauses [ii] and [iii], the analyst should set the discussions with the \ac{DM}, his partners and concerned stakeholders in such a way as to forster reactions and elicit criticisms when it comes to this relevance of $N$. For example, if the decision aiding task is monitored, as part of a public procurement procedure, by a steering committee, the analyst should take advantage of the meetings with the committee to highlight possible reason both to accept and to reject $N$. If, thanks to his understanding of the local context, the analyst suspects that the structure of the steering commitee is biased against a given group of stakeholders, he should suggest to the \ac{DM} to enlarge the committee to include those groups or external experts, and thereby facilitate the emergence of possible criticisms coming from them. In the same vein, he should do his best to take advantage of the scientific literature to identify relevant arguments.  

Obviously enough, in some situations, the \ac{DM} will simply reject the analyst's attempts to discuss the relevance of $N$, or will turn a blind eye towards the analyst's request to expand the steering committee. Similarly, in some situations, any defense of $N$ or any alternative to $N$ will face a stubborn resistance by ill-intentioned people simply willing to sabotage the decision process. In such cases, the analyst will have to surrender at some point. So long as the analyst has done his best to abide by clauses [i-iii] in such hard cases, in the sense that one could not have done more, then he will have abided by [iv].  
\end{example}

\section{Conclusions}
In this article, we have introduced a normative account of the role of decision sciences and their applications. For that purpose, we have explored various strategies designed  to jump from $N ⇒_c R$ to $R$.

We have strived to demonstrate that all these appoaches fail, which has led us to recommend a higher level norm $\adv$, on the basis of which, in a given decision situation, a decision analyst can decide, together with her client, whether or not a given $N$ can be adopted. In order to identify this $\adv$, we have admitted that the point of this higher level norm is to allow to \emph{justify} the choice of a given $N$, and we have used an ordinary language philosophical methodology to identify a series of requirements that the notion of justification should embody. We have then presented a set of practical rules that materializes these requirements and participate in fleshing them out. We thereby ended up recommending the corresponding model for the proper role of decision sciences.

As decision scientists, we should:
\begin{enumerate}[label=\roman*.]
	\item Systematically display arguments in favor of the choice of the $N$ from which our recommendations derive;
	\item Actively elicit criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understand our own justifiability as unavoidably provisional.
\end{enumerate}

To ponder on this formulation, it is useful to mention two prominent objections that one might want to raise against our approach.

A first objection might come from decision scientists who would reduce our argument to a simple call for decision scientists to justify their recommendations, which, they might argue, is what decision scientists already do. This would miss an important aspect of our reasonings. Indeed, our rationale emphazises that recommendations necessarily rest on norms, and stresses that decision scientists cannot eschew the need to help \acp{DM} to make up their mind about those norms. Current practices address this issue informally, if at all. By contrast, we argue that it is necessary to anchor this important part of applied decision theory in a rigorous methodology, an objective to which this article proposes to contribute. To do so, we propose practical rules that decision scientists should follow in order to obtain justified recommendations. If followed, these practical rules will modify current practices.

A second objection might come from people who would claim that justification requirements command respect, but are impossible to implement in practice. Such critics would claim that, in practice, decision scientists have no choice but to pick up some norms $N$ to derive recommendations, and that any serious attempt to justify these norms would be impractical. Justification requirements would be impractical indeed, if they meant that any recommendation should be anchored in an “ultimate” justification. However, our reasoning is based on an incremental and provisional approach to justifications: the justifications that we are interested in are not ``ultimate'' in any sense, they are tentative and open to improvements. Identifying such provisional justifications is far more practical than pretending to capture ``ultimate justifications'', and we argue that it can be done in practice by following our proposed practical rules.

We hence see our contribution as an attempt to improve the scientific rigor of current applications of decision sciences, with concrete, practical implications. Although this article is, accordingly, undoubtedly very ambitious, we emphasize that it is also very modest in many respects. It does not provide a metric, no generally applicable mechanical means to compare any two applications of decision sciences without discussions. There is bound to be myriads of hard cases where one application of decision science will appear better than another on some respect, but worse on another respect.

%Avoids printing section numbers, but leaves entries in the TOC
\setcounter{secnumdepth}{0}
\section{Acknowledgements}
We thank Philippe Grill and Juliette Rouchier for powerful comments and suggestions on this manuscript.

\section{References}
\bibliography{properplace}
\end{document}
