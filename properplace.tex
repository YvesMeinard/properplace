\RequirePackage[l2tabu, orthodox]{nag}%more warnings
\RequirePackage{silence}\WarningFilter{newunicodechar}{Redefining Unicode character}
\pdfgentounicode=1 %permits (with package glyphtounicode) to copy eg x ⪰ y iff v(x) ≥ v(y) from pdf to unicode data. 
\input{glyphtounicode}%nice copy from PDF
\documentclass[preprint, french, english, 11pt, authoryear]{elsarticle}%english main language
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{newunicodechar}%able to use e.g. → or ≤ in source
\usepackage{babel}
\usepackage{scrextend}
\frenchbsetup{AutoSpacePunctuation=false, SuppressWarning=true}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{color}
\usepackage{natbib}
\usepackage{doi}
	\usepackage{etoolbox} 
	\makeatletter
	\patchcmd{\@doi}{http://dx.doi.org}{https://doi.org}{}{}
	\makeatother
\usepackage{hyperref}
\hypersetup{breaklinks, bookmarksopen, hidelinks}
\usepackage{bookmark}% hyperref doc says: Package bookmark replaces hyperref’s bookmark organization by a new algorithm (...) Therefore I recommend using this package.
\usepackage{cleveref}
\newcommand{\protectforpdf}[1]{\texorpdfstring{\ensuremath{#1}}{#1}}
\bibliographystyle{abbrvnat}
\usepackage{etoolbox}
\apptocmd{\thebibliography}{\hfuzz=20cm\raggedright}{}{}
\usepackage[nolist,smaller,printonlyused]{acronym}
\begin{acronym}
\acro{DM}{Decision Maker}
\acro{WTP}{Willingness to Pay}
\end{acronym}

\onehalfspacing
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newcommand{\commentYM}[1]{\textcolor{green}{YM: #1}}
\newcommand{\commentOC}[1]{\textcolor{red}{OC: #1}}
\newcommand{\commentSD}[1]{\textcolor{red}{SD: #1}}
\newcommand{\commentOCf}[1]{\textcolor{red}{\selectlanguage{french}{OC : #1}}}
\newcommand{\commentE}[1]{\textcolor{green}{RelecteurExterne: #1}}
\newcommand{\possessivecite}[1]{\citeauthor{#1}'s \citeyearpar{#1}}
\newunicodechar{ℝ}{\mathbb{R}}
\newunicodechar{≠}{\ensuremath{\neq}}
\newunicodechar{≤}{\ensuremath{\leq}}
\newunicodechar{≥}{\ensuremath{\geq}}
\newunicodechar{→}{\ifmmode\rightarrow\else\textrightarrow\fi}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{∪}{\cup}
\newunicodechar{∩}{\cap}
\newunicodechar{¬}{\ifmmode\lnot\else\textlnot\fi}
\newunicodechar{…}{\ifmmode\ldots\else\textellipsis\fi}

\newcommand{\adv}{\mathscr{N}}
\newcommand{\fadv}{\mathscr{N}_J}%fuzzy adv

\begin{document}
%Stupid elsarticle class forces colors AtBeginDocument, need to insist here to override. (https://tex.stackexchange.com/questions/263496/elsarticle-class-how-to-get-coloured-links-without-boxes)
\hypersetup{citecolor=black}
\title{Justification and decision analysis}

\author[ld]{Y. Meinard\corref{cor1}}
\author[ld]{O. Cailloux}
\cortext[cor1]{Corresponding author}
\address[ld]{Universit\'e Paris-Dauphine, PSL Research University, CNRS, UMR [7243], LAMSADE, 75016 PARIS, FRANCE}

\begin{abstract}
Many \acp{DM} requesting decision support, many concerned stakeholders and the general public typically expect that applications of decision sciences to concrete problems lead to recommendations. But in fact decision sciences obtain conclusions containing recommendations conditioned by norms or normative conceptions. This article explores the attitudes with respect to norms that can be witnessed in the academic literature. We argue that these attitudes share a critical blind spot: they evacuate or trivialize the task to help the \ac{DM} to make up her mind about the norms. As an alternative to these attitudes, we introduce and recommend a higher level norm, on the basis of which, in a given decision situation, a decision analyst can decide, together with the \ac{DM}, whether a given sub-norm or recommendation can be adopted. The point of this higher level norm is to allow to \emph{justify} the subsequent choices. We then identify and discuss a series of requirements that the notion of justification should embody.
\end{abstract}
\acresetall
\begin{keyword}
Decision Aiding, Normative Economics, Legitimacy, Justification, Ethics of Operational Research
\end{keyword}

\maketitle

\section{Introduction}
When analysts use decision sciences to tackle a given concrete problem, they are commonly expected by \acp{DM}, concerned stakeholders and the general public to formulate recommendations $R$. 
Such recommendations $R$ are inevitably conditioned by norms, normative conceptions or value judgments $N$ \citep{funtowicz_science_1993,brans_ethics_2002,mingers_ethics_2011,ormerod_operational_2013,diekmann_moral_2013}. This anchorage in norms raises numerous questions concerning the extent to which sciences are, can be and should be anchored in different kinds of norms, and concerning whether and how the decision analyst can or should take this anchorage in norms into account. The immense literature on the normative underpinnings of economic science \citep{buchanan_positive_1959, sen_nature_1967, dwyer_scientific_1985, heath_value_1994, sen_rationality_2004, mongin_value_2006, sen_idea_2009, baujard_value_2013} investigates some of these questions. %However, the applied literature still expresses diverging stances on these matters \citep{spash_bulldozing_2015, scharks_dont_2016}. 
However, despite its important theoretical contributions, it does not provide practical and concrete guidelines to verify that the norms on which a given decision analysis rests are justified. \commentOC{Thinking about it, I agree that my idea of helping practicioners avoid taking liberties with their scientific neutrality, and help them avoid being dogmatic, paternalist, proselyte, or authoritarian, seems quite pretentious and unclear, I tried another phrasing.}.
The present article attempts to contribute to answer this question. 

As we question the normative grounds on which recommendations rest, we consider, for simplicity's sake, that it is possible to distinguish neatly $N$ from $R$. In practice, it is not always possible to distinguish the $N$ underlying a given $R$ from what one might call ``technical'' elements involved in data elicitation and analysis, model parametrization, and so on \citep{baujard_value_2013}. Such practical difficulties will be left aside in this article and should be tackled in further studies, aimed at developing practical applications of our approach. As a further simplification, we also admit that the recommendations $R$ elaborated by the analyst are offered to a single, well-identified \ac{DM}. We thereby leave aside difficulties associated with group decisions \citep{jackson_towards_1984}, stakeholder identification \citep{wang_systemic_2015} and with boundary judgments involving the integration of several individuals in a collective \ac{DM} \citep{midgley_systemic_2000} -- not for lack of interest, but because they are to too complex to be tackled in the limited space of this article.

\begin{example}
Let us introduce a simple example, which will be used in the entire article to illustrate various important steps of our reasoning. %We will structure this example as a Russian doll, with an abstract example and its concrete instantiation in a concrete setting. 
We start with an abstract example, that we will then instantiate in a concrete setting.

Imagine that a decision analyst is asked by a \ac{DM} to help him decide whether he should implement a given project $P$.
The analyst uses cost-benefit analysis \citep{layard_cost-benefit_1994} and ends-up formulating a recommendation $R$ = “$P$ should be implemented”.
This recommendation is not unconditional. Thanks to her precise analysis of the context and her computations, the analyst derives $R$ from norms $N$, entrenching the relevance of using cost-benefit analysis to decide whether $P$ should be implemented. Some of these norms characterize fundamental philosophical or ethical stances, including a version of utilitarianism stipulating that the total sum of a measure of preference inferred from willingness to pay should be maximized \citep{meinard_ethical_2016}. 
But $N$ also encompasses other, more or less clearly articulated norms. These are, for example, elements referring to the usual requirements for a CBA to be considered to be ``properly'' implemented, such as the claim that the preferences taken into account in the study are the relevant ones, the claim that no important aspect has been forgotten among those included as costs and benefits, the claim that the preference elicitation methods used correctly capture the preferences, etc.

A concrete instantiation of this abstract example is given by the request, through a public procurement procedure, by the local administration in the Var Department (South-east France), in 2013, to analyze a project to restore dry grasslands in the Lachens summit, a natural mountainous area destroyed by the construction of military buidings which are now abandoned \citep{meinard_etude_2015}.
In this concrete instantiation, $R$ refers to a recommendation to restore the dry grasslands that used to exist in the Lachens summit before their destruction when the military base was built. 
The elements composing $N$ refer, among others, to the claim that the analyst properly implemented various kinds of stated-preferences protocols such as contingent valuation surveys, that he properly identified the whole set of relevant stakeholders to investigate in his contingent valuation survey, that he properly computed the value of the various ecosystem services that could accrue from the restored dry grasslands…

In both contexts, the question that we aim to tackle in this article is: when, as decision analysts, we apply decision sciences to solve the practical problems at issue, how should we handle the anchorage of our recommendations in norms, so as to remain scientifically neutral (in the sense given above to the phrase ``scientific neutrality'')? \commentOC{To be rephrased depending on the above issue.}
\end{example}

In order to answer this question, in this article we will start (in \cref{sec:existing}) by exploring attitudes of decision analysts with respect to the normative aspect of decision analysis, as they are exemplified in the economic and philosophical literature. We will see that these various attitudes share a critical blind spot: they evacuate or trivialize the task to help the \ac{DM} to make up her mind about the normative elements underlying the decision analysis they are provided with. By contrast, we argue (in \cref{sec:recomm}) that this task is pivotal, and that decision analysts should endorse an “higher level” norm $\adv$, embodying the requirement to produce \emph{justifications}. We call $\adv$ a “higher level” norm because $\adv$ can be used to establish if this or that $N$ can be used in a given application of decision sciences, but in itself $\adv$ is too abstract for any $R$ to be directly derived from it. Notice that we use here a comparative term (“high\emph{er}”), because our point is simply that $\adv$ does not play the same role as $N$, and places itself “upstream” $N$ (elaborating a precise and complete typology of norms falls beyond the scope of this article). We flesh out $\adv$ as a series of four simple rules that applications of decisions sciences should follow in order to help the \ac{DM} make up her mind about the normative elements underlying the decision analysis she is provided with. \Cref{sec:concl} then briefly concludes.

\section{Varieties of attitudes with respect to \protectforpdf{N}}
\label{sec:existing}
In this section, we review attitudes with respect to $N$ witnessed in the economic and philosophical literature. In a first subsection, we start by exploring the literature in decision sciences and argue that this literature tends to evacuate the task to help \acp{DM} to make up their mind about $N$. But we also highlight that some contributions in this literature point towards an interesting solution, without seriously exploring it: this solution consists in referring to a higher level norm. In a second subsection, we explore attempts developed in the philosophical literature to elaborate this idea to refer to a higher level norm. We argue that these philosophical attempts are unsuccessful as they stand.

\subsection{Elusive economic attitudes with respect to \protectforpdf{N}}
\subsubsection{\texorpdfstring{$A_O$}{AO}: The elusive search for ``basic'' \protectforpdf{N}}
In normative economics, a widespread approach, that we will call $A_O$ ($O$ standing for “obvious”), consists in insulating particularly simple and clear norms. Such norms $N$ are simple enough to let \acp{DM} decide, without the help of the analyst, if they endorse them. It is then possible to derive $R$ from the chosen $N$.

Identifying such simple $N$ however proves more difficult than one might expect. Indeed, as \citet{sen_nature_1967} observes, a value may appear convincing but fail to be basic, in the sense that there may exist facts whose knowledge would lead an individual originally supporting this value to cease to support it. Or a value may conflict with another value, and the individual may cease to support one of them upon realizing this conflict. Because this might hold even for norms such as Pareto Dominance \citep[ch. 5 and 6]{sen_collective_1984}, applying strategy $A_O$ effectively appears difficult.

To illustrate this idea, consider \citeauthor{arrow_social_2012}’s \citeyearpar{arrow_social_2012} famous theorem. Arrow's argument shows that Dictatorship follows (in some formal context) from the axioms of Universal Domain, Pareto Dominance, and Independence of Irrelevant Alternatives. It is easily imaginable that non-expert individuals would willingly accept each of these axioms as capturing value judgments they endorse about what they demand from a voting rule, if the axioms were explained to them by focusing only on what each axiom demands separately, even though they would reject Dictatorship. This example shows that one cannot rest content with the bare fact that a norm $N$ seems self-evident in the abstract, since one can be led to reject a seemingly self-evident $N$ on due reflection, once one has come to realize some of $N$'s implications.

To sum up, $A_O$ flouts \commentOC{I have some doubts that flout is the right verb here.} scientific neutrality by surreptitiously admitting the unwarranted premise that 
some norms $N$ can be found about which \acp{DM} can readily make up their mind.

\subsubsection{\texorpdfstring{$A_E$}{AE}: choosing \protectforpdf{N} that \acp{DM} “would endorse if they could understand”}
$A_O$ is an attitude whereby analysts claim to use decisions sciences while leaving $N$ outside the purview of their scientific inquiry. We have argued that this attitude fails because it is predicated on the implausible premise of the existence of “obvious” norms from which recommendations can directly follow.

By contrast, a second attitude, $A_E$ (where $E$ stands for “expert”), consists in claiming that \acp{DM} cannot systematically take the time to strive to understand $N$ or are not always willing or able to do so. Decision scientists holding this attitude admit that they have the collective skills to understand decision science and discuss among peers whether this or that $N$ should be accepted. But they do not consider that \acp{DM} should take part in such discussions, because these are technical, difficult discussions. When they arrive at conclusions including recommendations $R$, predicated on $N$ encapsulating axioms that decision scientists collectively deem commendable, they consider themselves entitled to jump to $R$ without bothering to help \acp{DM} to make up their mind about $N$. Indeed, this would be a waste of time and energy. At most the decision analyst will invest some time to explain to the \ac{DM} why it was a good idea to endorse $N$, or will content himself to think that, if the \ac{DM} were able to understand the axioms, he would endorse $N$.

\citet[p. 180]{morgenstern_reflections_1979} might be considered as a champion of $A_E$, at least in a plausible interpretation of his text. He writes that: 

\begin{addmargin}[3em]{3em}
“\emph{the expected utility theory (...) as formulated by the von Neumann-Morgenstern axioms, is normative in the sense that the theory is ‘absolutely convincing’ which implies that men will act accordingly. If they deviate from the theory, an explanation of the theory and of their deviation will cause them to readjust their behavior. This is similar to the man who tries to build a perpetuum mobile and then is shown that this will never be possible. Hence, on understanding the underlying physical theory, he will give up the vain effort. Or, an individual making a mistake in, say, long division, will clearly correct himself when shown the mistake.}” 
\end{addmargin}
If understood as referring to a usage of expected utility theory aiming at producing recommendations, this excerpt embodies attitude $A_E$: it takes it to be unquestionable that anyone should be convinced by expected utility theory. (Notice, however, that the above quotation can also be interpreted as referring to a purely mathematical version of utility theory that does not lead to any recommendations, and therefore falls outside our scope.)

Attitude $A_E$ consists, for the decision analyst, in endorsing a higher-level norm $\mathscr{N}_E$ that consists in claiming that expert discussions about norms among decision scientists entitle them to make decisions about norms on behalf of \acp{DM}. Such a norm $\mathscr{N}_E$ grants to expert the role of unquestionable leaders (a questionable moral stance that \citet{estlund_democratic_2009} calls the ``expert/boss fallacy''), and it is unlikely that many decision scientists really wholeheartedly endorse it. Besides, to our best knowledge, it is left unspecified in the literature what is precisely required (when adopting  $\mathscr{N}_E$) for an expert to decide that “enough” discussion has taken place in the expert community and that a consensus has been reached that a given $N$ should be accepted. Furthermore, the fact that a norm has been considered acceptable in the abstract by the scientifict community does not guarantee that it is acceptable in its concrete use by the analyst in the context he studies.

\subsubsection{\texorpdfstring{$A_I$}{AI}: informally testing whether \acp{DM} endorse \protectforpdf{N}}
The blatant weaknesses of $A_E$ suggest a pragmatic variant, $A_I$, with $I$ standing for “informal”. This is the attitude of decision analysts who reject $A_E$'s idea that decision scientists can decide about $N$ on behalf of \acp{DM}, and therefore make a point to informally discuss the meaning of $N$ with \acp{DM} to verify that they agree that the specifics of the situation are such that $N$ appears endorsable to the \acp{DM}, or to let the \acp{DM} choose or parameterize the norms applicable to the situation.

\citet{roy_multicriteria_1996} can be seen as a prominent supporter of $A_I$. Indeed, although he did not use the term “norm” to refer to elements underlying recommendations, he emphasized the need to develop interactions with the \ac{DM} designed to ensure that, not only the recommendations, but also the building blocks of the decision support process from which they derive should be ``meaningful'' for the \ac{DM}:
\begin{addmargin}[3em]{3em}
 “\emph{the analyst has to interact
with the \ac{DM} (or with his representative), in view of co-constructing the model of preferences that the considered method exploits to work out expected results. A key issue is to organize this interaction such that the analyst is able to
elaborate meaningful results. This implies that the interaction protocol or the
software tool involved should be compatible with the way in which the analyst has
been inserted in the decision process, with the way of reasoning of the inquired
people, and with their meaning of useful results.}” \citep[pp. 84--85]{roy_questions_2013}.
\end{addmargin}

This meaningfulness requirement can be interpreted as a need to render the various elements of the decision support process intelligible for the \ac{DM}. But once one admits, as we did at the point of departure of this article, that recommendations $R$ are necessarily anchored in norms $N$, it is difficult to see how this intelligibility requirement, when applied to  the elements of the decision support process embodying $N$, could avoid also including a requirement that the \ac{DM} \emph{endorse} $N$. It therefore seems fair to claim that \citet{roy_multicriteria_1996} implicitly championed a requirement to test whether \acp{DM} endorse $N$. 

As another example of this attitude, one can think about \citet{raiffa_back_1985}’s claim that, in some cases, discussions with \acp{DM} rejecting subjective expected utility theory can lead them to accept it after all.

The problem with $A_I$ is that it combines a scientific approach to arrive at $R$, with an informal, loose approach to lead \acp{DM} to make up their mind about $N$.
Like $A_E$, it is anchored in a higher level norm $\mathscr{N}_I$. But this higher level norm is not clearly articulated. It encapsulates the idea that decision analysts cannot make decisions about $N$ on behalf of \acp{DM}, but does not specify precisely what they should do.

\begin{example}
Let us simply illustrate the meaning of attitudes $A_O$, $A_E$ and $A_I$ in our hypothetical scenario of an application of CBA.

$A_O$ would mean, for the analyst, that she admits that it is clear and evident for \acp{DM} to decide whether they endorse, not only preference utilitarianism, but also all the more or less clearly articulated norms specifying all the requirements for a CBA to be considered to be ``properly'' implemented.

$A_E$, by contrast, acknowledges that \acp{DM} can find it difficult to understand the meaning of this $N$, and might be at a loss trying to decide whether they should endorse it. An analyst adopting $A_E$ would hence fall back upon a community of researchers endorsing $N$ to take the decision to endorse $N$ on behalf of \acp{DM}.

Lastly, an analyst adopting $A_I$ would find $A_E$ unacceptable, and would informally strive to discuss with the \ac{DM} to help him decide whether he endorses $N$. But to accomplish this task, the analyst will be left without a rigorous methodology.
\end{example}

\subsection{Philosophical explorations of higher level norms}
\label{sec:higher}
We have argued in the former subsection that the attitudes currently found in the economic literature are unsatisfactory. $A_E$ and $A_I$ however suggest an interesting solution, which consists in referring to a higher level norm. The philosophical literature contains some interesting, deeper explorations of this idea, in particular in debates (which might seem at first sight quite remote from the subject matter of the literature on decision sciences) on “purely procedural” vs. “substantive” normative theories of justice and democracy.

Substantive theories account for justice and democracy by explicitly referring to values, whereas purely procedural normative theories strive to avoid value judgments. \cite{rawls_political_2005}'s normative theory of democratic legitimacy is a classical example of a purely procedural theory. Rawls did not want his theory to make any value judgment about the kind of state of affair that should prevail in a democratic society. He therefore argued that a policy is democratically legitimate if it is based on a constitution whose justification is acceptable by all  “reasonable” citizens. But he did not want to make value judgments about democratic processes either. He therefore further argued that the very definition of reasonableness should be something for reasonable citizens to pick-up. He thereby attempted to eschew making any value judgments in his account of legitimacy and reasonableness. This was supposed to be a complete ``flight from substance'' \citep{estlund_democratic_2009}, in the sense that this account was supposed to eschew any value judgment, whatsoever.% If this reasoning were successful, it would allow to derive $R$ from $N ⇒_c R$ by removing the value judgments from $N$, rendering it innocuous to endorse.

This approach arguably fails, however, for reasons articulated most prominently by \cite{habermas_reconciliation_1995} and \cite{estlund_democratic_2009}. \citet{estlund_democratic_2009} noticed that, if one admits, following Rawls, that the notion of reasonableness should be selected by reasonable people themselves, then there is an “impervious” plurality of groups that could select themselves as being “reasonable”. He concluded that rawlsian political philosophers have no choice but to render the concept of reasonableness more precise, by specifying the values underlying it. \cite{habermas_reconciliation_1995} criticizes Rawls's presentation of his notions of the “veil of ignorance” and the “overlapping consensus” as \emph{devices} whose real-life functioning can give rise to principles of justice. According to \cite{habermas_reconciliation_1995}, these notions are rather rhetorical tools thanks to which Rawls exposes principles of justice that he surreptitiously deduces from various philosophical notions, such as the one of a moral person, which he (perhaps unconsciously) presupposes. Rawls's ``flight from substance'' hence collapses in a retreat back to the substantial inquiry into the nature and features of a moral subject.  Rawls's attempt therefore does not completely implement the desired flight from substance (which is neither a logical flaw nor a failure to produce illuminating insights, but a failure to strip the argument from its normative anchorage, or “substance”). His theory is anchored in a higher level norm $\mathscr{N}_R$, but this higher level norm is not thematized as such in his philosophy.

By contrast, in his debate with Rawls on the theory of justice, Habermas goes a step further by analyzing the higher level norm underlying his own theory (though he does not uses this vocabulary). \possessivecite{habermas_moralbewustsein_1983} \commentOCf{Déplacer la citation pour éviter le conflit avec le génitif, si possible (nuit légèrement à la lecture, mais pas très grave) ? (Par ailleurs, j’ai systématiquement ajouté le s à Rawls’s et Habermas’s, plus moderne \href{https://en.wikipedia.org/wiki/Apostrophe\#Singular_nouns_ending_with_an_\%22s\%22_or_\%22z\%22_sound}{parait-il}.)} “weak” transcendental deduction of the tenets of “discourse ethics” from communicative action is particularly interesting in this respect. \citet{habermas_theorie_1981} argues that agents communicating with one another make validity claims of three sorts: veritative claims about truth, normative claims about values and norms, and authenticity claims about expressions concerning their inner life, feelings and consciousness. The role that norms play is therefore clearly circumscribed in Habermas's framework, and it concerns one kind of validity claims among others. \cite{habermas_moralbewustsein_1983} does not locate the tenets of “discourse ethics” at this level. He rather argues that all the acts and deeds that consist in making validity claims are oriented by a strive for intercomprehension, which lies at the core of communicative action. And he identifies the tenets of discourse ethics as conditions of possibility for this intercomprehension-oriented activity. 

On the face of it, Habermas's reasoning therefore seems to provide the means to eschew the task to help the \acp{DM} to make up their mind about norms. \commentOCf{Je trouve la phrase précédente alambiquée (\og{}provide the means to eschew the task to help to make up…\fg{}), mais je ne trouve pas comment reformuler.} Indeed, he identifies an “ethics”, which is presumably something that allows to formulate recommendations. And it would be pointless to expect \acp{DM} to make up their mind about the tenets of this “ethics”, because these tenets are conditions of possibility for a very basic, all-pervasive structure of human action. Like $A_E$, Habermas's approach is therefore anchored in a higher level norm, $\mathscr{N}_{H}$, capturing the tenets of discourse ethics. A formulation of this higher level norm is: “For a norm to be valid, the consequences and side effects that its general observance can be expected to have for the satisfaction of the particular interests of each person affected must be such that all affected can accept them freely” \citep{habermas_moralbewustsein_1983}. Just like $\mathscr{N}_E$, this higher level norm does not allow directly to deduce recommendations $R$. But as opposed to proponents of $A_E$, Habermas provides foundations to entrench his $\mathscr{N}_{H}$. 

These foundations are, however, derived from his very specific understanding of communication and its importance in the functioning of human societies, which has been extensively criticized in the literature \citep{heath_communicative_2001,honneth_kritik_1985,benhabib_situating_1992}. 

By anchoring itself in a higher level norm $\mathscr{N}_E$, $A_E$ paves the way for a satisfactory solution to our problem in this article. $A_I$ overcomes $A_E$'s shortcomings by pointing the need to find a better higher level norm than $\mathscr{N}_E$, but fails to articulate one. Similarly, Rawls's approach is anchored in a higher level norm $\mathscr{N}_{R}$ that he fails to account for. Habermas goes a step further by entrenching his higher level norm $\mathscr{N}_{H}$ in his philosophy of society. In the sections to come, our aim is to follow this lead and identify a more relevant higher level norm $\adv$, not derived from Habermas's disputed vision of communicative action. (This contrasts with \citet{mingers_ethics_2011}, who deems that the limits of Habermas's discourse ethics are outweighed by its relevance to operational research -- a stance that we do not demean, but whose counterpart we aim to explore.)

\section{The recommended model}
\label{sec:recomm}
\subsection{Justification}
In this section, our aim is to identify a higher level norm $\adv$, on the basis of which, in a given decision situation, a decision analyst can decide, together with the \ac{DM}, whether a given $N$ can be adopted. In order to identify this $\adv$, let us admit that the point of this higher level norm is to allow to \emph{justify} the choice of a given $N$.

This reference to the notion of \emph{justification} echoes contemporary debates on the role of scientific expertise in policy making, which is often enough presented as undergoing a crisis of \emph{confidence} \citep{godard_environnement_2015}. As a response, many expertise settings, proceedings and institutions have evolved (in more or less successful attempts to restore the lost confidence) to increase their \emph{transparency}, \emph{pluralism} and \emph{independence}. These three criteria are largely accepted as requirements to impose on any expertise. However, they cannot be considered as absolute and applicable in all situations. As \citet{godard_environnement_2015} points out, in some situations, an excessive transparency can cripple expertise, and independence is, in many respects, unachievable: every expert has its interests. Similarly, pluralism denies the very idea that expertise can have a point, if it means that all opinions, however fanciful or extremist, should be given the same weight. Accordingly, these three criteria are better conceived as implications of a more fundamental principle: the need to justify expert opinions. \citet[][p. 379]{godard_environnement_2015} mentions this idea in passing, in the case of independence: “the right question is not `tell me to whom are you tied', but `tell me which arguments justify your opinion' ”. But a similar rationale applies to the other two criteria: the point of requiring transparency is to render visible the justifications underlying the various expert opinions, or the lack thereof; the point of pluralism is to expose justifications to a large sample of counter-arguments, as diverse as possible.

These contemporary debates hence illustrate that the requirement, for decision analysts, to justify themselves, is often taken as a self-evident, unquestionable premise. One might even argue that a willingness to justify is a necessary condition for decision scientists to present themselves as \emph{scientists} \citep{ormerod_justifying_2010}. This pervasive reference to a justification requirement is, however, much too vague. Indeed, the term ``justification'' is extremely polysemous. In some contexts, one might call any argument, however spurious or ill-conceived, a ``justification''. Even if one admits that a purported justification deserves to be called so only if it comes up to some ``standards of quality'' of some sort, the term ``justification'' remains underdetermined, and could mean very different things depending on the nature of the standards at issue.

Our agenda in this section is to start with the notion of justification in general, admitting that, at this level of generality, a justification requirement is innocuous, and to progressively clarify and flesh out a concrete notion of justification. Such a concrete notion should no longer be ambiguous, and should allow us to identify a satisfactory $\adv$. To that end, our approach will be similar to the one typically used in ordinary language philosophy \citep{soames_philosophical_2003}: we will draw on everyday intuitions about the meaning of the term ``justification'', and strive to progressively sharpen a specific definition that the term should take in order to play the role that we want it to play, in the very specific context in which we want to use it. To do so, we will take advantage of the arguments developed above against the various attitudes presented in the former section. Using the terminology of ``justification'', these arguments can be summarized by saying that these attitudes are anchored in higher level norms that provide \emph{unsatisfactory justifications} to adopt norms $N$ in various decision situations, in some yet unclarified understanding of the phrase ``unsatisfactory justification''. Drawing on these arguments will allow us to clarify the language intuitions underlying the idea that the flaws of the above attitudes testify for their being \emph{unsatisfactory justifications} \commentOCf{Je ne comprends pas cette phrase.}. This, in turn, will allow us to sharpen our understanding of what the idea of a \emph{satisfactory justification} means for our purposes.

In the two subsections below, using this methodology, we identify a series of requirements that the notion of justification should embody (these subsections draw on provisional ideas introduced by \citet{meinard_du_2013, meinard_what_2017}). The third subsection then presents a set of practical rules that materialize these requirements and participate in fleshing them out. These practical rules specify the attitude that a decision analyst should have, if he sets himself the task to produce \emph{satisfactory justifications} for the $N$ grounding his $R$.

\subsection{Three requirements}
A first, almost trivially unadapted notion of justification should be eliminated straightaway. This is the extremely large notion (already mentioned above) that would call ``justification'' any discourse designed to buttress a given $N$, whatever its characteristics, independently of any standard of any sort (standards of clarity, rigorousness, convincingness and so on). In this extremely large understanding of ``justification'', the phrase ``unsatisfactory justification'' is a contradiction in terms, and the idea that the attitudes explored in the former section exemplify ``unsatisfactory justifications'' is void.

We hence need a notion of justification that integrates criteria. But what criteria should one use? Here we introduce three requirements encapsulating the criteria that, we argue, are relevant to capture the notion of justification that we need.

\subsubsection{Incrementalism}
As we have seen, $\mathscr{N}_E$ encapsulates a criterion: $N$ should be considered consensual among decision scientist experts. $\mathscr{N}_E$ presupposes that this criterion is clear and determined. However, one cannot find, in the literature, any elaboration of how this criterion is supposed to be checked. This blind spot obfuscates the idea that such a consensus, if it existed, would certainly evolve as decision science knowledge improves. A more satisfactory version of $\mathscr{N}_E$ would hence clarify the meaning of this criterion, and would thereby in particular highlight that the content of the criterion is liable to change as knowledge improves, incrementally. The same idea applies to $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$. We have seen that the former is anchored in an implicit philosophy of the moral subject, and the latter in a theory of society. But both theories can be questioned, and more satisfactory versions of $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$ should admit and openly display their provisional status (\cite{habermas_moralbewustsein_1983} does emphasize this point -- discussing whether this claim is coherent with the larger habermassian framework falls beyond the scope of this article).

This first analysis of part of the shortcomings of $\mathscr{N}_E$, $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$ hence suggests the need to integrate, in our notion of justification, an \emph{incrementalism} requirement, holding that it is illusory to claim to be able to capture a definitive list of criteria defining what is a satisfactory justification. According to “incrementalism”, one had better work incrementally, to improve step by step one's understanding of the relevant criteria. “Incrementalism” reflects the idea that even experts have limited capacities to identify definitive solutions to the problems they are entrusted to tackle, and therefore their conclusions cannot be considered to be definitive solutions.

\subsubsection{Anchorage in real-life acceptability}
Another problematic feature that our exploration of $A_E$ illustrated is that it conceives the elaboration and application of $\mathscr{N}_E$ as tasks for decision scientists alone to tackle. By contrast, Rawls and Habermas wanted their theories to avoid granting the philosopher (or the decision scientist) the right to preempt discussions about $N$, an idea also supported by attitude $A_I$. Rawls introduced this idea thanks to his notion of the ``reasonable'', which \cite{estlund_democratic_2009} rearticulated at a more general level as an acceptability requirement. We have seen that, at least according to \cite{habermas_reconciliation_1995} and \cite{estlund_democratic_2009}, Rawls's argument is flawed. But a core idea underlying it remains, in our view, pivotal to elaborate a relevant notion of justification: this idea is that how people in the flesh receive and react to purported justifications should play a core role in deciding whether the latter qualifies as a satisfactory justification.

\subsubsection{Interventionism}
The latter requirement might suggest the following approach, inspired by the sociological literature on “orders of justification” \citep{boltanski_justification_2006}. According to this literature, various groups in various situations typically refer to different and largely irreconcilable “orders of justifications”, which can (according to some authors at least) be formalized as sets of normative axioms accepted by some groups but rejected by others.

Drawing on this literature, one could set out to use sociological surveys determining in which groups the people concerned by a given application of decision sciences fall, and produce recommendations justified by the axioms endorsed by those people in the situation at issue. Such an approach can be seen as a refinement of $A_O$: it allows for the case where different people find different norms self-evident, but it falls under the same problems than $A_O$ by still requiring that people judge by themselves whether they consider some norms as self-evident. In particular, it might be that people accept some norms only because they have not realized all their implications.

In order to integrate such reactions, we need a notion of justification that does not reduce the acceptability of justifications to the bare factual acceptance of discourses. This requirement obviously echoes \possessivecite{habermas_reconciliation_1995} and \possessivecite{estlund_democratic_2009} criticism of Rawls's notion of “reasonable”: if it is to make sense, Rawls's theory cannot be about justifications that real people usually accept or will accept, it must be about justifications that citizens \emph{would} accept, if they were reasonable. \citet{habermas_faktizitat_1992} forcefully emphasizes this counterfactual aspect in his theory of legitimacy, but this leaves his approach vulnerable to the criticism that he talks about counterfactual worlds in outer space. In our view, the important idea that Habermas's reasoning conceals is that the notion of acceptability is only convincing if one accepts that the philosopher or the decision scientist trying to capture what people can find acceptable allows himself to interact with those people, and thereby goes beyond the approach championed by authors like \cite{boltanski_justification_2006}.


\subsection{Conjoining the three requirements: primacy of practice}
But how can one know that a justification is acceptable in this sense? %We have seen above that \cite{estlund_democratic_2009}'s solution would consist, for the philosopher, in making bold claims about the truth of the criteria used to sort out what is acceptable and what is not. But a major problem with such an approach is that it contradicts our above requirements of \emph{incrementalism} and \emph{anchorage in real-life acceptability}. In order to overcome this problem, 
Our proposal is that the relevant notion of justification should embody the following tenet of “primacy of practice”: instead of searching for acceptability criteria through theoretical reflection, one should take the stance that consists in putting justifications to the test in real-life situations, so as to improve gradually our blunt understanding of what it means for a justification to be acceptable. In this approach, purported justifications deserve to be called so depending on whether they satisfy some criteria. These criteria are a matter of confronting purported justifications to their real-life acceptability by people in the flesh (echoing the \emph{anchorage in real-life acceptability} requirement). This acceptability is in turn not reduced to factual acceptance (echoing the \emph{interventionism} requirement). It rather refers to acceptance conditioned on purported justifications being put to the test, tentatively and iteratively (echoing the \emph{incrementalism} requirement).

\subsection{Unfolding practical rules}
Obviously enough, though our analysis in the former subsections allowed us to flesh out the notion of justification to some extent, it still is indeterminate in an important respect. We still have to describe more precisely what it means to ``put purported justifications to the test''. This subsection is devoted to describe a practical procedure that decision analysts should follow to do that. The features of this practical procedure are derived from the understanding of the notion of justification spelled out in the former subsections. (The tenets constituting our practical procedure bear a resemblance with \citeauthor{diekmann_moral_2013}’s \citeyearpar{diekmann_moral_2013} ``mid-level'' moral principles, but they aim to be more general -- not being limited to a specific activity such as modeling -- and are not derived from moral theories, but rather from our meta-norm $\mathscr{N}$, which is designed to be more fundamental.)

\citet{meinard_what_2017} attempted to elaborate a practical procedure of that sort in an exploration of the concept of legitimacy. Here we will translate some elements of this approach to our context, and also address what we take to be weaknesses, so as to unfold a more satisfactory account. Our proposed practical procedure will be articulated in four points.

A first requirement is designed to capture the idea that, as application of “primacy of practice”, our endorsement of $\adv$ should first and foremost take the form of our actually articulating justifications. As application of ``anchorage in real-life acceptability'', in our context where an analyst offers a recommendation $R$ to a \ac{DM}, ``articulating a justification'' obviously implies that the justification should be articulated in such a way that the \ac{DM} understands it and is convinced by it. In this setting, our first requirement can be articulated as follows:

\begin{itemize}
\item[i.]	Systematically display arguments in favor of the $N$ from which our recommendations derive.
\end{itemize}
A second point should prevent our using justifications that happen to be accepted, as a matter of fact, at the moment when we articulate them, but whose weaknesses are swept under the carpet. This point embodies “incrementalism” and ``interventionism'', by admitting that, once we have found arguments in favor of something, we should try to look for ways through which they could be discarded. Real-life examples of decision-aiding practices that flout this clause are given in \cite{meinard_what_2017}, which lead him to introduce a requirement to be ready to defend one's recommendations against criticisms, even when none are formulated. This requirement is insufficient, however. Indeed, an account associating it with clause [i] would be impaired by a worrying weakness, which can readily be identified by referring to the literature on epistemic injustice \citep{fricker_epistemic_2007} (this problem is not addressed by \cite{meinard_what_2017}, and it arguably is also left aside by \cite{mingers_ethics_2011}, since this issue is mentioned in the limit to his own framework that he calls ``Engagement and inclusion''). Some people and groups have access to knowledge, others have not. The former are in a position to articulate criticisms, the latter are not. By imposing that decision analysts should be ready to defend their recommendations, the above approach exposes applications of decision science only to part of the spectrum from which criticisms can come. What if there are no criticisms addressed at us, whereas many could have been, but were not, because of epistemic injustices? Would we still feel confident in claiming that our approach materializes satisfactory justifications in such a case? We do not think so. There is therefore something amiss in the above account.

One might suggest that the problem could be fixed by identifying a specific group of people that should be the source of criticisms, or even a procedure that should be used to encourage the formulation of such criticisms. But this would mean presuming that we have the kind of perfect knowledge needed to identify \emph{the} ultimate procedure once and for all.

``Primacy of practice” offers a solution to this problem. We cannot identify once and for all a perfectly relevant group of people and/or a perfect procedure. What we can do is identify an attitude that will be conducive to more satisfactory justifications, and this attitude is a requirement to actively elicit criticisms. This requirement is the missing element in our account, liable to fix its first weakness.

\begin{itemize}
\item[ii.]	Actively elicit criticisms
\end{itemize}

We now need a third clause to allow clauses i and ii to fully embody “primacy of practice”, by putting justifications to the test in real-life, instead of confining them to theoretical criteria.

\begin{itemize}
\item[iii.]	 Actively defend our recommendations against all criticisms
\end{itemize}

 Obviously enough, just like clause i, clause iii only makes sense as an application of ``anchorage in real-life acceptability'' because the ``defense'' at issue consists in articulating arguments that the \ac{DM} understands and that convince her.

Clauses [i-iii] spell out the attitude of experts who would enact a willingness to justify themselves by displaying the arguments underlying their stances, and by actively being willing to face dissident stances. But this account, although completed to fix the weaknesses mentioned above, has another worrying weakness, which can be captured by raising the question: when can one admit that one has produced \emph{enough} justifications? (This weakness was also ignored by  \citet{meinard_what_2017}.) Indeed, in practice, whatever the effort one makes to address all the criticisms that one can think about, there is bound to remain infinitely numerous other possible criticisms -- criticisms that one failed to think about, or even criticisms that are not conceivable today, but that will emerge in the future, as knowledge increases. The justificatory task to address criticisms therefore appears infinite, and including it in rules that decision analysts should abide by might accordingly seem unrealistic.

We propose to solve this problem by applying ``incrementalism'' to the justifiability of the decision analysis process. When applied to the identification of criteria to sort out acceptable justifications from unacceptable ones, incrementalism means that one can never admit that one knows what the right criterion is: proposed identifications of ``the right'' criterion are always provisional. When applied to the implementation of steps [i-iii] spelled out above, incrementalism means that, when implementing [i-iii], the decision analyst deploys a provisional account of the justifiability of the decision analysis she provides. The claim that she thereby makes does not amount to claiming that the decision analysis is justified, in any absolute and definitive sense. It is a provisional claim. The decision analyst can claim that her decision analysis is more justifiable than it would have been if she had not done this or that, while unfolding [i-iii].

In concrete terms, applying incrementalism to the justifiability of the decision analysis process leads to add a fourth clause to our account.
\begin{itemize}
\item[iv.]	Understand our own justifiability as unavoidably provisional.
\end{itemize}

To sum up, the model that we recommend is that, as decision analysts implementing decision science in concrete situations so as to provide recommendations, we should:
\begin{enumerate}[label=\roman*.]
	\item Systematically display arguments in favor of the $N$ from which our recommendations derive;
	\item Actively elicit criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understand our own justifiability as unavoidably provisional.
\end{enumerate}

Clearly, applying the formula [i-iv] is unlikely to ensure that we will be able to identify \emph{the} ultimate justification for our recommendations. For that, we would need to have access to all the possible arguments, all the possibly relevant information, and we would need a perfect definitive definition of what is a satisfactory justification.  The more modest ambition of this account is to provide a practical answer to the core question of our inquiry: \emph{as practitioners applying decision sciences to the resolution of concrete problems, how can we make sure that the normative aspects of the decision analysis that we provide don't lead us to take liberties with our scientific neutrality by being dogmatic, paternalist, proselyte, or authoritarian?} \commentOC{À reformuler en fonction.} The answer that we propose is: \emph{we can make sure that we remain scientifically neutral by applying formula [i-iv]}. \commentOCf{Make sure semble trop fort ici.} Obviously enough, unfolding the process epitomized by formula [i-iv] is bound to fail if the \ac{DM} with whom we work stubbornly rejects all our attempts at reasoning with him. In such a borderline case, our core question simply cannot be answered: in such a case, it is just impossible to provide decision support while remaining scientifically neutral.

\begin{example}
To illustrate the concrete meaning of our reasoning, let us see how it applies to our example of a decision analyst using CBA to help a \ac{DM} to decide whether he should implement a given project $P$.

As application of clause [i], instead of simply using the chosen method without further ado, the analyst should take upon herself to clarify the norms $N$ underlying the usage of this method, and to explain to the \ac{DM} why she deems it relevant to admit $N$ in the case at hand. An analyst who would skip this step, for example because using CBA was part of the requirements of the public procurement procedure through which she was chosen and she admits that she has nothing to say about the relevance of this requirement, would fail to abide by [i].

As application of clauses [ii] and [iii], the analyst should set the discussions with the \ac{DM} in such a way as to foster reactions and elicit criticisms when it comes to the relevance of $N$. For example, if the decision analysis task is monitored by a steering committee, the analyst should take advantage of the meetings with the committee to highlight possible reasons both to accept and to reject $N$. If, thanks to her understanding of the local context, the analyst suspects that the structure of the steering committee is biased against a given group of stakeholders, she should suggest to the \ac{DM} to enlarge the committee to include those groups or external experts, and thereby facilitate the emergence of possible criticisms coming from them. In the same vein, she should do her best to take advantage of the scientific literature to identify relevant arguments.  

%Obviously enough, in some situations, the \ac{DM} will simply reject the analyst's attempts to discuss the relevance of $N$, or will turn a blind eye towards the analyst's request to expand the steering committee. Similarly, in some situations, any defense of $N$ or any alternative to $N$ will face a stubborn resistance by ill-intentioned people simply willing to sabotage the decision process. In such cases, the analyst will have to surrender at some point.

%But this surrender is not a failure of his justification attempts. He will have failed if an alternative decision process is launched whereby another decision analyst manages to develop a more successful justification. In the absence of such a more successful alternative, the first decision process should be considered provisionally justified.

Let us now illustrate these ideas using our concrete example of the restoration of dry grasslands on the Lachens summit (the account below is somewhat stylized, ni particular in that it focuses on the exchanges of arguments between the analyst and the \ac{DM}, and leaves aside the contributions of other people, which are not directly relevant to our argument here). In its analysis of the restoration project, the consultancy in charge argued that using CBA was inappropriate in this case, due to two main reasons. First, they argued that, due to knowledge gaps in the literature on restoration of the kind of natural habitats concerned, it was impossible to compute the risks involved in the project. Second, they argued that some of the likely consequences were such that using CBA was ill-advised. Among these risks are possible impacts on populations of rare species, in particular \emph{Leucanthemum burnatii} Briq.\@ \& Cav.\@ \commentOCf{Why not emphasize our friends Briq and Cav as well?}, a rare plant species (see the discussion of this issue by \citet{meinard_ethical_2016}). The main value recognized to this species, which does not provide any ecosystem service and has no market value, lies in the fact that botanists around Europe consider that it has an intrinsic value as a rare species. A prominent method used in the context of CBA to capture this kind of value is travel cost method, which, in its application in this case, would compute the money that botanists are prepared to pay to make the trip to the Lachens summit to see the species. The consultancy argued that a major problem for this method is that it does not take account of the value that botanists who don't have the money to make the trip bestow on the species. An important part of the value of the species would hence be ignored if this method were used. A prominent alternative to this method is stated-preferences methods, but here again the consultancy argued that applying it would not give completely satisfactory results, because the applicability of this method to biodiversity is debated in the literature. Part of these arguments can be found in the technical report produced by the consultancy \citep{meinard_etude_2015}, but many were voiced in meetings. In the end, although the initial demand was to implement a complete CBA, the consultants did not do it, not for lack of time or competence, but because they had reasons, that they could articulate in discussions with the \ac{DM}, to believe that they lacked the data and technologies needed to properly implement this method. This means neither that the \ac{DM}'s problem was unsolvable, nor that other consultants could not have found a way to solve it using CBA. But as it stands, the consultants who tried to solve the problem using CBA did not find a satisfactory way to do it, and produced arguments which convinced the \ac{DM} that doing it was (possibly provisionally) impossible. Accordingly, this endeavor to provide decision aid was justified, in the sense articulated above.
\end{example}

\section{Conclusions}
\label{sec:concl}
In this article, we have introduced an account of how, as decision analysts applying decision sciences to concrete situations, we should cope with the normative aspects of our endeavor. For that purpose, we have explored a series of attitudes with respect to $N$ observed in the decision sciences literature. We have striven to demonstrate that all these attitudes trivialize or avoid to task to help \acp{DM} to make up their mind about $N$, whereas this task is, according to our argument, a pivotal part of decision analysis. This argument led us to recommend a higher level norm $\adv$, on the basis of which, in a given decision situation, a decision analyst can decide, together with the \ac{DM}, whether a given $N$ can be endorsed. In order to identify this $\adv$, we have admitted that the point of this higher level norm is to allow to \emph{justify} the choice of a given $N$, and we have used an ordinary language philosophical methodology to identify a series of requirements that the notion of justification should embody. We have then presented a set of practical rules that materializes these requirements and participate in fleshing them out. We thereby ended-up recommending the following account.

As decision analysts, we should:
\begin{enumerate}[label=\roman*.]
	\item Systematically display arguments in favor of the $N$ from which our recommendations derive;
	\item Actively elicit criticisms;
	\item Actively defend our recommendations against all criticisms;
	\item Understand our own justifiability as unavoidably provisional.
\end{enumerate}

To ponder on this formulation, it is useful to mention three prominent objections that one might want to raise against our approach.

A first objection might come from decision scientists who would reduce our argument to a simple call for decision analysts to justify their recommendations, which, they might argue, is what decision analysts already do. This would miss an important aspect of our reasoning. Indeed, our rationale emphasizes that recommendations necessarily rest on norms, and stresses that decision analysts cannot eschew the need to help \acp{DM} to make up their mind about those norms. Current practices address this issue informally, if at all. By contrast, we argue that it is necessary to anchor this important part of applied decision theory in a rigorous methodology, an objective to which this article attempts to contribute. To do so, we have proposed practical rules that decision analysts should follow in order to obtain justified recommendations. If followed, these practical rules will modify current practices. \citet{cailloux_formal_2018} provide a first instantiation of this account in a formal framework.

A second objection might come from people who would claim that justification requirements command respect, but are impossible to implement in practice. Such critics would claim that, in practice, decision scientists have no choice but to pick up some norms $N$ to derive recommendations, and that any serious attempt to justify these norms would be impractical. Justification requirements would be impractical indeed, if they meant that any recommendation should be anchored in an “ultimate” justification. However, our reasoning is based on an incremental and provisional approach to justifications: the justifications that we are interested in are not ``ultimate'' in any sense, they are tentative and open to improvements. Identifying such provisional justifications is far more practical than pretending to capture ``ultimate justifications'', and we argue that it can be done in practice by following our proposed practical rules.

A third objection is a radicalized version of the second one. It would claim that, in practice, justification is irrelevant: the only relevant point is that decision analysis should ``work'' -- that it should be value-adding. This idea is \emph{prima facie} convincing, but what does it mean for decision analysis to ``work'' or to be ``value-adding''? 
To a large extent, the successfulness of decision analysis hinges upon the analyst's capacity to justify it. In that sense, this would-be objection does not seem to be a real objection after all. At least the burden of proof lies on critics who would be able to articulate it using a clear explanation of what it means for decision analysis to work. 

We see our contribution as an attempt to articulate (relatively) precise requirements that applications of decision sciences should follow, with concrete, practical implications. We emphasize that the precision of those requirements is limited in many respects.
It does not provide a metric, no generally applicable mechanical means to compare any two applications of decision sciences without discussions. There is bound to be myriads of hard cases where one application of decision science will appear better than another on some respect, but worse on another respect. However, this first step towards a more precise account of the requirements for proper justification might, if made still more precise in a formal framework, lay a path to such a systematic comparison procedure, which is attempted in a continuation of this work \citep{cailloux_formal_2018}. \commentOC{We should say something like this, I think. (Probably, in place of the previous reference to the same article.)}

Besides, as emphasized above, our work in this article is focused on relatively simple situations where the recommendations elaborated by the analyst are offered to a single, well-identified \ac{DM}, which evacuates difficulties associated with group decisions and some particularly complex boundary judgments. One might want to criticize our approach by claiming that this restriction in effect confines our analysis to highly stylized decision processes that are never exemplified in real-life decision analysis, because even in settings in which a single \ac{DM} is clearly identified \emph{prima facie}, most of the time in effect this \ac{DM} has limited leverage and other stakeholders are always at least informally involved in his decision. This idea could suggest that the relevant notion of justification for decision analysis is not a matter of arguments and counter-arguments that the \ac{DM} understands and accepts, but that the collective involved in the decision understands and accepts. Such a rationale however conflates two different kinds of decision situations. On the one hand, in some decision situations, although a single \ac{DM} is clearly identified, he has to take account of the fact that his power to act is limited, and he has to take a series of stakeholders into account. In such cases, our framework is applicable, and the stakeholders' stances are among the important constitutive elements of the arguments and counter-arguments that our justification procedure should integrate. On the other hand, in some other decision situations, the real \ac{DM} is a collective: in such cases, our framework needs to be extended or adapted, but we do not see any reason to believe that all the decision situations are amenable to such collective decision settings. 

Another limitation that we acknowledge is that we also left aside issues concerning the social responsibility of operational research interventions \citep{ackoff_social_1974,gallo_operations_2004}.

In our view, the analysis of these more complex issues can benefit from our exploration, in the sense that the difficulties involved in aiding a single \ac{DM} to make up his mind about the relevance of admitting a given norm are exacerbated in these more complex, pluri-actor settings. A prominent avenue for future research is therefore to explore how our framework can contribute to criticize and improve frameworks devoted to tackle the complex issues, such as ``system of systems methodology'' \citep{jackson_towards_1984}, ``critical heuristics'' \citep{ulrich_critical_1987}, ``critical rationalism'' \citep{ormerod_critical_2014}, ``systems thinking'' \citep{mingers_review_2010}, ``problem structuring methods'' \citep{hector_problem-structuring_2009}, ``community operational research'' \citep{johnson_emerging_2018} or ``stakeholder-oriented multi-criteria decision analysis'' \citep{de_brucker_multi-criteria_2013}.

%Avoids printing section numbers, but leaves entries in the TOC
\setcounter{secnumdepth}{0}
\section{Acknowledgements}
We thank S. Deparis, P. Grill, M. Nunez and J. Rouchier for powerful comments and suggestions on this manuscript. \commentOCf{Je retire Denis, car je soupçonne qu’il considérerait négativement l’idée d’être associé d’une quelconque façon à cet article.}

\section{References}
\bibliography{propermanual}
\end{document}
