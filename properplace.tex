\RequirePackage[l2tabu, orthodox]{nag}%more warnings
\RequirePackage{silence}\WarningFilter{newunicodechar}{Redefining Unicode character}
\pdfgentounicode=1 %permits (with package glyphtounicode) to copy eg x ⪰ y iff v(x) ≥ v(y) from pdf to unicode data. 
\input{glyphtounicode}%nice copy from PDF
\documentclass[preprint, french, english, 11pt, authoryear]{elsarticle}%english main language
\usepackage{lineno}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{newunicodechar}%able to use e.g. → or ≤ in source
\usepackage{babel}
\usepackage{scrextend}
\frenchbsetup{AutoSpacePunctuation=false, SuppressWarning=true}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{color}
%\usepackage{natbib}
\usepackage{doi}
\usepackage{slantsc}
\usepackage[rightbars]{changebar}
%\setlength\linenumbersep{9mm}
\setlength\changebarsep{7mm}
	\usepackage{etoolbox} 
	\makeatletter
	\patchcmd{\@doi}{http://dx.doi.org}{https://doi.org}{}{}
	\makeatother
\usepackage{hyperref}
\hypersetup{breaklinks, bookmarksopen, hidelinks}
\usepackage{bookmark}% hyperref doc says: Package bookmark replaces hyperref’s bookmark organization by a new algorithm (...) Therefore I recommend using this package.
\usepackage{cleveref}
%\usepackage{titlesec}
%\titlespacing{\section}{0pt}{10pt}{0pt}
%\titlespacing{\subsection}{0pt}{10pt}{0pt}
%\titlespacing{\subsubsection}{0pt}{10pt}{0pt}
\newcommand{\protectforpdf}[1]{\texorpdfstring{\ensuremath{#1}}{#1}}
%Making sure we follow: “If your source files are in LaTeX, please visit our LaTeX site.” (in https://www.elsevier.com/journals/european-journal-of-operational-research/03772217/guide-for-authors), which gives a bibliographic style file. Style is not consistent with examples given elsewhere in the authors guide.
\bibliographystyle{elsarticle-harv-nourl}
%\bibliographystyle{apalike}
%\bibliographystyle{abbrvnat-noissn-noisbn-nourl}
\usepackage{etoolbox}
\apptocmd{\thebibliography}{\raggedright}{}{}
%\usepackage[single]{acro}
%\acsetup{short-format = {\scshape}} 
%\DeclareAcronym{CBA}{short=cba, long={cost-benefit analysis}}
%\DeclareAcronym{DM}{short=dm, long={Decision Maker}}
%\DeclareAcronym{OR}{short=or, long={Operational Research}}
%\DeclareAcronym{WTP}{short=wtp, long={Willingness to Pay}}
\newcommand{\ac}[1]{#1}
\newcommand{\acp}[1]{#1s}
\newcommand{\aclp}[1]{#1s[long]}
\newcommand{\acresetall}{}
\onehalfspacing
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newcommand{\commentYM}[1]{\textcolor{green}{YM: #1}}
\newcommand{\commentOC}[1]{\textcolor{red}{OC: #1}}
\newcommand{\commentSD}[1]{\textcolor{red}{SD: #1}}
\newcommand{\commentOCf}[1]{\textcolor{red}{\selectlanguage{french}{OC : #1}}}
\newcommand{\commentE}[1]{\textcolor{green}{RelecteurExterne: #1}}
\newcommand{\possessivecite}[1]{\citeauthor{#1}'s \citeyearpar{#1}}
\newunicodechar{ℝ}{\mathbb{R}}
\newunicodechar{≠}{\ensuremath{\neq}}
\newunicodechar{≤}{\ensuremath{\leq}}
\newunicodechar{≥}{\ensuremath{\geq}}
\newunicodechar{→}{\ifmmode\rightarrow\else\textrightarrow\fi}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{∪}{\cup}
\newunicodechar{∩}{\cap}
\newunicodechar{¬}{\ifmmode\lnot\else\textlnot\fi}
\newunicodechar{…}{\ifmmode\ldots\else\textellipsis\fi}

\newcommand{\adv}{\mathscr{N}}
\newcommand{\fadv}{\mathscr{N}_J}%fuzzy adv
%Accept overfull hbox up to...
\hfuzz=3pt
\AtBeginDocument{%
  \DeclareFontShape{T1}{lmr}{m}{scit}{<->ssub*lmr/m/scsl}{}%
}
\crefname{enumi}{clause}{clauses}

\begin{document}
%Stupid elsarticle class forces colors AtBeginDocument, need to insist here to override. (https://tex.stackexchange.com/questions/263496/elsarticle-class-how-to-get-coloured-links-without-boxes)
\hypersetup{citecolor=black}
\title{Justification and decision analysis}

\author[ld]{Y. Meinard\corref{cor1}}
\author[ld]{O. Cailloux}
\cortext[cor1]{Corresponding author}
\address[ld]{Universit\'e Paris-Dauphine, PSL Research University, CNRS, UMR [7243], LAMSADE, 75016 PARIS, FRANCE}

\begin{abstract}
\begin{changebar}When decision sciences are applied to concrete problems, \acp{DM}, concerned stakeholders, and the general public typically expect clear recommendations.
But in fact any recommendations contained in the conclusions will be conditioned by norms or normative conceptions.
This article explores the attitude to norms in the academic literature. We argue that these attitudes share a critical blind spot: they evacuate or trivialize the task of helping the \acp{DM} to make up their minds about norms.
As an alternative to these attitudes, we introduce and recommend a higher level norm on the basis of which, in a given decision situation, a decision analyst can decide, together with the \ac{DM}, whether a given sub-norm or recommendation can be adopted.
The point of this higher level norm is to enable the subsequent choices to be justified by the decision analyst and the decision maker. We then identify and discuss a series of requirements that the notion of justification should embody.\end{changebar}

%Many \acp{DM} requesting decision support, many concerned stakeholders and the general public typically expect that applications of decision sciences to concrete problems lead to recommendations. But in fact decision sciences obtain conclusions containing recommendations conditioned by norms or normative conceptions. This article explores the attitudes with respect to norms that can be identified in the academic literature. We argue that these attitudes share a critical blind spot: they evacuate or trivialize the task to help the \ac{DM} to make up her mind about norms. As an alternative to these attitudes, we introduce and recommend a higher level norm, on the basis of which, in a given decision situation, a decision analyst can decide, together with the \ac{DM}, whether a given sub-norm or recommendation can be adopted. The point of this higher level norm is to enable to \emph{justify} the subsequent choices. We then identify and discuss a series of requirements that the notion of justification should embody.
\end{abstract}
\acresetall
\begin{keyword}
Decision Analysis, Normative Economics, Legitimacy, \begin{changebar}Morality\end{changebar}, Ethics of Operational Research
\end{keyword}

\maketitle

\section{Introduction}
When analysts use decision sciences to tackle a given concrete problem, they are commonly expected by \acp{DM}, concerned stakeholders and the general public to formulate recommendations $R$. 
Such $R$ are inevitably conditioned by norms, normative conceptions or value judgments $N$ \citep{funtowicz_science_1993,brans_ethics_2002,mingers_ethics_2011}. 
\commentYM{add here Williams, T. (2008). Ethics. In Management Science in Practice (pp. 277-290). Chichester, UK: John Wiley \& Sons, Ltd.}
\begin{changebar}We understand this $N$ in a very broad sense, and take it to refer to any element that analysts have to associate with factual statements in order to derive recommendations. 
They may include or reflect implicitely or explicitely held philosophical stances concerning objectives of decision analysis in general, professional deontology, the ethics of analysts' relationships with clients, but also norms specifying good practices in using various methods, and so on.\end{changebar}

\begin{changebar}
This importance of norms is largely acknowledged in the \ac{OR} literature \citep{churchman_operations_1970,taket_undercover_1994,brans_ethics_2007,picavet_opportunities_2009}, 
because ``\ac{OR} is a human activity in which \ac{OR} workers engage with other humans to improve human-activity systems'' \citep{ormerod_operational_2013}, which unavoidably raises ``explicit or implicit moral issues'' \citep{diekmann_moral_2013}.
``Soft \ac{OR}'' approaches are said to have increased the awareness of these ethical dimensions, by emphasizing that defining a problem unavoidably involves choices with ethical dimensions \citep{ulrich_beyond_2003}.\end{changebar}

\begin{changebar}
There is now a large consensus, in both \ac{OR} and economics \citep{buchanan_positive_1959, sen_nature_1967, dwyer_scientific_1985, heath_value_1994, sen_rationality_2004, mongin_value_2006, sen_idea_2009, baujard_value_2013},
that objectivity and scientific neutrality, if understood in an absolute sense, are unachievable and irrelevant \citep{le_menestrel_ethics_2004,reisach_creation_2016}. However, most authors also claim that \ac{OR} analysts have a duty to remain neutral with respect to \acp{DM} 
-- a duty echoing Kant’s tenet of duty ethics, translated by \citet{reisach_creation_2016} as a right that every human being enjoys to set her own objectives.
\citet{gass_ethical_2009}'s ``Oath of Prometheus'' similarly starts with a reference to \ac{DM}'s goals.\end{changebar}

\begin{changebar}
A weaker form of neutrality, encapsulated in the requirement to refrain from being \emph{dogmatic, paternalist, proselyte, or authoritarian} in our interaction with \acp{DM}, is hence largely accepted.
However, because ``most contributions to the ‘ethics’ of \ac{OR}, well-taken as they are in drawing our attention to the value content of all \ac{OR} practice, tell us (...) little about how to handle ethical conflicts'' \citep{ormerod_operational_2013},
this literature barely explores how to make sure that analysts' and \acp{DM}' values do not diverge.\end{changebar}
The present article attempts to contribute to answer \begin{changebar}to\end{changebar} this question.

\begin{example}
Let us introduce a simple example, to be used in the entire article. %We will structure this example as a Russian doll, with an abstract example and its concrete instantiation in a concrete setting. 
We start with an abstract presentation, which we then instantiate in a concrete setting.

Imagine that an analyst is asked by a \ac{DM} to help him decide whether he should implement a given project $P$.
The analyst uses \ac{CBA} \citep{layard_cost-benefit_1994} and ends-up formulating a recommendation $R$ = “$P$ should be implemented”.
This recommendation is not unconditional.
Thanks to her analysis of the context and her computations, the analyst derives $R$ from norms $N$, entrenching the relevance of using \ac{CBA} to decide whether $P$ should be implemented.
In this case, $N$ contains norms characterizing philosophical or ethical stances, including a version of utilitarianism stipulating that one should maximize the sum of a measure of preference inferred from willingness to pay \citep{meinard_ethical_2016}. 
But $N$ also encompasses other norms, more or less clearly articulated, referring to the usual requirements for a \ac{CBA} to be considered to be ``properly'' implemented, such as the claim that the preferences taken into account in the study are the relevant ones,
that no important costs and benefits was ignored, that the preference elicitation methods used correctly capture preferences, etc.

A concrete instantiation of this abstract example is given by the request, through a public procurement procedure, by the local administration in the Var Department (South-east France), in 2013, to analyze a project to restore dry grasslands in the Lachens summit, 
a natural mountainous area destroyed by the construction of military buildings which are now abandoned \citep{meinard_etude_2015}.
In this concrete instantiation, $R$ refers to a recommendation to restore dry grasslands. 
The elements composing $N$ refer, among other things, to the claim that the analyst properly implemented the relevant protocols, 
that he properly identified the whole set of relevant stakeholders to include in his survey, that he properly computed the value of the various ecosystem services that could accrue from the restored dry grasslands, etc.

In both contexts, the question that we aim to tackle is: when, as decision analysts, we apply decision sciences to solve the practical problems at issue, how should we handle the anchorage of our recommendations in norms, so as to remain neutral (in the sense given above to this term)?
\end{example}

\begin{changebar}
We tackle this question as part of a broader research program analyzing the role of researchers in decision support, in particular in public policy, in the wake of questions initially articulated by \citet{tsoukias_policy_2013}.
This program includes analyzes of the concepts of legitimacy \citep{meinard_what_2017}, meaning \citep{meinard_utility_2018}, rationality \citep{meinard_rationality_2019} and argumentation \citep{cailloux_formal_2018}, 
and applications in environmental policy evaluations \citep{jeanmougin_mismatch_2017} and recommendations \citep{choulak_meta-decision-analysis_2019}.
The present article pursues these efforts by addressing the role of the norms underlying decision support interventions.\end{changebar}

We begin (in \cref{sec:existing}) by exploring attitudes of decision analysts with respect to $N$ in the economic and philosophical literature. 
We argue that these various attitudes share a critical blind spot: they evacuate or trivialize the task to help the \ac{DM} to make up her mind about $N$. 
By contrast, we argue (in \cref{sec:recomm}) that this task is pivotal, and that decision analysts should endorse a “higher level” norm $\adv$, embodying the requirement to produce \emph{justifications}, understood in a specific sense that we elaborate. 
We call $\adv$ a “higher level” norm because $\adv$ can be used to establish if this or that $N$ can be used in a given application of decision sciences, but in itself $\adv$ is too abstract for any $R$ to be directly derived from it.
We use here a comparative term (“high\emph{er}”), because our point is simply that $\adv$ does not play the same role as $N$, and places itself “upstream” $N$ (elaborating a precise and complete typology of norms falls beyond the scope of this article).
We flesh out $\adv$ as a series of four simple rules that applications of decisions sciences should follow in order to help the \ac{DM} make up her mind about the normative elements underlying the decision analysis she is provided with. \Cref{sec:concl} then briefly concludes.

\section{Varieties of attitudes with respect to \protectforpdf{N}}
\label{sec:existing}
In this section, we review attitudes with respect to $N$ in the economic and philosophical literature.
\begin{changebar}
Our approach to establish this typology is interpretative: we infer a proposal for a classification based on our knowledge of the literature in economics, philosophy and \ac{OR}.
Like any hermeneutic claim, our proposed typology is tentative.
We distinguish four attitudes ($A_O$, $A_E$, $A_I$ and $A_J$) which are reminiscent of \citet{le_menestrel_ethics_2004}'s distinction between ``ethics outside'' (echoing our $A_O$), ``inside'' (echoing $A_E$) and ``beyond the model'' (of which $A_I$ and $A_J$ can be seen as variants). 
However, our topic is broader, since we are interested here in the role that norms $N$ play in a decision support process as a whole, not only in models, and we introduce a distinction (between $A_I$ and $A_J$) without conterpart in \citet{le_menestrel_ethics_2004}'s typology.
\commentYM{je trouve que ces quelques lignes tombaient comme un cheveu sur la soupe là où elles étaient... mais je ne suis pas convaincu que ce soit mieux là...} 
\end{changebar}

\commentYM{si on doit raccourcir, je dirais que les annonces de plan au sein des sections sont dispensables}
%We begin by exploring the literature in decision sciences and argue that this literature tends to evacuate the task to help \acp{DM} to make up their mind about $N$.
%However, this literature points towards an interesting solution, which consists in referring to a higher level norm.
%We then explore attempts to elaborate this idea in the philosophical literature, and argue that these attempts are unsuccessful as they stand.

\subsection{Elusive economic attitudes with respect to \protectforpdf{N}}
\subsubsection{\texorpdfstring{$A_O$}{AO}: The elusive search for ``basic'' \protectforpdf{N}}
In normative economics, a widespread approach, which we will call $A_O$ (``$O$'' stands for “obvious”), consists in insulating supposedly simple and clear norms. 
Such norms $N$ are considered to be simple enough to let \acp{DM} decide, without the help of the analyst, if they endorse them. It is then possible to derive $R$ from the chosen $N$.

Identifying such simple $N$ however proves more difficult than one might expect. 
Indeed, as \citet{sen_nature_1967} observes, a value may appear convincing but fail to be basic, in the sense that there may exist facts whose knowledge would lead an individual, originally supporting this value, to cease to support it. 
Or a value may conflict with another value, and the individual may cease to support one of them upon realizing this conflict.
Because this might hold even for norms such as Pareto Dominance \citep[ch. 5 and 6]{sen_collective_1984}, $A_O$ appears untenable.
To illustrate this idea, consider \citeauthor{arrow_social_2012}’s \citeyearpar{arrow_social_2012} theorem.
It shows that Dictatorship follows (in some formal context) from the axioms of Universal Domain, Pareto Dominance, and Independence of Irrelevant Alternatives.
One can easily imagine that individuals would accept each of these axioms as capturing value judgments they endorse about what they demand from a voting rule, if the axioms were explained to them by focusing only on what each axiom demands separately, even though they would reject Dictatorship.
This example shows that one cannot rest content with the bare fact that a norm $N$ seems self-evident in the abstract, since one can reject a seemingly self-evident $N$ on due reflection, once one has come to realize some of $N$'s implications.

$A_O$ hence flouts neutrality by surreptitiously accepting the unwarranted premise that 
some norms $N$ can be found about which \acp{DM} can readily make up their mind.

\subsubsection{\texorpdfstring{$A_E$}{AE}: choosing \protectforpdf{N} that Decision Makers % \acp{DM}
 “would endorse if they could understand”}
%$A_O$ is an attitude whereby analysts claim to use decisions sciences while leaving $N$ outside the purview of their scientific inquiry. We have argued that this attitude fails because it is predicated on the implausible premise of the existence of “obvious” norms from which recommendations can directly follow.

A second attitude, $A_E$ (where ``$E$'' stands for “expert”), consists in claiming that \acp{DM} cannot systematically take the time to strive to understand $N$ or are not always willing or able to do so. 
Decision scientists holding this attitude claim that they have the collective skills to understand decision science and discuss among peers whether this or that $N$ should be accepted. 
But they do not consider that \acp{DM} should take part in such discussions, because these are technical, difficult discussions. 
When they arrive at conclusions including recommendations $R$, predicated on $N$ encapsulating axioms that decision scientists collectively deem commendable, they consider themselves entitled to jump to $R$ without bothering to help \acp{DM} to make up their mind about $N$. 
% Indeed, this would be a waste of time and energy. 
%At most the decision analyst will invest some time to explain to the \ac{DM} why it was a good idea to endorse $N$. %, or will content himself to think that, if the \ac{DM} were able to understand the axioms, he would endorse $N$.
\begin{changebar}
This attitude is illustrated by \citet{brans_ethics_2002}'s call for ``independent ethical experts'' to take charge of the ``ethical pole'' of decision support.% might be seen as a champion of $A_E$, at least in a plausible interpretation of his texts. He writes that: 
\end{changebar}

%\begin{addmargin}[3em]{3em}
%“\emph{the expected utility theory (...) as formulated by the von Neumann-Morgenstern axioms, is normative in the sense that the theory is ‘absolutely convincing’ which implies that men will act accordingly. If they deviate from the theory, an explanation of the theory and of their deviation will cause them to readjust their behavior. This is similar to the man who tries to build a perpetuum mobile and then is shown that this will never be possible. Hence, on understanding the underlying physical theory, he will give up the vain effort. Or, an individual making a mistake in, say, long division, will clearly correct himself when shown the mistake.}” 
%\end{addmargin}
%If understood as referring to a usage of expected utility theory aimed at producing recommendations, this excerpt embodies attitude $A_E$: it \begin{changebar}considers that expected utility theory should convince everybody\end{changebar}.
%(Notice, however, that the above quotation can also be interpreted as referring to a purely mathematical version of utility theory that does not lead to any recommendations, and therefore falls outside our scope.)

Attitude $A_E$ consists, for the decision analyst, in endorsing a higher-level norm $\mathscr{N}_E$ claiming that expert discussions about norms enable them to make decisions about norms on behalf of \acp{DM}, a questionable moral stance that \citet{estlund_democratic_2009} calls the ``expert/boss fallacy''. 
It is unlikely that many decision scientists really wholeheartedly endorse it. 
Besides, to \begin{changebar}the best of our knowledge\end{changebar}, the literature does not specify what is precisely required (when adopting  $\mathscr{N}_E$) for an expert to decide that “enough” discussion has taken place in the expert community and that a consensus has been reached concerning a given $N$. 
Furthermore, the fact that a norm has been considered acceptable in the abstract by the scientific community does not guarantee that it is acceptable in its use by the analyst in a concrete context.

\subsubsection{\texorpdfstring{$A_I$}{AI}: informally testing whether \aclp{DM} endorse \protectforpdf{N}}
The blatant weaknesses of $A_E$ suggest a pragmatic variant, $A_I$, with $I$ standing for “informal”. 
This is the attitude of decision analysts who reject $A_E$'s idea that decision scientists can decide on $N$ on behalf of \acp{DM}, and therefore make a point \begin{changebar}of informally discussing\end{changebar} the meaning of $N$ with \acp{DM} to verify that %the specifics of the situation are such that 
$N$ appears endorsable to the \acp{DM}.%, or to let the \acp{DM} choose or parameterize the norms applicable to the situation.

\citet{roy_multicriteria_1996} can be seen as a prominent supporter of $A_I$. 
Indeed, although he did not use the term “norm” to refer to elements underlying recommendations, he emphasized the need to develop interactions with the \ac{DM} to ensure that, not only the recommendations, 
but also the building blocks of the decision support process from which they derive should be ``meaningful'' for the \ac{DM}.
%\begin{addmargin}[3em]{3em}
% “\emph{the analyst has to interact
%with the \ac{DM} (or with his representative), in view of co-constructing the model of preferences that the considered method exploits to work out expected results. A key issue is to organize this interaction such that the analyst is able to
%elaborate meaningful results. This implies that the interaction protocol or the
%software tool involved should be compatible with the way in which the analyst has
%been inserted in the decision process, with the way of reasoning of the inquired
%people, and with their meaning of useful results.}” \citep[pp. 84--85]{roy_questions_2013}.
%\end{addmargin}
This meaningfulness requirement can be interpreted as a need to render the various elements of the decision support process intelligible for the \ac{DM}.
And because $R$ are necessarily anchored in norms $N$, this intelligibility requirement, when applied to the elements of the decision support process embodying $N$, unavoidably includes a requirement that the \ac{DM} \emph{endorse} $N$. 
It therefore seems fair to claim that \citet{roy_multicriteria_1996} implicitly championed a requirement to informally test whether \acp{DM} endorse $N$. 
As another example, one can think about \citet{raiffa_back_1985}’s claim that, in some cases, discussions with \acp{DM} rejecting subjective expected utility theory can lead them to accept it after all.

The problem with $A_I$ is that it combines a scientific approach to arrive at $R$, with an informal, loose approach to lead \acp{DM} to make up their mind about $N$.
Like $A_E$, it is anchored in a higher level norm $\mathscr{N}_I$. But this higher level norm is not clearly articulated. It encapsulates the idea that decision analysts cannot make decisions about $N$ on behalf of \acp{DM}, but does not specify precisely what they should do.


\begin{changebar}
\subsubsection{\texorpdfstring{$A_J$}{AJ}: loosely justifying \protectforpdf{N}}
\commentYM{we have to find a better term: ``loosly'' is too contemptuous}

%This reference to \emph{justification} is pervasive in the literature.
%echoes contemporary debates on the role of scientific expertise in policy making, which is often presented as undergoing a crisis of \emph{confidence} \citep{godard_environnement_2015}. 
%As a response, many expertise settings, \begin{changebar}{procedures} and institutions have evolved (in more or less successful attempts to restore the lost confidence) to increase \emph{transparency}, \emph{pluralism} and \emph{independence}. 
%These three criteria are largely accepted as requirements to impose on any expertise. 
%However, they cannot be considered as absolute and applicable in all situations. 
%As \citet{godard_environnement_2015} points out, in some situations, an excessive transparency can cripple expertise, and independence is, in many respects, unachievable: \begin{changebar}{all experts have their interests}. 
%Similarly, pluralism denies the very idea that expertise can have a point, if it means that all opinions, however fanciful or extremist, should be given the same weight. Accordingly, these three criteria are better conceived as implications of a more fundamental principle: the need to justify expert opinions. 
%\citet[][p. 379]{godard_environnement_2015} mentions this idea in passing, in the case of independence: “the right question is not `tell me to whom are you tied', but `tell me which arguments justify your opinion'”. 
%But a similar rationale applies to the other two criteria: the point of requiring transparency is to render visible the justifications underlying the various expert opinions, or the lack thereof; the point of pluralism is to expose justifications to a large sample of counter-arguments, as diverse as possible.

Although they do not explicitly tackle our problem, many authors in the literature, especially in ethics and methodology of \ac{OR}
endorse a fourth attitude that can seem to offer a solution to our problem. This candidate solution consists in advocating that analysts should \emph{justify} the decision support they provide, and in particular should justify the $N$ from which their recommendations derive.
For example, \citet{lahtinen_why_2017} advocate \ac{OR} practices following an ``ideal path'', ``formed by well-\emph{justified} choices''.
Similarly, \citet{diekmann_moral_2013}'s defense of ``transparency'' is explicitly anchored in a justification requirement, defining transparency in terms of ``open communication'' and ``clarification''. His presentation of ``integrity'' explicitly refers to ``justification''.
 \citet{beauchamp_principles_2009}'s criteria to balance principles when they conflict also explicitly refer to justification.
\citet{white_death_1994}'s call to desacralise expertise enjoin experts to justify their intervention.
\citet{jackson_towards_1999} concurs on the importance of justification and goes as far as spelling out``guidelines'' that justifications ``must'' follow to “claim to have used a management science methodology according to a particular rationale''.
\end{changebar}

This requirement for decision analysts to justify themselves
\begin{changebar}(or, equivalently, to limit themselves to use assertions that are ``warranted'')\end{changebar}, is hence often taken as a self-evident, unquestionable premise. 
One might even argue that a willingness to justify is a necessary condition for decision scientists to present themselves as \emph{scientists} \citep{ormerod_justifying_2010}. 
This pervasive reference to a justification requirement is, however, much too vague. Indeed, the term ``justification'' is extremely polysemous. 
In some contexts, one might call any argument, however spurious or ill-conceived, a ``justification''.

%Even if one accepts that a purported justification deserves to be called so only if it satisfies ``standards of quality'' of some sort, the term ``justification'' remains underdetermined, and could mean very different things depending on the nature of the standards at issue.

\begin{changebar}This is illustrated by \citet{jackson_towards_1999}, who spells out in detail the resources that can be used to articulate justification, but does not explore how to ensure that an argument based on his guidelines qualifies as a justification.
Indeed, his ``guidelines'' consist in a table of prototypical arguments that can be used to structure justifications. In that sense, they are more ``buiding blocks'' than ``guidelines''. 
As is stands, $A_J$ hence also appears unsatisfactory because it takes for granted that the notion of justification is transparent and unproblematic, whereas on due reflexion this notion appears ambiguous.
\end{changebar}

\begin{example}
Let us simply illustrate the meaning of attitudes $A_O$, $A_E$, $A_I$ and $A_J$ in our hypothetical scenario of an application of \ac{CBA}.

$A_O$ would mean, for the analyst, that she claims that it is clear and evident for \acp{DM} to decide whether they endorse, not only preference utilitarianism, but also all the more or less clearly articulated norms specifying all the requirements for a \ac{CBA} to be considered to be ``properly'' implemented.

$A_E$, by contrast, acknowledges that \acp{DM} can find it difficult to understand the meaning of this $N$, and might be at a loss trying to decide whether they should endorse it. 
An analyst adopting $A_E$ would hence fall back upon a community of researchers endorsing $N$ to take the decision to endorse $N$ on behalf of \acp{DM}.

An analyst adopting $A_I$ would find $A_E$ unacceptable, and would informally strive to discuss with the \ac{DM} to help him decide whether he endorses $N$. But to accomplish this task, the analyst will be left without a rigorous methodology.
\begin{changebar}
Similarly, an analyst adopting $A_J$ would make a point to justify the $N$ from which her recommendation derive, but for lack of a deeper analysis of what ``justification'' amounts to, she would find herself incapable of telling whether or not the justification she produces is a good justification.
\end{changebar}
\end{example}

\subsection{Philosophical explorations of higher level norms}
\label{sec:higher}
We argued in the former subsection that the attitudes currently found in the decision science literature are unsatisfactory. 
$A_E$ and $A_I$ however suggest an interesting solution, which consists in referring to a higher level norm, and $A_J$ goes a step further by claiming that this higher level norm might be a justification requirement. 
The philosophical literature contains interesting, deeper explorations of this idea, in particular in debates (which might seem at first sight quite remote from the subject matter of the literature on decision sciences) on “purely procedural” vs. “substantive” normative theories of justice and democracy.

Substantive theories account for justice and democracy by explicitly referring to values, whereas purely procedural normative theories strive to evacuate value judgments. 
\cite{rawls_political_2005}'s normative theory of democratic legitimacy is a classical example of a purely procedural theory. 
Rawls did not want his theory to make any value judgment about the kind of state of affair that should prevail in a democratic society. 
He therefore argued that a policy is democratically legitimate if it is based on a constitution whose justification is acceptable by all  “reasonable” citizens. 
But he did not want to make value judgments about democratic processes either. He therefore further argued that the very definition of reasonableness should be something for reasonable citizens to pick-up. 
He thereby attempted to eschew making any value judgments in his account of legitimacy and reasonableness. 
This was supposed to be a complete ``flight from substance'' \citep{estlund_democratic_2009}, in the sense that this account was supposed to eschew all forms of value judgments.
% If this reasoning were successful, it would allow to derive $R$ from $N ⇒_c R$ by removing the value judgments from $N$, rendering it innocuous to endorse.

This approach hence elaborates on the idea to produce justification, anchors this idea in a reference to acceptability, but strive to eschew specifying criteria to distinguish acceptable justifications from non-acceptable ones.

This approach arguably fails, however, for reasons articulated by \cite{habermas_reconciliation_1995} and \cite{estlund_democratic_2009}. 
\citet{estlund_democratic_2009} noticed that, if one accepts, following Rawls, that the notion of reasonableness should be selected by reasonable people themselves, then there is an “impervious” plurality of groups that could select themselves as being “reasonable”. 
He concluded that rawlsian political philosophers have no choice but to render the concept of reasonableness more precise, by specifying the values underlying it. 
\cite{habermas_reconciliation_1995} criticizes Rawls's presentation of his notions of “veil of ignorance” and  “overlapping consensus” as \emph{devices} whose real-life functioning can give rise to principles of justice. 
According to \cite{habermas_reconciliation_1995}, these notions are rather rhetorical tools thanks to which Rawls exposes principles of justice that he surreptitiously deduces from various philosophical notions, such as the one of a moral person, which he (perhaps unconsciously) presupposes. 
Rawls's ``flight from substance'' hence collapses in a retreat back to the substantial inquiry into the nature and features of a moral subject.  Rawls's theory therefore appears to be anchored in a higher level norm $\mathscr{N}_R$, but this higher level norm is not thematized as such in his philosophy.

By contrast, in his debate with Rawls on the theory of justice, Habermas goes a step further by analyzing the higher level norm underlying his own theory (though he does not uses this vocabulary). 
\citet{habermas_moralbewustsein_1983}'s “weak” transcendental deduction of the tenets of “discourse ethics” from communicative action is particularly interesting in this respect. 
\citet{habermas_theorie_1981} argues that agents communicating with each other make validity claims of three sorts: veritative claims about truth, normative claims about values and norms, and authenticity claims about expressions concerning their inner life, feelings and consciousness. 
The role that norms play is therefore clearly circumscribed in Habermas's framework, and it concerns one kind of validity claims among others. 
\cite{habermas_moralbewustsein_1983} does not locate the tenets of “discourse ethics” at this level. 
He rather argues that all the acts and deeds that consist in making validity claims are oriented by a strive for intercomprehension, which lies at the core of communicative action. And he identifies the tenets of discourse ethics as conditions of possibility for this intercomprehension-oriented activity. 

Habermas's reasoning provides criteria of sorts to elaborate the notion of justification, by anchoring it in his philosophy of society, which refers in turn to his theory of communicative action. 
%helping \acp{DM} to make up their mind about norms. 
Indeed, he identifies an “ethics”, which is presumably something that allows to formulate recommendations. And, according to his views, this ethics justifies itself, or is self-evidently justified,

%But it would be pointless to expect \acp{DM} to make up their mind about the tenets of this “ethics”, because 
because the tenets of this ethics are conditions of possibility for a very basic, all-pervasive structure of human action. 
%Like $A_E$, Habermas's approach is therefore anchored in a higher level norm, $\mathscr{N}_{H}$, capturing the tenets of discourse ethics. 
%A formulation of this higher level norm is: “For a norm to be valid, the consequences and side effects that its general observance can be expected to have for the satisfaction of the particular interests of each person affected must be such that all affected can accept them freely” \citep{habermas_moralbewustsein_1983}. 
Just like $\mathscr{N}_E$, Habermas' higher level norm $\mathscr{N}_{H}$ does not directly allow to deduce recommendations $R$. 
But, as opposed to proponents of $A_E$, Habermas provides foundations to entrench his $\mathscr{N}_{H}$ and, as opposed to proponents of $A_J$, these foundations provide Habermas with a reason to claim that a justification based on these foundations is a good justification. 

These foundations are, however, derived from his very specific understanding of communication and its importance in the functioning of human societies, which has been extensively criticized in the literature \citep{heath_communicative_2001,honneth_kritik_1985,benhabib_situating_1992}. 

\commentYM{s'il faut raccourcir, je pense qu'on peut virer le petit bilan d'étape ci-dessous}
By anchoring itself in a higher level norm $\mathscr{N}_E$, $A_E$ paves the way for a satisfactory solution to our problem in this article. 
$A_I$ overcomes $A_E$'s shortcomings by pointing the need to find a better higher level norm than $\mathscr{N}_E$, but fails to articulate one. Similarly, Rawls's approach is anchored in a higher level norm $\mathscr{N}_{R}$ that he fails to account for. 
Habermas goes a step further by entrenching his higher level norm $\mathscr{N}_{H}$ in his philosophy of society. In the sections to come, our aim is to follow this lead and identify a more relevant higher level norm $\adv$, not derived from Habermas's disputed vision of communicative action. 
%(This ambition contrasts with \citet{mingers_ethics_2011}, who deems that the limits of Habermas's discourse ethics are outweighed by its relevance to operational research).% -- a stance that we do not demean, but whose counterpart we aim to explore.)

\section{The recommended model}
\label{sec:recomm}

%In this section, our aim is to identify a higher level norm $\adv$, on the basis of which, in a given decision situation, a decision analyst can decide, together with the \ac{DM}, whether a given $N$ can be adopted. 
%In order to identify this $\adv$, let us assume that the point of this higher level norm is to allow to \emph{justify} the choice of a given $N$.

In this section, our aim is to elaborate on the idea outlined by $A_J$ and (according to our argument) unsatisfactorily elaborated by Rawls and Habermas, that a convenient higher level norm $\adv$ should embody a justification requirement.

We begin with the notion of justification in general, assuming that, at this level of generality, a justification requirement is innocuous. 
% (deeper investigations of the soundness of this premise are part of the larger agenda that includes the present article, but fall beyond our scope here -- see \citet{meinard_2018}).
We then progressively clarify and flesh out this idea so as to articulate a concrete notion of justification. Such a concrete notion should no longer be ambiguous, and should enable us to identify a satisfactory $\adv$. 
To that end, our approach will be similar to the one typically used in ordinary language philosophy \citep{soames_philosophical_2003}: 
we will draw on everyday intuitions about the meaning of the term ``justification'', and strive to progressively sharpen a specific definition that the term should take in order to play the role that we want it to play, in the very specific context in which we want to use it. 
To do so, we will take advantage of the arguments developed above against the various attitudes presented in the former section. 
Using the terminology of ``justification'', these arguments can be summarized by saying that these attitudes are anchored in higher level norms that provide \emph{unsatisfactory justifications} to adopting norms $N$ in various decision situations, 
in some yet unclarified understanding of the phrase ``unsatisfactory justification''. We will use these arguments to clarify the language intuitions underlying the idea that the above attitudes provide \emph{unsatisfactory justifications}. 
This will then enable us to sharpen our understanding of the idea of a \emph{satisfactory justification} in our context.

In the two subsections below, using this \begin{changebar}approach\end{changebar}, we identify a series of requirements that the notion of justification should embody (these subsections draw on provisional ideas introduced by \citet{meinard_du_2013, meinard_what_2017}). 
The third subsection then presents a set of practical rules that materialize these requirements and participate in fleshing them out. These practical rules specify the attitude that a decision analyst should have, if he sets himself the task to produce \emph{satisfactory justifications} for the $N$ grounding of his $R$.

\subsection{Three requirements}
%A first, almost trivially unadapted notion of justification should be eliminated straightaway. This is the extremely large notion %(already mentioned above) 
%that would call ``justification'' any discourse designed to buttress a given $N$, whatever its characteristics, independently of any standard of any sort (standards of clarity, rigorousness, convincingness and so on). 
%In this extremely large understanding of ``justification'', the phrase ``unsatisfactory justification'' is a contradiction in terms, and the idea that the attitudes explored in the former section exemplify ``unsatisfactory justifications'' is void.

Any notion of justification should be specified by criteria. But what criteria should one use? Here we introduce three requirements encapsulating the criteria that, we argue, are relevant to capture the notion of justification that we need.

\subsubsection{Incrementalism}
As we have seen, $\mathscr{N}_E$ encapsulates a criterion: $N$ should be considered consensual among decision science experts. $\mathscr{N}_E$ presupposes that this criterion is clear and determined. However, one cannot find, in the literature, any elaboration of how this criterion is supposed to be checked. 
This blind spot obfuscates the idea that such a consensus, if it existed, would certainly evolve as decision science knowledge improves. 
A more satisfactory version of $\mathscr{N}_E$ would hence clarify the meaning of this criterion, and would thereby in particular highlight that the content of the criterion is liable to change as knowledge improves, incrementally. The same idea applies to $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$. 
We have seen that the former is anchored in an implicit philosophy of the moral subject, and the latter in a theory of society. 
But both theories can be questioned, and more satisfactory versions of $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$ should accept and openly display their provisional status 
(\cite{habermas_moralbewustsein_1983} does emphasize this point -- discussing whether this claim is coherent with the larger habermassian framework falls beyond the scope of this article).

This first analysis of part of the shortcomings of $\mathscr{N}_E$, $\mathscr{N}_{R}$ and $\mathscr{N}_{H}$ hence suggests the need to integrate, in our notion of justification, an \emph{incrementalism} requirement, 
holding that it is illusory to claim to be able to capture a definitive list of criteria defining what is a satisfactory justification. According to “incrementalism”, one had better work incrementally, to improve step by step one's understanding of the relevant criteria. 
“Incrementalism” reflects the idea that even experts have limited capacities to identify definitive solutions to the problems they are entrusted to tackle, and therefore their conclusions cannot be considered to be definitive solutions.

\subsubsection{Anchorage in real-life acceptability}
Another problematic feature that our exploration of $A_E$ illustrated is that it conceives the elaboration and application of $\mathscr{N}_E$ as tasks for decision scientists alone to tackle. 
By contrast, Rawls and Habermas wanted their theories not to grant the philosopher the right to preempt discussions concerning $N$ -- an idea also supported by attitude $A_I$. 
Rawls introduced this idea thanks to his notion of ``reasonableness'', which \citeauthor{estlund_democratic_2009} rearticulated at a more general level as an acceptability requirement. 
We have seen that, at least according to \citeauthor{habermas_reconciliation_1995} and \citeauthor{estlund_democratic_2009}, Rawls's argument is flawed. 
But a core underlying idea remains, in our view, pivotal to elaborate a relevant notion of justification: whether a justification is satisfactory should depend on how people in the flesh receive and react to purported justifications.
\begin{changebar}
If we want to identify criteria distinguishing acceptable from unacceptable justifications, instead of searching for such criteria through theoretical reflection, we should take the stance that consists in putting justifications to the test in real-life situations, 
so as to improve gradually our blunt understanding of what it means for a justification to be acceptable.
\end{changebar}

\subsubsection{Interventionism}
The latter requirement might suggest the following approach, inspired by the sociological literature on “orders of justification” \citep{boltanski_justification_2006}. 
According to this literature, various groups in various situations typically refer to different and largely irreconcilable “orders of justifications”, which can (according to some authors at least) be formalized as sets of normative axioms accepted by some groups but rejected by others.

Drawing on this literature, one could set out to use sociological surveys determining in which groups the people concerned by a given application of decision sciences fall, and produce recommendations justified by the axioms endorsed by those people in the situation at issue. 
Such an approach can be seen as a refinement of $A_O$: it accounts for cases where different people find different norms self-evident, but it still requires that people judge by themselves whether they consider a given norm to be self-evident. 
In particular, it might be that people accept some norms only because they have not realized all their implications.

In order to integrate such reactions, we need a notion of justification that does not reduce the acceptability of justifications to the bare acceptance of discourses. 
This requirement obviously echoes \citeauthor{habermas_reconciliation_1995}’s and \citeauthor{estlund_democratic_2009}’s criticism of Rawls's notion of “reasonable”: 
if it is to make sense, Rawls's theory cannot be about justifications that real people usually accept or will accept, it must be about justifications that citizens \emph{would} accept, if they were reasonable. 
\citet{habermas_faktizitat_1992} forcefully emphasizes this counterfactual aspect in his theory of legitimacy, but this leaves his approach vulnerable to the criticism that he talks about counterfactual worlds in outer space. 
In our view, the important idea that Habermas's reasoning conceals is that the notion of acceptability is only convincing if one accepts that the philosopher or the decision scientist, trying to capture what people can find acceptable, 
allows himself to interact with those people, and thereby goes beyond the approach championed by authors like \cite{boltanski_justification_2006}.


%\subsection{Conjoining the three requirements: primacy of practice}
%But how can one know that a justification is acceptable in this sense? %We have seen above that \cite{estlund_democratic_2009}'s solution would consist, for the philosopher, in making bold claims about the truth of the criteria used to sort out what is acceptable and what is not. 
%But a major problem with such an approach is that it contradicts our above requirements of \emph{incrementalism} and \emph{anchorage in real-life acceptability}. In order to overcome this problem, 
%Our proposal is that the relevant notion of justification should embody the following tenet of “primacy of practice”: 
%instead of searching for acceptability criteria through theoretical reflection, one should take the stance that consists in putting justifications to the test in real-life situations, so as to improve gradually our blunt understanding of what it means for a justification to be acceptable. 
%In this approach, purported justifications deserve to be called so depending on whether they satisfy some criteria. These criteria are a matter of confronting purported justifications to their real-life acceptability by people in the flesh (echoing the \emph{anchorage in real-life acceptability} requirement). 
%This acceptability is in turn not reduced to factual acceptance (echoing the \emph{interventionism} requirement). It rather refers to acceptance conditioned by purported justifications being put to the test, tentatively and iteratively (echoing the \emph{incrementalism} requirement).

\subsection{Unfolding practical rules}
Obviously enough, though our analysis in the former subsections allowed us to flesh out the notion of justification to some extent, it still is indeterminate in an important respect. 
We still have to describe more precisely what it means to ``put purported justifications to the test''. This subsection is devoted to describe a practical procedure that decision analysts should follow to do that. 
The features of this practical procedure are derived from the understanding of the notion of justification spelled out in the former subsections. 
(The tenets constituting our practical procedure bear a resemblance with \citeauthor{diekmann_moral_2013}’s \citeyearpar{diekmann_moral_2013} ``mid-level'' moral principles, but they aim to be more general -- not being limited to a specific activity such as modeling -- 
and are not derived from moral theories, but rather from our higher level norm $\mathscr{N}$, which is designed to be more fundamental.)

\citet{meinard_what_2017} attempted to elaborate a practical procedure of that sort in an exploration of the concept of legitimacy. Here we will translate some elements of this approach to our context, and also address what we take to be weaknesses, so as to unfold a more satisfactory account. 
Our proposed practical procedure will be articulated in four points.

\begin{changebar}
A first requirement is designed to capture the idea that, as application of “Anchorage in real-life acceptability”, in a context where an analyst offers a recommendation $R$ to a \ac{DM}, 
the fact that the analyst endorses $\adv$ should first and foremost take the form of his actually articulating justifications in such a way that the \ac{DM} understands it and is convinced by it.
\end{changebar}

In this setting, our first requirement (\cref{it:argue}) can be articulated as follows: \emph{Systematically display arguments in favor of the $N$ from which our recommendations derive.}

\begin{changebar}\commentOC{Shouldn’t we move this to the part where we say that justification is always provisional? This remark simply highlights another way that justification can fail to be perfect. 
Forgetting to speak about a norm because it’s a hidden assumption is a bit like forgetting to phrase a counter-argument because nobody has thought about it.} 
\emph{il me semble plus pertinent de laisser ça là, car je pense que beaucoup de lecteurs piqués à l'herméneutique risquent de tiquer comme l'a fait notre reviewer 2, en arrivant à ce point de l'argument, et si l'on répond seulement plus loin à cette réaction, on aura perdu le lecteur entre temps. Mais c'est juste de la rhétorique, je ne suis pas figé sur cette question}
We emphasize that this task is more difficult than one might think at first sight.
Clarifying the $N$ that the analysts endorses, often implicitly, requires hermeneutic, communicative and interactive explorations which are no less complex than those involved in clarifying the goals of the various people involved in a decision process \citep{reisach_creation_2016}.
Besides, as \citet{cronin_issues_2014} point out, ``Often participants may not even be aware of the preconceptions, or assumptions, that they are taking for granted'' and interactions with \acp{DM} 
``are inevitably subject to various constraints some of which arise pre-consciously as a result of historically acquired competences and predispositions to operate in particular ways'' \citep{brocklesby_ethics_2009}.
Unfolding \cref{it:argue} is therefore a difficult task that can prove useful for the analyst himself to clarify his own assumptions, and one cannot assume that the exercise will always be successful.\end{changebar}

A second point should prevent our using justifications that happen to be accepted, as a matter of fact, at the moment when we articulate them, but whose weaknesses are concealed. 
This point embodies “incrementalism” and ``interventionism'', by claiming that, once we have found arguments in favor of something, we should try to look for ways through which they could be discarded. 
Real-life examples of decision-aiding practices that flout this clause are given in \cite{meinard_what_2017}, which lead him to introduce a requirement to be ready to defend one's recommendations against criticisms, even when none are formulated. 
This requirement is insufficient, however. Indeed, an account associating it with \cref{it:argue} would be impaired by a worrying weakness, which can readily be identified by referring to the literature on epistemic injustice \citep{fricker_epistemic_2007} 
(this problem is not addressed by \cite{meinard_what_2017}, and is also left aside by \cite{mingers_ethics_2011}, who mentions this issue without exploring it when acknowledging a limit to his own framework under the heading ``Engagement and inclusion''). 
Some people and groups have access to knowledge, others have not. The former are in a position to articulate criticisms, the latter are not. 
By imposing that decision analysts should be ready to defend their recommendations, the above approach exposes applications of decision science only to part of the spectrum from which criticisms can come. 
What if many criticisms could have been addressed at us, but none were, because of epistemic injustices? In such a case, we cannot confidently claim that our approach materializes satisfactory justifications. There is therefore something amiss in the above account.

One might suggest that the problem could be fixed by identifying a specific group of people that should be the source of criticisms, or even a procedure that should be used to encourage the formulation of such criticisms. 
But this would mean presuming that we have the kind of perfect knowledge needed to identify \emph{the} ultimate procedure once and for all.

The logic underlying ``anchorage in real-life acceptability” offers a solution to this problem. We cannot identify once and for all a perfectly relevant group of people or a perfect procedure. 
What we can do is identify an attitude that will be conducive to more satisfactory justifications, and this attitude is a requirement to actively elicit criticisms.
In some situations, this can imply enlarging the circle of people, groups or institutions involved in the decision process, for example as members of a steering committee.
The inclusion of other people can by itself bring in new insights or information.
  
This requirement, Actively elicit criticisms (\ref{it:criticize}), is the missing element in our account\begin{changebar}; it can fix\end{changebar} its first weakness.

We now need a third clause to allow \cref{it:argue,it:criticize} to fully embody the requirement to put justifications to the test in real-life, instead of confining them to theoretical criteria: Actively defend our recommendations against all criticisms (\ref{it:defend}).
Obviously enough, just like \cref{it:argue}, \cref{it:defend} only makes sense as an application of ``anchorage in real-life acceptability'' because the ``defense'' at issue consists in articulating arguments that the \ac{DM} understands and that convince her.

\Cref{it:argue,it:criticize,it:defend} spell out the attitude of experts who would enact a willingness to justify themselves by displaying the arguments underlying their stances, and by actively being willing to face dissident stances. 
But this account, although completed to fix the weaknesses mentioned above, has another worrying weakness, which can be captured by raising the question: when can one claim that one has produced \emph{enough} justifications? (This weakness was also ignored by  \citet{meinard_what_2017}.) 
Indeed, in practice, whatever the effort one makes to address all the criticisms that one can think about, there is bound to remain infinitely numerous other possible criticisms -- criticisms that one failed to think about, or even criticisms that are not conceivable today, but that will emerge in the future, as knowledge increases. 
\begin{changebar}Demanding that decision analysts abide by this apparently infinite justificatory task\end{changebar} might seem unrealistic.

This problem can be solved by applying ``incrementalism'' to the justifiability of the decision analysis process. 
Incrementalism means that one can never claim that one knows what the right criterion is to sort out acceptable justifications from unacceptable ones: proposed identifications of ``the right'' criterion are always provisional. 
As a consequence, when implementing \cref{it:argue,it:criticize,it:defend}, the decision analyst must develop a provisional account of the justifiability of the decision analysis she provides. 
The decision analyst can claim that her decision analysis is more justifiable thanks to specific actions taken while implementing \cref{it:argue,it:criticize,it:defend}, but not that the decision analysis is justified in an absolute and definitive sense. 
This adds a fourth clause to our account: Understand our own justifiability as unavoidably provisional (\ref{it:provisional}).

To sum up, the model that we recommend is that, as decision analysts implementing decision science in concrete situations so as to provide recommendations, we should:
\begin{enumerate}[label=\emph{\roman*}., ref=\textit{\roman*}]
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
	\item \label{it:argue}Systematically display arguments in favor of the $N$ from which our recommendations derive;
	\item \label{it:criticize}Actively elicit criticisms;
	\item \label{it:defend}Actively defend our recommendations against all criticisms;
	\item \label{it:provisional}Understand our own justifiability as unavoidably provisional.
\end{enumerate}

Clearly enough, applying \crefrange{it:argue}{it:provisional} is unlikely to ensure that we will be able to identify \emph{the} ultimate justification for our recommendations.
For that, we would need to have access to all the possible arguments, all the possibly relevant information, and we would need a perfect definitive definition of what a satisfactory justification is. 
The more modest ambition of the present account is to provide a practical answer to the core question of our inquiry: 
\emph{as practitioners applying decision sciences to the resolution of concrete problems, how can we make sure that the normative aspects of the decision analysis that we provide don't lead us to take liberties with our scientific neutrality by being dogmatic, paternalist, proselyte, or authoritarian?}
The answer that we propose is: \emph{we can make sure that we remain scientifically neutral by applying \crefrange{it:argue}{it:provisional}}.
%\commentOC{In the interest of space, we could remove this end of § (I think I insisted to have it originally but now I wonder what I had in mind).} 
%Obviously enough, unfolding the process epitomized by formula [i-iv] is bound to fail if the \ac{DM} with whom we work stubbornly rejects all our attempts to reason with him.
%In such a borderline case, our core question simply cannot be answered, it is just impossible to provide decision support while remaining scientifically neutral.

\begin{example}
To illustrate the concrete meaning of our reasoning, let us see how it applies to our example of a decision analyst using \ac{CBA} to help a \ac{DM} to decide whether he should implement a given project $P$.

\begin{changebar}To apply clause [i]\end{changebar}, instead of simply using the chosen method without further discussion, the analyst should take upon herself to clarify the norms $N$ underlying her usage of this method, and explain to the \ac{DM} why she deems it relevant to accept $N$ in the case at hand.
An analyst who would miss this step, for example because using \ac{CBA} was part of the requirements of the public procurement procedure through which she was chosen and she assumes that she has nothing to say about the relevance of this requirement, would fail to abide by [i].
\begin{changebar}To apply clauses [ii] and [iii]\end{changebar}, the analyst should set the discussions with the \ac{DM} in such a way as to foster reactions and elicit criticisms when it comes to the relevance of $N$.
For example, if the decision analysis task is monitored by a steering committee, the analyst should take advantage of the meetings with the committee to highlight possible reasons either to accept or to reject $N$.
If, thanks to her understanding of the local context, the analyst suspects that the structure of the steering committee is biased against a given group of stakeholders, she should suggest to the \ac{DM} to enlarge the committee to include those groups or external experts, 
and thereby facilitate the emergence of possible criticisms.
In the same vein, she should do her best to take advantage of the scientific literature to identify relevant arguments.  

%Obviously enough, in some situations, the \ac{DM} will simply reject the analyst's attempts to discuss the relevance of $N$, or will turn a blind eye towards the analyst's request to expand the steering committee. 
Similarly, in some situations, any defense of $N$ or any alternative to $N$ will face a stubborn resistance by ill-intentioned people simply willing to sabotage the decision process. In such cases, the analyst will have to surrender at some point.

%But this surrender is not a failure of his justification attempts. He will have failed if an alternative decision process is launched whereby another decision analyst manages to develop a more successful justification. In the absence of such a more successful alternative, the first decision process should be considered provisionally justified.

Let us now illustrate these ideas using our concrete example of the restoration of dry grasslands on the Lachens summit 
(the account below is stylized to some extent, in particular in that it focuses on exchange of arguments between the analyst and the \ac{DM}, and leaves aside the contributions of other people, which are not directly relevant to our argument here). 
In its analysis of the restoration project, the consultancy argued that using \ac{CBA} was inappropriate in this case, for two main reasons. 
First, they argued that, because of knowledge gaps in the literature on restoration of the kind of natural habitats at issue, it was impossible to compute the risks involved in the project. 
Second, they argued that some of the likely consequences were such that using \ac{CBA} was ill-advised.
 Among these risks are possible impacts on populations of rare species, in particular \emph{Leucanthemum burnatii} Briq.\@ \& Cav.\@, a rare plant species (see the discussion of this issue by \citet{meinard_ethical_2016}).
\begin{changebar}The main recognized value of this species lies in its scarcity. Although it does not provide any major ecosystem service and has no market value, botanists around Europe consider that it has an intrinsic value as a rare species\end{changebar}.
A prominent method used in the context of \ac{CBA} to capture this kind of value is the travel cost method, which, in its application in this case, would compute the money that botanists are prepared to pay to make the trip to the Lachens summit to see the species.
A major problem for this method is that it does not take account of the value that botanists who don't have the money to make the trip bestow on the species. An important part of the value of the species would hence be ignored if this method were used.
\begin{changebar}Prominent alternatives to this method are provided by stated-preferences methods. But\end{changebar} here again the consultancy argued that applying it would not give completely satisfactory results, because the applicability of this method to biodiversity is debated in the literature.
Part of these arguments can be found in the technical report produced by the consultancy \citep{meinard_etude_2015}, but many were voiced in meetings.
In the end, although the initial demand was to implement a complete \ac{CBA}, the consultants did not do it, because they had reasons that they could articulate in discussions with the \ac{DM}, the reasons being that they believed they lacked the data and technologies needed to properly implement this method. 
This means neither that the \ac{DM}'s problem was unsolvable, nor that other consultants could not have found a way to solve it using \ac{CBA}.
But as it stands, the consultants who tried to solve the problem using \ac{CBA} did not find a satisfactory way to do it, and produced arguments which convinced the \ac{DM} that doing it was (possibly provisionally) impossible.
Accordingly, this endeavor to provide decision aid was justified, in the sense articulated above.
\end{example}

The \begin{changebar}practical rules spelled out above echo \citet{lahtinen_why_2017}'s ``path approach'' to \ac{OR} activities, and their promotion of an ``ideal path'', which they describe as a ``path formed by well-justified choices''.
Our own practical rules aim at spelling out in more concrete terms the requirements that \citet{lahtinen_why_2017} refer to using terms such as ``well-justified'', ``essential characteristics'', ``reflective''.
Similarly, our point [i] echoes \citet{funtowicz_science_1993}'s claim that in post-normal science ``values are not presupposed but made explicit'', and our point [ii] is reminiscent of \citet{funtowicz_science_1993}'s ``extended peer community''.
However, \citet{funtowicz_science_1993} neglect the difficulties involved in implementing [i-ii], which prompted us to introduce clauses [iii-iv] and, as opposed to \citet{funtowicz_science_1993}, we argue that the procedure [i-iv] should be deployed in all decision support processes, 
not only in situations characterized by high decision stakes and systems uncertainties.
Our proposed practical rule should therefore be seen as complementary to the above contributions, which they contribute to strengthen by clarifying a preliminary crucial step that they tend to neglect.
A similar relation exists with \citet{mingers_ethics_2011}, who delineates applications of Habermas' discourse ethics to \ac{OR} practice, but refers to the idea of ``justifiability'' without defining it and 
advocates that what is important is ``that every effort is made to involve and engage all the relevant stakeholders in a genuine and continuing dialogue'' without specifying how to ensure that the dialog is ``genuine''.
Although, at this stage, we do not explore in concrete behavioral terms the interaction between analysts and \acp{DM}, 
our approach also interestingly echoes \citet{hamalainen_importance_2013} who emphasize, in their review of the importance of taking behavioral aspects in \ac{OR}, 
``the phenomenon that people are less influenced by decision problem framing, that is, by the way in which the information is presented, if they are asked to give written reasons for their decision''.
Our approach provides a framework to implement this requirement in practice.\end{changebar}

\section{Conclusions}
\label{sec:concl}
In this article, we have introduced an account of how, as decision analysts applying decision sciences to concrete situations, we should cope with the normative aspects of our endeavor. %For that purpose, we have explored a series of attitudes with respect to $N$ observed in the decision sciences literature.
\begin{changebar}Several aspects of this account echo ideas developed by American pragmatist philosophers \citep{ormerod_history_2006}. 
In particular, our approach to ``justification'' is anchored in an analysis of the usages of the term, we propose to unfold the requirement to produce justification as a practical procedure and, even more fundamentally, 
our original research question only makes sense against the pragmatic background idea that norms play a key role even in activities that other approaches would categorize as entirely concerned with pure facts.
However, beyond these fundamental ideas, our reasoning is not tightly anchored in any specific philosophical framework developed by authors in this school of thought.
%However, interpretations of American pragmatism are debated in the literature, especially in their application to environmental issues \citep{spash_new_2009}.
We therefore do not place this contribution under the aegis of American pragmatism.
%, because this would require addressing the above criticisms of this broader framework, which falls beyond our scope.
\end{changebar}

%To ponder on this formulation, it is useful to mention three prominent objections that one might want to raise against our approach. A first objection might come from decision scientists who would reduce our argument to a simple call for decision analysts to justify their recommendations, which, they might argue, is what decision analysts already do. This would miss an important aspect of our reasoning. Indeed, our rationale emphasizes that recommendations necessarily rest on norms, and stresses that decision analysts cannot eschew the need to help \acp{DM} to make up their mind about those norms. Current practices address this issue informally, if at all. By contrast, we argue that it is necessary to anchor this important part of applied decision theory in a rigorous methodology -- an objective to which this article attempts to contribute. To that end, we have proposed practical rules that decision analysts should follow in order to obtain justified recommendations. If followed, these practical rules will modify current practices. \citet{cailloux_formal_2018} provide a first instantiation of this account in a formal framework.

%A second objection might come from decision analysts who would claim that justification requirements command respect, but are impossible to implement in practice. Such critics would claim that, in practice, decision scientists have no choice but to pick up some norms $N$ to derive recommendations, and that any serious attempt to justify these norms would be impractical. Justification requirements would be impractical indeed, if they meant that any recommendation should be anchored in an “ultimate” justification. However, our reasoning is based on an incremental and provisional approach to justifications: the justifications that we are interested in are not ``ultimate'' in any sense, they are tentative and open to improvements. Identifying such provisional justifications is far more practical than pretending to capture ``ultimate justifications'', and we argue that it can be done in practice by following our proposed practical rules.

%A third objection is a radicalized version of the second one. It would claim that, in practice, justification is irrelevant: the only relevant point is that decision analysis should ``work''. This idea is \emph{prima facie} convincing, but what does it mean for decision analysis to ``work'' or to be ``value-adding''? 
%To a large extent, the successfulness of decision analysis hinges upon the analyst's capacity to justify it. In that sense, this would-be objection does not seem to be a real objection after all. At the very least, the burden of proof lies on critics who should be able to articulate it using a clear explanation of what it means for decision analysis to work. 

We see our contribution as an attempt to articulate (relatively) precise requirements that applications of decision sciences should follow, with concrete, practical implications. We emphasize that the precision of those requirements is limited in many respects.
It provide neither a metric nor generally applicable mechanical means to compare any two applications of decision sciences without discussions (\citet{cailloux_formal_2018} introduce the rudiments of a procedure liable to fulfill this more ambitious agenda).
Besides, as emphasized above, our work in this article is focused on relatively simple situations where the recommendations elaborated by the analyst are offered to a single, well-identified \ac{DM}, which evacuates difficulties associated with group decisions and some particularly complex boundary judgments.
One might want to criticize our approach by claiming that this restriction in effect confines our analysis to highly stylized decision processes never exemplified in real-life decision analysis.
\begin{changebar}We rather see our contribution as an exploration of a fundamental aspect shared by all decision support processes, which is, in our view, insufficiently analyzed in the literature addressing decision processes in their full concrete complexity.\end{changebar}
%Indeed, one might point out that even in settings in which a single \ac{DM} is clearly identified \emph{prima facie}, most of the time in effect this \ac{DM} has limited leverage and other stakeholders are always at least informally involved in his decision. 
%This idea could suggest that the relevant notion of justification for decision analysis is not a matter of arguments and counter-arguments that \emph{the \ac{DM}} understands and accepts, but that \emph{the collective involved in the decision} understands and accepts. 
%Such a rationale however conflates two different kinds of decision situations. 
%On the one hand, in some decision situations, although a single \ac{DM} is clearly identified, he has to take account of the fact that his power to act is limited, and he has to take a series of stakeholders into account.
% In such cases, our framework is applicable, and the stakeholders' stances are among the important constitutive elements of the arguments and counter-arguments that our justification procedure should integrate. 
 %On the other hand, in some other decision situations, the real \ac{DM} is a collective: in such cases, our framework needs to be extended or adapted, but we do not see any reason to believe that all the decision situations are amenable to such collective decision settings.  
 %Another limitation that we acknowledge is that we also left aside issues concerning the social responsibility of operational research interventions \citep{ackoff_social_1974,gallo_operations_2004}.

In our view, the analysis of these more complex issues can benefit from our exploration, in the sense that the difficulties involved in aiding a single \ac{DM} to make up his mind about the relevance of accepting a given norm are exacerbated in these more complex, pluri-actor settings.

\begin{changebar}Although the requirement to justify can participate in unveiling, and thereby denouncing, power relations which could otherwise have distorted discussions and decisions, 
we cannot claim at this stage that our framework addresses all the problems liable to be generated by the pervasiveness of power relations in decision processes \citep{cronin_issues_2014}.
Another important aspect of decision processes that our framework does not explicitly addresses is the idea that \acp{OR} might fail to serve the interest of the public or of those who cannot afford it \citep{rosenhead_report_1986}, 
which suggests a need for more critical and socially responsible OR practices \citep{jackson_systems_2000,ulrich_beyond_2003}. This is reinforced by the context of environmental crisis, already stressed by Churchman (1970).
Besides, we also \begin{changebar}consider\end{changebar} here that the recommendations $R$ elaborated by the analyst are offered to a single, well-identified \ac{DM}.
We thereby leave aside difficulties associated with group decisions \citep{jackson_towards_1984}, stakeholder identification \citep{wang_systemic_2015} and with boundary judgments involving the integration of several individuals in a collective \ac{DM} \citep{midgley_systemic_2000}
-- not for lack of interest, but because they are too complex to be tackled in the limited space of this article.\end{changebar}
A prominent avenue for future research is therefore to explore how our framework can contribute to criticize and improve frameworks devoted to tackle the complex issues, such as ``system of systems methodology'' \citep{jackson_towards_1984}, ``critical heuristics'' \citep{ulrich_critical_1987}, 
``critical rationalism'' \citep{ormerod_critical_2014}, ``systems thinking'' \citep{mingers_review_2010}, ``problem structuring methods'' \citep{hector_problem-structuring_2009}, ``cognitive mapping'' \citep{eden_analyzing_2004}, ``community operational research'' \citep{johnson_emerging_2018} or 
``stakeholder-oriented multi-criteria decision analysis'' \citep{de_brucker_multi-criteria_2013}.

%Avoids printing section numbers, but leaves entries in the TOC
\setcounter{secnumdepth}{0}
\section{Acknowledgements}
We thank D. Bouyssou, S. Deparis, P. Grill, M. Nunez and J. Rouchier for powerful comments and suggestions on this manuscript.

%\singlespacing
%\setlength\bibsep{0pt}
\section{References}
\bibliography{propermanual,proper_revisions}

\end{document}
